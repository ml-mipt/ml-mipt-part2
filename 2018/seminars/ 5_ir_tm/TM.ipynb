{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тематическое моделирование\n",
    "============================================================\n",
    "На основе семинара Анны Потапенко "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key words:** \n",
    "   Тематическое моделирование, PLSA, LDA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Plan </h3>\n",
    "  * **Теоретический минимум** (20 minutes)\n",
    "     \n",
    "  * ** nltk+gensim ** (30 minutes)\n",
    "  * ** Обсуждение предобработки ** (20 minutes)\n",
    "  * **BigARTM** (20 minutes)</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Постановка задачи "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Тема** - вероятностное распределение на терминах: $p(w|t)$ - вероятность встретить термин $w$ в теме $t$.\n",
    " \n",
    "Документ имеет ненаблюдаемый **тематический профиль**: \n",
    "$p(t|d)$ - неизвестная частота темы $t$ в~документе $d$.\n",
    "\n",
    "\n",
    "Когда автор писал термин $w$ в~документ~$d$, он думал о~теме~$t$.\n",
    "\n",
    "Документ $d$ состоит из наблюдаемых терминов $w_1,\\dots, w_{n_d}$, $p(w|d)$ - известная частота термина $w$ в~документе~$d$.\n",
    "\n",
    "**Тематическая модель** пытается выявить латентные темы.\n",
    "\n",
    "\n",
    "*  каждое слово в документе связано снекоторой темой $t\\in T$\n",
    "\n",
    "*  $D\\times W\\times T$ - дискретное вероятностное пространство\n",
    "\n",
    "*   коллекция - это  выборка $(d_i,w_i,t_i)_{i=1}^n \\sim p(d,w,t)$\n",
    "\n",
    "*   $d_i,w_i$ - наблюдаемые, темы $t_i$ - скрытые\n",
    "\n",
    "*   гипотеза условной независимости: $p(w|d,t) = p(w|t)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Модель PLSA (Probabilistic Latent Semantic Analysis)\n",
    "\n",
    "**Задача** найти максимум правдоподобия\n",
    "\n",
    "$$\n",
    "            \\!\\sum_{d\\in D} \\sum_{w\\in d} \\!n_{dw} \\ln \\sum_{t\\in T} \\phi_{wt}\\theta_{td}\n",
    "            \\to \\max_{\\Phi,\\Theta},\n",
    "$$\n",
    "при ограничениях неотрицательности и нормировки\n",
    "\n",
    "$$\n",
    "            \\phi_{wt}\\geq 0;\\quad\n",
    "            \\sum_{w\\in W} \\phi_{wt}=1;\n",
    "            \\qquad\n",
    "            \\theta_{td}\\geq 0;\\quad\n",
    "            \\sum_{t\\in T} \\theta_{td}=1\n",
    "$$\n",
    "\n",
    "**Интерпретация:** стохастическое матричное разложение\n",
    "\n",
    "$$\n",
    "        F \\approx \\Phi\\Theta,\n",
    "$$\n",
    "\n",
    "$F = \\bigl( \\hat p(w|d) \\bigr)_{W\\times D}$ -- известная матрица исходных данных,\n",
    "    \n",
    "$\\Phi = \\bigl( \\phi_{wt} \\bigr)_{W\\times T}$ - искомая матрица терминов тем $\\phi_{wt} \\!=\\! p(w|t)$,\n",
    "\n",
    "$\\Theta = \\bigl( \\theta_{td} \\bigr)_{T\\times D}$ - искомая матрица тем документов $\\theta_{td} \\!=\\! p(t|d)$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA(Latent Dirichlet Allocation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод латентного размещения Дирихле (latent Dirichlet allocation, LDA) предложен Дэвидом Блеем в 2003 году, основан на гипотезе о том, что:\n",
    "* векторы документов порождаются одним и тем же вероятностным распределением на нормированных $|T|$-мерных векторах; это распределение удобно взять из параметрического семейства распределений Дирихле $\\mathrm{Dir}(\\theta,\\alpha),\\; \\alpha\\in\\mathbb{R}^{|T|}$;\n",
    "\n",
    "* векторы тем  порождаются одним и тем же вероятностным распределением на нормированных векторах размерности $|W|$; это распределение удобно взять из параметрического семейства распределений Дирихле $\\mathrm{Dir}(\\theta,\\beta),\\; \\beta\\in\\mathbb{R}^{|W|}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для идентификации параметров модели LDA по коллекции документов применяется самплирование Гиббса, вариационный байесовский вывод или метод Expectation-Propagation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пример построения LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Подключаем библиотеку тематического моделирования gensim (http://radimrehurek.com/gensim/),\n",
    "загружаем из NLTK (http://nltk.org/) корпус wordnet - он понадобится при лемматизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import sys\n",
    "import os\n",
    "from math import log\n",
    "import numpy as np\n",
    "from time import time\n",
    "from gensim import corpora, models, similarities\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "nltk.download() #download WordNet corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим предобработку текста: приводим к нижнему регистру, разбиваем на токены, производим лемматизацию. Таким образом, превращаем текст в список лемм."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    wnl = nltk.WordNetLemmatizer()\n",
    "    return [wnl.lemmatize(t) for t in text.lower().split()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считаем коллекцию исходных текстов в список документов. Каждый документ - список лемм (токенов). В этом примере мы загружаем всю коллекцию в оперативную память. На самом деле, gensim позволяет этого избежать на всех этапах построения модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts = []\n",
    "for filename in os.listdir(\"nips11\"):\n",
    "    with open( \"nips11/\"+ filename) as f: \n",
    "        texts.append(preprocess(f.read().decode('cp1251')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Строим по коллекции словарь: каждому уникальному токену присваивается номер, запоминается отображение id2word. Выполним второй этап предобработки: отсеим слишком редкие слова (например, опечатки) и слишком частые слова (например, стоп-слова или просто частотные нетематические термины). Функция filter_extremes удаляет из словаря токены, которые встретились менее чем в no_below документов или более чем в доле no_above от общего числа документов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-11-20 21:20:37,757 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2017-11-20 21:20:38,251 : INFO : built Dictionary(51323 unique tokens: [u'=jtm', u'considered,', u'v\\x7fe', u'considered.', u'7:461-467,']...) from 151 documents (total 482453 corpus positions)\n",
      "2017-11-20 21:20:38,376 : INFO : discarding 46048 tokens: [(u'essay', 1), (u'all', 139), (u'distribution),', 1), (u'consider', 93), (u'exponentiation', 1), (u'particular', 76), (u'known', 76), (u'proposition', 4), (u't\\x7f:-le-tdt', 1), (u'sin\\x7feroresearch.', 1)]...\n",
      "2017-11-20 21:20:38,377 : INFO : keeping 5275 tokens which were in no less than 5 and no more than 75 (=50.0%) documents\n",
      "2017-11-20 21:20:38,408 : INFO : resulting dictionary: Dictionary(5275 unique tokens: [u'ever,', u'two-dimensional', u'biophysical', u'similarity', u'fig.']...)\n",
      "2017-11-20 21:20:38,413 : INFO : saving Dictionary object under nips.dict, separately None\n",
      "2017-11-20 21:20:38,453 : INFO : saved nips.dict\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Dictionary(51323 unique tokens: [u'=jtm', u'considered,', u'v\\x7fe', u'considered.', u'7:461-467,']...)\n",
      "Filtered: Dictionary(5275 unique tokens: [u'ever,', u'two-dimensional', u'biophysical', u'similarity', u'fig.']...)\n"
     ]
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(texts)\n",
    "print 'Original: {}'.format(dictionary)\n",
    "dictionary.filter_extremes(no_below = 5, no_above = 0.5, keep_n=None)\n",
    "dictionary.save('nips.dict')\n",
    "print 'Filtered: {}'.format(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используя полученный словарь, преобразуем корпус текстов в векторизованное представление. Каждый документ теперь это список пар (номер токена, число его вхождений в документ). Это разреженное представление вектора частот: токены, которые не встречаются в документе, не указываются."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-11-20 21:20:38,775 : INFO : storing corpus in Matrix Market format to nips.mm\n",
      "2017-11-20 21:20:38,776 : INFO : saving sparse matrix to nips.mm\n",
      "2017-11-20 21:20:38,777 : INFO : PROGRESS: saving document #0\n",
      "2017-11-20 21:20:39,347 : INFO : saved 151x5275 matrix, density=10.393% (82785/796525)\n",
      "2017-11-20 21:20:39,348 : INFO : saving MmCorpus index to nips.mm.index\n"
     ]
    }
   ],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "corpora.MmCorpus.serialize('nips.mm', corpus) # store on disc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим глазами на начало одного из документов. То, что большинство счетчиков равно 1 -- типично. Распределение частот слов в документе подчиняется закону Ципфа (частота обратно пропорциональна рангу слова)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(7, 1), (16, 1), (25, 9), (27, 2), (35, 1), (38, 1), (72, 2), (81, 1), (112, 1), (117, 1), (141, 3), (145, 1), (146, 3), (150, 1), (161, 1), (169, 1), (190, 1), (195, 1), (199, 1), (241, 1)]\n"
     ]
    }
   ],
   "source": [
    "print corpus[0][0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы готовы к тому, чтобы строить тематическую модель нашей коллекции. Мы строим модель online lda, реализованную в библиотеке gensim. Указываем векторизованный корпус текстов, словарь, число тем 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-11-20 21:20:39,369 : INFO : using symmetric alpha at 0.01\n",
      "2017-11-20 21:20:39,371 : INFO : using symmetric eta at 0.000189573459716\n",
      "2017-11-20 21:20:39,374 : INFO : using serial LDA version on this node\n",
      "2017-11-20 21:20:43,358 : INFO : running online (multi-pass) LDA training, 100 topics, 2 passes over the supplied corpus of 151 documents, updating model once every 50 documents, evaluating perplexity every 151 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2017-11-20 21:20:43,359 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2017-11-20 21:20:43,360 : INFO : PROGRESS: pass 0, at document #50/151\n",
      "2017-11-20 21:20:43,811 : INFO : merging changes from 50 documents into a model of 151 documents\n",
      "2017-11-20 21:20:44,421 : INFO : topic #54 (0.010): 0.018*\"image\" + 0.014*\"scene\" + 0.006*\"convolution\" + 0.005*\"series\" + 0.004*\"local\" + 0.004*\"sensor\" + 0.004*\"markov\" + 0.004*\"control\" + 0.004*\"polynomial\" + 0.003*\"forward\"\n",
      "2017-11-20 21:20:44,423 : INFO : topic #3 (0.010): 0.010*\"image\" + 0.005*\"em\" + 0.004*\"training\" + 0.004*\"component\" + 0.004*\"gaussian\" + 0.004*\"scene\" + 0.004*\"sensor\" + 0.004*\"digit\" + 0.004*\"mixture\" + 0.004*\"state\"\n",
      "2017-11-20 21:20:44,424 : INFO : topic #84 (0.010): 0.009*\"state\" + 0.006*\"image\" + 0.004*\"prior\" + 0.004*\"convolution\" + 0.004*\"noise\" + 0.004*\"bayesian\" + 0.004*\"signal\" + 0.004*\"training\" + 0.003*\"dynamic\" + 0.003*\"impulse\"\n",
      "2017-11-20 21:20:44,425 : INFO : topic #0 (0.010): 0.006*\"control\" + 0.005*\"concept\" + 0.005*\"state\" + 0.005*\"gaussian\" + 0.004*\"noise\" + 0.004*\"&\" + 0.004*\"training\" + 0.004*\"policy\" + 0.004*\"positive\" + 0.004*\"approximation\"\n",
      "2017-11-20 21:20:44,426 : INFO : topic #67 (0.010): 0.010*\"image\" + 0.010*\"filter\" + 0.008*\"phase\" + 0.007*\"approximation\" + 0.006*\"statistic\" + 0.006*\"gaussian\" + 0.006*\"minimax\" + 0.005*\"firing\" + 0.004*\"training\" + 0.004*\"rate\"\n",
      "2017-11-20 21:20:44,431 : INFO : topic diff=27.200535, rho=1.000000\n",
      "2017-11-20 21:20:44,434 : INFO : PROGRESS: pass 0, at document #100/151\n",
      "2017-11-20 21:20:44,894 : INFO : merging changes from 50 documents into a model of 151 documents\n",
      "2017-11-20 21:20:45,209 : INFO : topic #90 (0.010): 0.006*\"cortical\" + 0.006*\"state\" + 0.005*\"image\" + 0.004*\"neuron\" + 0.004*\"complex\" + 0.004*\"correlation\" + 0.004*\"impulse\" + 0.004*\"visual\" + 0.004*\"degree\" + 0.004*\"behavior\"\n",
      "2017-11-20 21:20:45,210 : INFO : topic #73 (0.010): 0.008*\"signal\" + 0.007*\"training\" + 0.006*\"state\" + 0.004*\"source\" + 0.004*\"search\" + 0.004*\"unit\" + 0.004*\"component\" + 0.004*\"v\" + 0.004*\"structure\" + 0.004*\"class\"\n",
      "2017-11-20 21:20:45,212 : INFO : topic #11 (0.010): 0.006*\"p\" + 0.006*\"training\" + 0.005*\"gaussian\" + 0.005*\"correlation\" + 0.005*\"&\" + 0.004*\"noise\" + 0.004*\"cortical\" + 0.004*\"w\" + 0.004*\"prediction\" + 0.003*\"hidden\"\n",
      "2017-11-20 21:20:45,213 : INFO : topic #14 (0.010): 0.014*\"bound\" + 0.013*\"margin\" + 0.012*\"cost\" + 0.010*\"labeled\" + 0.005*\"training\" + 0.005*\"contour\" + 0.004*\"classifier\" + 0.004*\"field\" + 0.004*\"kernel\" + 0.004*\"hebbian\"\n",
      "2017-11-20 21:20:45,215 : INFO : topic #33 (0.010): 0.019*\"mobile\" + 0.013*\"dense\" + 0.012*\"robot\" + 0.011*\"sparse\" + 0.010*\"pomdp\" + 0.010*\"prior\" + 0.009*\"search\" + 0.009*\"trace\" + 0.008*\"eds.,\" + 0.007*\"pruning\"\n",
      "2017-11-20 21:20:45,219 : INFO : topic diff=11.327812, rho=0.707107\n",
      "2017-11-20 21:20:45,222 : INFO : PROGRESS: pass 0, at document #150/151\n",
      "2017-11-20 21:20:45,603 : INFO : merging changes from 50 documents into a model of 151 documents\n",
      "2017-11-20 21:20:45,819 : INFO : topic #52 (0.010): 0.004*\"state\" + 0.004*\"visual\" + 0.003*\"&\" + 0.003*\"rate\" + 0.003*\"neuron\" + 0.003*\"policy\" + 0.003*\"series\" + 0.003*\"em\" + 0.002*\"fig.\" + 0.002*\"call\"\n",
      "2017-11-20 21:20:45,820 : INFO : topic #76 (0.010): 0.006*\"mixture\" + 0.005*\"gaussian\" + 0.005*\"training\" + 0.005*\"sample\" + 0.005*\"em\" + 0.004*\"state\" + 0.004*\"image\" + 0.004*\"margin\" + 0.004*\"scene\" + 0.003*\"prior\"\n",
      "2017-11-20 21:20:45,821 : INFO : topic #81 (0.010): 0.010*\"similarity\" + 0.007*\"hardware\" + 0.007*\"flow\" + 0.007*\"running\" + 0.007*\"{0,\" + 0.006*\"em\" + 0.005*\"state\" + 0.004*\"and/or\" + 0.004*\"recognition\" + 0.004*\"object\"\n",
      "2017-11-20 21:20:45,823 : INFO : topic #33 (0.010): 0.022*\"ease\" + 0.022*\"pomdp\" + 0.015*\"chosen,\" + 0.015*\"mobile\" + 0.011*\"dense\" + 0.011*\"pruning\" + 0.010*\"prior\" + 0.010*\"search\" + 0.010*\"robot\" + 0.009*\"sparse\"\n",
      "2017-11-20 21:20:45,824 : INFO : topic #87 (0.010): 0.008*\"em\" + 0.008*\"contour\" + 0.006*\"mixture\" + 0.005*\"split\" + 0.005*\"component\" + 0.005*\"8\" + 0.004*\"local\" + 0.004*\"field\" + 0.003*\"training\" + 0.003*\"constraint\"\n",
      "2017-11-20 21:20:45,828 : INFO : topic diff=10.288827, rho=0.577350\n",
      "2017-11-20 21:20:46,010 : INFO : -10.433 per-word bound, 1382.3 perplexity estimate based on a held-out corpus of 1 documents with 1004 words\n",
      "2017-11-20 21:20:46,011 : INFO : PROGRESS: pass 0, at document #151/151\n",
      "2017-11-20 21:20:46,028 : INFO : merging changes from 1 documents into a model of 151 documents\n",
      "2017-11-20 21:20:46,209 : INFO : topic #80 (0.010): 0.005*\"training\" + 0.003*\"classification\" + 0.003*\"p\" + 0.003*\"proximity\" + 0.003*\"state\" + 0.003*\"margin\" + 0.003*\"distance\" + 0.003*\"hidden\" + 0.003*\"w\" + 0.002*\"&\"\n",
      "2017-11-20 21:20:46,210 : INFO : topic #39 (0.010): 0.006*\"population\" + 0.006*\"&\" + 0.005*\"motion\" + 0.005*\"labeled\" + 0.004*\"activity\" + 0.004*\"series\" + 0.004*\"response\" + 0.004*\"neuron\" + 0.003*\"direction\" + 0.003*\"state\"\n",
      "2017-11-20 21:20:46,212 : INFO : topic #36 (0.010): 0.005*\"curve\" + 0.005*\"state\" + 0.003*\"margin\" + 0.003*\"image\" + 0.003*\"line\" + 0.003*\"gaussian\" + 0.002*\"principal\" + 0.002*\"noise\" + 0.002*\"approximation\" + 0.002*\"blind\"\n",
      "2017-11-20 21:20:46,213 : INFO : topic #29 (0.010): 0.006*\"em\" + 0.005*\"state\" + 0.004*\"mixture\" + 0.004*\"recognition\" + 0.003*\"behavior\" + 0.002*\"&\" + 0.002*\"prior\" + 0.002*\"sample\" + 0.002*\"visual\" + 0.002*\"training\"\n",
      "2017-11-20 21:20:46,215 : INFO : topic #93 (0.010): 0.036*\"plan\" + 0.030*\"function:\" + 0.014*\"classifier.\" + 0.010*\"classifier\" + 0.008*\"margin\" + 0.004*\"robot\" + 0.004*\"on-line\" + 0.004*\"win\" + 0.003*\"noise\" + 0.003*\"regularized\"\n",
      "2017-11-20 21:20:46,219 : INFO : topic diff=9.219024, rho=0.500000\n",
      "2017-11-20 21:20:46,224 : INFO : PROGRESS: pass 1, at document #50/151\n",
      "2017-11-20 21:20:46,562 : INFO : merging changes from 50 documents into a model of 151 documents\n",
      "2017-11-20 21:20:46,739 : INFO : topic #59 (0.010): 0.004*\"image\" + 0.003*\"convolution\" + 0.003*\"impulse\" + 0.002*\"polynomial\" + 0.002*\"f\" + 0.002*\"training\" + 0.002*\"noise\" + 0.002*\"state\" + 0.002*\"speed\" + 0.002*\"kernel\"\n",
      "2017-11-20 21:20:46,740 : INFO : topic #6 (0.010): 0.121*\"convolution\" + 0.099*\"microsoft\" + 0.092*\"impulse\" + 0.059*\"polynomial\" + 0.017*\"quantization\" + 0.016*\"n-th\" + 0.013*\"extraction\" + 0.012*\"coefficients.\" + 0.011*\"depicted\" + 0.009*\"kernel\"\n",
      "2017-11-20 21:20:46,741 : INFO : topic #95 (0.010): 0.003*\"independent\" + 0.003*\"&\" + 0.002*\"component\" + 0.002*\"cell\" + 0.002*\"signal\" + 0.002*\"sensor\" + 0.002*\"study\" + 0.002*\"human\" + 0.002*\"image\" + 0.002*\"mixture\"\n",
      "2017-11-20 21:20:46,743 : INFO : topic #8 (0.010): 0.061*\"history\" + 0.026*\"simplification\" + 0.011*\"dk\" + 0.008*\"exceed\" + 0.007*\"auxiliary\" + 0.006*\"curve\" + 0.005*\"segment\" + 0.005*\"principal\" + 0.005*\"state\" + 0.005*\"q_\"\n",
      "2017-11-20 21:20:46,745 : INFO : topic #42 (0.010): 0.042*\"failed\" + 0.016*\"position\" + 0.016*\"convergence\" + 0.012*\"v\" + 0.011*\"continuous\" + 0.011*\"shape\" + 0.011*\"contour\" + 0.011*\"control\" + 0.010*\"discontinuous\" + 0.010*\"arm\"\n",
      "2017-11-20 21:20:46,750 : INFO : topic diff=7.946481, rho=0.447214\n",
      "2017-11-20 21:20:46,753 : INFO : PROGRESS: pass 1, at document #100/151\n",
      "2017-11-20 21:20:47,094 : INFO : merging changes from 50 documents into a model of 151 documents\n",
      "2017-11-20 21:20:47,264 : INFO : topic #38 (0.010): 0.197*\"emission\" + 0.065*\"oscillation\" + 0.039*\"europhys.\" + 0.026*\"studied.\" + 0.025*\"1992;\" + 0.021*\"wo\" + 0.013*\"signal.\" + 0.011*\"1993;\" + 0.011*\"independent\" + 0.009*\"component\"\n",
      "2017-11-20 21:20:47,266 : INFO : topic #54 (0.010): 0.156*\"flow\" + 0.142*\"optical\" + 0.098*\"scene\" + 0.080*\"motion\" + 0.039*\"regularization\" + 0.039*\"field\" + 0.027*\"image\" + 0.024*\"computation\" + 0.023*\"vision\" + 0.020*\"velocity\"\n",
      "2017-11-20 21:20:47,266 : INFO : topic #89 (0.010): 0.004*\"image\" + 0.004*\"sensor\" + 0.003*\"&\" + 0.002*\"fig.\" + 0.002*\"prior\" + 0.002*\"gaussian\" + 0.002*\"em\" + 0.002*\"local\" + 0.002*\"object\" + 0.002*\"mixture\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-11-20 21:20:47,268 : INFO : topic #30 (0.010): 0.015*\"training\" + 0.014*\"z\" + 0.013*\"prior\" + 0.013*\"gaussian\" + 0.011*\"regression\" + 0.011*\"bayesian\" + 0.009*\"prediction\" + 0.007*\"distance\" + 0.007*\"on-line\" + 0.007*\"em\"\n",
      "2017-11-20 21:20:47,270 : INFO : topic #98 (0.010): 0.004*\"image\" + 0.003*\"&\" + 0.003*\"noise\" + 0.002*\"state\" + 0.002*\"phase\" + 0.002*\"approximation\" + 0.002*\"agent\" + 0.002*\"prior\" + 0.002*\"action\" + 0.002*\"gaussian\"\n",
      "2017-11-20 21:20:47,273 : INFO : topic diff=7.271029, rho=0.447214\n",
      "2017-11-20 21:20:47,276 : INFO : PROGRESS: pass 1, at document #150/151\n",
      "2017-11-20 21:20:47,621 : INFO : merging changes from 50 documents into a model of 151 documents\n",
      "2017-11-20 21:20:47,808 : INFO : topic #85 (0.010): 0.167*\"efficacy\" + 0.136*\"em.\" + 0.102*\"aston\" + 0.026*\"motivated\" + 0.013*\"normalizing\" + 0.006*\"prior\" + 0.006*\"sparse\" + 0.005*\"sensor\" + 0.004*\"1\" + 0.003*\"covariance\"\n",
      "2017-11-20 21:20:47,810 : INFO : topic #65 (0.010): 0.001*\"neuron\" + 0.001*\"utility\" + 0.001*\"&\" + 0.001*\"state\" + 0.001*\"correlation\" + 0.001*\"p\" + 0.001*\"independent\" + 0.001*\"component\" + 0.001*\"gaussian\" + 0.001*\"traffic\"\n",
      "2017-11-20 21:20:47,811 : INFO : topic #24 (0.010): 0.002*\"curve\" + 0.001*\"state\" + 0.001*\"policy\" + 0.001*\"blind\" + 0.001*\"signal\" + 0.001*\"line\" + 0.001*\"principal\" + 0.001*\"table\" + 0.001*\"gradient\" + 0.001*\"reinforcement\"\n",
      "2017-11-20 21:20:47,812 : INFO : topic #46 (0.010): 0.002*\"curve\" + 0.002*\"principal\" + 0.001*\"image\" + 0.001*\"line\" + 0.001*\"h\" + 0.001*\"sensor\" + 0.001*\"local\" + 0.001*\"fig.\" + 0.001*\"convolution\" + 0.001*\"vertex\"\n",
      "2017-11-20 21:20:47,813 : INFO : topic #43 (0.010): 0.030*\"direction\" + 0.024*\"response\" + 0.017*\"population\" + 0.015*\"motion\" + 0.014*\"stimulus\" + 0.014*\"visual\" + 0.014*\"activity\" + 0.012*\"coding\" + 0.011*\"code\" + 0.011*\"cortical\"\n",
      "2017-11-20 21:20:47,818 : INFO : topic diff=6.180342, rho=0.447214\n",
      "2017-11-20 21:20:47,943 : INFO : -7.693 per-word bound, 206.9 perplexity estimate based on a held-out corpus of 1 documents with 1004 words\n",
      "2017-11-20 21:20:47,944 : INFO : PROGRESS: pass 1, at document #151/151\n",
      "2017-11-20 21:20:47,961 : INFO : merging changes from 1 documents into a model of 151 documents\n",
      "2017-11-20 21:20:48,125 : INFO : topic #80 (0.010): 0.001*\"training\" + 0.001*\"classification\" + 0.001*\"p\" + 0.001*\"proximity\" + 0.001*\"state\" + 0.001*\"margin\" + 0.001*\"distance\" + 0.001*\"hidden\" + 0.001*\"w\" + 0.001*\"&\"\n",
      "2017-11-20 21:20:48,126 : INFO : topic #23 (0.010): 0.046*\"commercial\" + 0.045*\"madison,\" + 0.031*\"state\" + 0.024*\"environment\" + 0.020*\"hmm\" + 0.017*\"hmms\" + 0.016*\"call\" + 0.014*\"false\" + 0.013*\"(3).\" + 0.012*\"centroid\"\n",
      "2017-11-20 21:20:48,127 : INFO : topic #91 (0.010): 0.001*\"control\" + 0.001*\"population\" + 0.001*\"state\" + 0.001*\"policy\" + 0.001*\"noise\" + 0.001*\"j\" + 0.001*\"correlation\" + 0.001*\"reinforcement\" + 0.001*\"continuous\" + 0.001*\"dynamic\"\n",
      "2017-11-20 21:20:48,128 : INFO : topic #15 (0.010): 0.010*\"dk\" + 0.003*\"e)\" + 0.002*\"&\" + 0.001*\"em\" + 0.001*\"positive\" + 0.001*\"r\" + 0.001*\"agent\" + 0.001*\"action\" + 0.001*\"proximity\" + 0.001*\"factor\"\n",
      "2017-11-20 21:20:48,130 : INFO : topic #72 (0.010): 0.009*\"calculates\" + 0.006*\"approximation\" + 0.005*\"gaussian\" + 0.005*\"field\" + 0.004*\"state\" + 0.004*\"approximation.\" + 0.003*\"estimation\" + 0.003*\"massachusetts,\" + 0.003*\"wu,\" + 0.003*\"f\"\n",
      "2017-11-20 21:20:48,134 : INFO : topic diff=4.897453, rho=0.447214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.146152416865\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "model = models.ldamodel.LdaModel(corpus, id2word=dictionary, num_topics=100, chunksize=50, update_every=1, passes=2)\n",
    "print 'Evaluation time: {}'.format((time()-start) / 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, что получилось.  Интерпретируемо?) Коллекция NIPS вся посвящена машинному обучению. Зрительно сложно оценить темы, хотя некоторая интерпретируемость прослеживается. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'neuron', 0.02354453349042205), (u'synaptic', 0.022050759030025225), (u'cell', 0.020612523237473982), (u'visual', 0.017937468076819191), (u'spike', 0.017489225979225004), (u'firing', 0.01737808830794868), (u'rate', 0.013340562805124981), (u'&', 0.013108742606273614), (u'rule', 0.013097234863106405), (u'potential', 0.010659506464008126)] \n",
      "\n",
      "[(u'job', 0.13801409069869797), (u'concept', 0.00068028379825395974), (u'approximation', 0.00064664799687722853), (u'rate', 0.00062139356608129461), (u'positive', 0.00060642558490200363), (u'prior', 0.00059585580690812588), (u'series', 0.00058351254944747396), (u'hypothesis', 0.00055741076959087892), (u'state', 0.00054959245508515631), (u'posterior', 0.0005433337547529728)] \n",
      "\n",
      "[(u'clustering', 0.16902563208901178), (u'language', 0.064770866351768042), (u'dependency', 0.055198442456061793), (u'clustering.', 0.043548247496583335), (u'unsupervised', 0.036502659111949193), (u'cluster', 0.034290032312123318), (u'{0,', 0.02603092226978174), (u'document', 0.020961542633513779), (u'partitioning', 0.016859517884715885), (u'partition', 0.016611419155191636)] \n",
      "\n",
      "[(u'working', 0.042749084995753681), (u'risk', 0.019483281790808247), (u'machine', 0.016380005233068498), (u'training', 0.012510124572198897), (u'support', 0.010985634478416854), (u'integer', 0.010754789280704159), (u'class', 0.0090379191882739435), (u'structural', 0.0088471025043751848), (u'overall', 0.0083261811414485527), (u'report', 0.0079553625036208626)] \n",
      "\n",
      "[(u'image', 0.0025402168655870925), (u'optical', 0.0019419807023685093), (u'scene', 0.0012256671194468963), (u'gaussian', 0.001037346386137778), (u'constraint', 0.00097094158552185541), (u'state', 0.00096443163075924819), (u'sensor', 0.00095880622510488057), (u'local', 0.00094104166054826148), (u'flow', 0.0008358490802974146), (u'call', 0.00083044592512084936)] \n",
      "\n",
      "\n",
      "[(u'neuron', 0.02354453349042205), (u'synaptic', 0.022050759030025225), (u'cell', 0.020612523237473982), (u'visual', 0.017937468076819191), (u'spike', 0.017489225979225004), (u'firing', 0.01737808830794868), (u'rate', 0.013340562805124981), (u'&', 0.013108742606273614), (u'rule', 0.013097234863106405), (u'potential', 0.010659506464008126)] \n",
      "\n",
      "[(u'job', 0.13801409069869797), (u'concept', 0.00068028379825395974), (u'approximation', 0.00064664799687722853), (u'rate', 0.00062139356608129461), (u'positive', 0.00060642558490200363), (u'prior', 0.00059585580690812588), (u'series', 0.00058351254944747396), (u'hypothesis', 0.00055741076959087892), (u'state', 0.00054959245508515631), (u'posterior', 0.0005433337547529728)] \n",
      "\n",
      "[(u'clustering', 0.16902563208901178), (u'language', 0.064770866351768042), (u'dependency', 0.055198442456061793), (u'clustering.', 0.043548247496583335), (u'unsupervised', 0.036502659111949193), (u'cluster', 0.034290032312123318), (u'{0,', 0.02603092226978174), (u'document', 0.020961542633513779), (u'partitioning', 0.016859517884715885), (u'partition', 0.016611419155191636)] \n",
      "\n",
      "[(u'working', 0.042749084995753681), (u'risk', 0.019483281790808247), (u'machine', 0.016380005233068498), (u'training', 0.012510124572198897), (u'support', 0.010985634478416854), (u'integer', 0.010754789280704159), (u'class', 0.0090379191882739435), (u'structural', 0.0088471025043751848), (u'overall', 0.0083261811414485527), (u'report', 0.0079553625036208626)] \n",
      "\n",
      "[(u'image', 0.0025402168655870925), (u'optical', 0.0019419807023685093), (u'scene', 0.0012256671194468963), (u'gaussian', 0.001037346386137778), (u'constraint', 0.00097094158552185541), (u'state', 0.00096443163075924819), (u'sensor', 0.00095880622510488057), (u'local', 0.00094104166054826148), (u'flow', 0.0008358490802974146), (u'call', 0.00083044592512084936)] \n",
      "\n",
      "\n",
      "[(u'neuron', 0.02354453349042205), (u'synaptic', 0.022050759030025225), (u'cell', 0.020612523237473982), (u'visual', 0.017937468076819191), (u'spike', 0.017489225979225004), (u'firing', 0.01737808830794868), (u'rate', 0.013340562805124981), (u'&', 0.013108742606273614), (u'rule', 0.013097234863106405), (u'potential', 0.010659506464008126)] \n",
      "\n",
      "[(u'job', 0.13801409069869797), (u'concept', 0.00068028379825395974), (u'approximation', 0.00064664799687722853), (u'rate', 0.00062139356608129461), (u'positive', 0.00060642558490200363), (u'prior', 0.00059585580690812588), (u'series', 0.00058351254944747396), (u'hypothesis', 0.00055741076959087892), (u'state', 0.00054959245508515631), (u'posterior', 0.0005433337547529728)] \n",
      "\n",
      "[(u'clustering', 0.16902563208901178), (u'language', 0.064770866351768042), (u'dependency', 0.055198442456061793), (u'clustering.', 0.043548247496583335), (u'unsupervised', 0.036502659111949193), (u'cluster', 0.034290032312123318), (u'{0,', 0.02603092226978174), (u'document', 0.020961542633513779), (u'partitioning', 0.016859517884715885), (u'partition', 0.016611419155191636)] \n",
      "\n",
      "[(u'working', 0.042749084995753681), (u'risk', 0.019483281790808247), (u'machine', 0.016380005233068498), (u'training', 0.012510124572198897), (u'support', 0.010985634478416854), (u'integer', 0.010754789280704159), (u'class', 0.0090379191882739435), (u'structural', 0.0088471025043751848), (u'overall', 0.0083261811414485527), (u'report', 0.0079553625036208626)] \n",
      "\n",
      "[(u'image', 0.0025402168655870925), (u'optical', 0.0019419807023685093), (u'scene', 0.0012256671194468963), (u'gaussian', 0.001037346386137778), (u'constraint', 0.00097094158552185541), (u'state', 0.00096443163075924819), (u'sensor', 0.00095880622510488057), (u'local', 0.00094104166054826148), (u'flow', 0.0008358490802974146), (u'call', 0.00083044592512084936)] \n",
      "\n",
      "\n",
      "[(u'neuron', 0.02354453349042205), (u'synaptic', 0.022050759030025225), (u'cell', 0.020612523237473982), (u'visual', 0.017937468076819191), (u'spike', 0.017489225979225004), (u'firing', 0.01737808830794868), (u'rate', 0.013340562805124981), (u'&', 0.013108742606273614), (u'rule', 0.013097234863106405), (u'potential', 0.010659506464008126)] \n",
      "\n",
      "[(u'job', 0.13801409069869797), (u'concept', 0.00068028379825395974), (u'approximation', 0.00064664799687722853), (u'rate', 0.00062139356608129461), (u'positive', 0.00060642558490200363), (u'prior', 0.00059585580690812588), (u'series', 0.00058351254944747396), (u'hypothesis', 0.00055741076959087892), (u'state', 0.00054959245508515631), (u'posterior', 0.0005433337547529728)] \n",
      "\n",
      "[(u'clustering', 0.16902563208901178), (u'language', 0.064770866351768042), (u'dependency', 0.055198442456061793), (u'clustering.', 0.043548247496583335), (u'unsupervised', 0.036502659111949193), (u'cluster', 0.034290032312123318), (u'{0,', 0.02603092226978174), (u'document', 0.020961542633513779), (u'partitioning', 0.016859517884715885), (u'partition', 0.016611419155191636)] \n",
      "\n",
      "[(u'working', 0.042749084995753681), (u'risk', 0.019483281790808247), (u'machine', 0.016380005233068498), (u'training', 0.012510124572198897), (u'support', 0.010985634478416854), (u'integer', 0.010754789280704159), (u'class', 0.0090379191882739435), (u'structural', 0.0088471025043751848), (u'overall', 0.0083261811414485527), (u'report', 0.0079553625036208626)] \n",
      "\n",
      "[(u'image', 0.0025402168655870925), (u'optical', 0.0019419807023685093), (u'scene', 0.0012256671194468963), (u'gaussian', 0.001037346386137778), (u'constraint', 0.00097094158552185541), (u'state', 0.00096443163075924819), (u'sensor', 0.00095880622510488057), (u'local', 0.00094104166054826148), (u'flow', 0.0008358490802974146), (u'call', 0.00083044592512084936)] \n",
      "\n",
      "\n",
      "[(u'neuron', 0.02354453349042205), (u'synaptic', 0.022050759030025225), (u'cell', 0.020612523237473982), (u'visual', 0.017937468076819191), (u'spike', 0.017489225979225004), (u'firing', 0.01737808830794868), (u'rate', 0.013340562805124981), (u'&', 0.013108742606273614), (u'rule', 0.013097234863106405), (u'potential', 0.010659506464008126)] \n",
      "\n",
      "[(u'job', 0.13801409069869797), (u'concept', 0.00068028379825395974), (u'approximation', 0.00064664799687722853), (u'rate', 0.00062139356608129461), (u'positive', 0.00060642558490200363), (u'prior', 0.00059585580690812588), (u'series', 0.00058351254944747396), (u'hypothesis', 0.00055741076959087892), (u'state', 0.00054959245508515631), (u'posterior', 0.0005433337547529728)] \n",
      "\n",
      "[(u'clustering', 0.16902563208901178), (u'language', 0.064770866351768042), (u'dependency', 0.055198442456061793), (u'clustering.', 0.043548247496583335), (u'unsupervised', 0.036502659111949193), (u'cluster', 0.034290032312123318), (u'{0,', 0.02603092226978174), (u'document', 0.020961542633513779), (u'partitioning', 0.016859517884715885), (u'partition', 0.016611419155191636)] \n",
      "\n",
      "[(u'working', 0.042749084995753681), (u'risk', 0.019483281790808247), (u'machine', 0.016380005233068498), (u'training', 0.012510124572198897), (u'support', 0.010985634478416854), (u'integer', 0.010754789280704159), (u'class', 0.0090379191882739435), (u'structural', 0.0088471025043751848), (u'overall', 0.0083261811414485527), (u'report', 0.0079553625036208626)] \n",
      "\n",
      "[(u'image', 0.0025402168655870925), (u'optical', 0.0019419807023685093), (u'scene', 0.0012256671194468963), (u'gaussian', 0.001037346386137778), (u'constraint', 0.00097094158552185541), (u'state', 0.00096443163075924819), (u'sensor', 0.00095880622510488057), (u'local', 0.00094104166054826148), (u'flow', 0.0008358490802974146), (u'call', 0.00083044592512084936)] \n",
      "\n",
      "\n",
      "[(u'neuron', 0.02354453349042205), (u'synaptic', 0.022050759030025225), (u'cell', 0.020612523237473982), (u'visual', 0.017937468076819191), (u'spike', 0.017489225979225004), (u'firing', 0.01737808830794868), (u'rate', 0.013340562805124981), (u'&', 0.013108742606273614), (u'rule', 0.013097234863106405), (u'potential', 0.010659506464008126)] \n",
      "\n",
      "[(u'job', 0.13801409069869797), (u'concept', 0.00068028379825395974), (u'approximation', 0.00064664799687722853), (u'rate', 0.00062139356608129461), (u'positive', 0.00060642558490200363), (u'prior', 0.00059585580690812588), (u'series', 0.00058351254944747396), (u'hypothesis', 0.00055741076959087892), (u'state', 0.00054959245508515631), (u'posterior', 0.0005433337547529728)] \n",
      "\n",
      "[(u'clustering', 0.16902563208901178), (u'language', 0.064770866351768042), (u'dependency', 0.055198442456061793), (u'clustering.', 0.043548247496583335), (u'unsupervised', 0.036502659111949193), (u'cluster', 0.034290032312123318), (u'{0,', 0.02603092226978174), (u'document', 0.020961542633513779), (u'partitioning', 0.016859517884715885), (u'partition', 0.016611419155191636)] \n",
      "\n",
      "[(u'working', 0.042749084995753681), (u'risk', 0.019483281790808247), (u'machine', 0.016380005233068498), (u'training', 0.012510124572198897), (u'support', 0.010985634478416854), (u'integer', 0.010754789280704159), (u'class', 0.0090379191882739435), (u'structural', 0.0088471025043751848), (u'overall', 0.0083261811414485527), (u'report', 0.0079553625036208626)] \n",
      "\n",
      "[(u'image', 0.0025402168655870925), (u'optical', 0.0019419807023685093), (u'scene', 0.0012256671194468963), (u'gaussian', 0.001037346386137778), (u'constraint', 0.00097094158552185541), (u'state', 0.00096443163075924819), (u'sensor', 0.00095880622510488057), (u'local', 0.00094104166054826148), (u'flow', 0.0008358490802974146), (u'call', 0.00083044592512084936)] \n",
      "\n",
      "\n",
      "[(u'neuron', 0.02354453349042205), (u'synaptic', 0.022050759030025225), (u'cell', 0.020612523237473982), (u'visual', 0.017937468076819191), (u'spike', 0.017489225979225004), (u'firing', 0.01737808830794868), (u'rate', 0.013340562805124981), (u'&', 0.013108742606273614), (u'rule', 0.013097234863106405), (u'potential', 0.010659506464008126)] \n",
      "\n",
      "[(u'job', 0.13801409069869797), (u'concept', 0.00068028379825395974), (u'approximation', 0.00064664799687722853), (u'rate', 0.00062139356608129461), (u'positive', 0.00060642558490200363), (u'prior', 0.00059585580690812588), (u'series', 0.00058351254944747396), (u'hypothesis', 0.00055741076959087892), (u'state', 0.00054959245508515631), (u'posterior', 0.0005433337547529728)] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'clustering', 0.16902563208901178), (u'language', 0.064770866351768042), (u'dependency', 0.055198442456061793), (u'clustering.', 0.043548247496583335), (u'unsupervised', 0.036502659111949193), (u'cluster', 0.034290032312123318), (u'{0,', 0.02603092226978174), (u'document', 0.020961542633513779), (u'partitioning', 0.016859517884715885), (u'partition', 0.016611419155191636)] \n",
      "\n",
      "[(u'working', 0.042749084995753681), (u'risk', 0.019483281790808247), (u'machine', 0.016380005233068498), (u'training', 0.012510124572198897), (u'support', 0.010985634478416854), (u'integer', 0.010754789280704159), (u'class', 0.0090379191882739435), (u'structural', 0.0088471025043751848), (u'overall', 0.0083261811414485527), (u'report', 0.0079553625036208626)] \n",
      "\n",
      "[(u'image', 0.0025402168655870925), (u'optical', 0.0019419807023685093), (u'scene', 0.0012256671194468963), (u'gaussian', 0.001037346386137778), (u'constraint', 0.00097094158552185541), (u'state', 0.00096443163075924819), (u'sensor', 0.00095880622510488057), (u'local', 0.00094104166054826148), (u'flow', 0.0008358490802974146), (u'call', 0.00083044592512084936)] \n",
      "\n",
      "\n",
      "[(u'neuron', 0.02354453349042205), (u'synaptic', 0.022050759030025225), (u'cell', 0.020612523237473982), (u'visual', 0.017937468076819191), (u'spike', 0.017489225979225004), (u'firing', 0.01737808830794868), (u'rate', 0.013340562805124981), (u'&', 0.013108742606273614), (u'rule', 0.013097234863106405), (u'potential', 0.010659506464008126)] \n",
      "\n",
      "[(u'job', 0.13801409069869797), (u'concept', 0.00068028379825395974), (u'approximation', 0.00064664799687722853), (u'rate', 0.00062139356608129461), (u'positive', 0.00060642558490200363), (u'prior', 0.00059585580690812588), (u'series', 0.00058351254944747396), (u'hypothesis', 0.00055741076959087892), (u'state', 0.00054959245508515631), (u'posterior', 0.0005433337547529728)] \n",
      "\n",
      "[(u'clustering', 0.16902563208901178), (u'language', 0.064770866351768042), (u'dependency', 0.055198442456061793), (u'clustering.', 0.043548247496583335), (u'unsupervised', 0.036502659111949193), (u'cluster', 0.034290032312123318), (u'{0,', 0.02603092226978174), (u'document', 0.020961542633513779), (u'partitioning', 0.016859517884715885), (u'partition', 0.016611419155191636)] \n",
      "\n",
      "[(u'working', 0.042749084995753681), (u'risk', 0.019483281790808247), (u'machine', 0.016380005233068498), (u'training', 0.012510124572198897), (u'support', 0.010985634478416854), (u'integer', 0.010754789280704159), (u'class', 0.0090379191882739435), (u'structural', 0.0088471025043751848), (u'overall', 0.0083261811414485527), (u'report', 0.0079553625036208626)] \n",
      "\n",
      "[(u'image', 0.0025402168655870925), (u'optical', 0.0019419807023685093), (u'scene', 0.0012256671194468963), (u'gaussian', 0.001037346386137778), (u'constraint', 0.00097094158552185541), (u'state', 0.00096443163075924819), (u'sensor', 0.00095880622510488057), (u'local', 0.00094104166054826148), (u'flow', 0.0008358490802974146), (u'call', 0.00083044592512084936)] \n",
      "\n",
      "\n",
      "[(u'neuron', 0.02354453349042205), (u'synaptic', 0.022050759030025225), (u'cell', 0.020612523237473982), (u'visual', 0.017937468076819191), (u'spike', 0.017489225979225004), (u'firing', 0.01737808830794868), (u'rate', 0.013340562805124981), (u'&', 0.013108742606273614), (u'rule', 0.013097234863106405), (u'potential', 0.010659506464008126)] \n",
      "\n",
      "[(u'job', 0.13801409069869797), (u'concept', 0.00068028379825395974), (u'approximation', 0.00064664799687722853), (u'rate', 0.00062139356608129461), (u'positive', 0.00060642558490200363), (u'prior', 0.00059585580690812588), (u'series', 0.00058351254944747396), (u'hypothesis', 0.00055741076959087892), (u'state', 0.00054959245508515631), (u'posterior', 0.0005433337547529728)] \n",
      "\n",
      "[(u'clustering', 0.16902563208901178), (u'language', 0.064770866351768042), (u'dependency', 0.055198442456061793), (u'clustering.', 0.043548247496583335), (u'unsupervised', 0.036502659111949193), (u'cluster', 0.034290032312123318), (u'{0,', 0.02603092226978174), (u'document', 0.020961542633513779), (u'partitioning', 0.016859517884715885), (u'partition', 0.016611419155191636)] \n",
      "\n",
      "[(u'working', 0.042749084995753681), (u'risk', 0.019483281790808247), (u'machine', 0.016380005233068498), (u'training', 0.012510124572198897), (u'support', 0.010985634478416854), (u'integer', 0.010754789280704159), (u'class', 0.0090379191882739435), (u'structural', 0.0088471025043751848), (u'overall', 0.0083261811414485527), (u'report', 0.0079553625036208626)] \n",
      "\n",
      "[(u'image', 0.0025402168655870925), (u'optical', 0.0019419807023685093), (u'scene', 0.0012256671194468963), (u'gaussian', 0.001037346386137778), (u'constraint', 0.00097094158552185541), (u'state', 0.00096443163075924819), (u'sensor', 0.00095880622510488057), (u'local', 0.00094104166054826148), (u'flow', 0.0008358490802974146), (u'call', 0.00083044592512084936)] \n",
      "\n",
      "\n",
      "[(u'neuron', 0.02354453349042205), (u'synaptic', 0.022050759030025225), (u'cell', 0.020612523237473982), (u'visual', 0.017937468076819191), (u'spike', 0.017489225979225004), (u'firing', 0.01737808830794868), (u'rate', 0.013340562805124981), (u'&', 0.013108742606273614), (u'rule', 0.013097234863106405), (u'potential', 0.010659506464008126)] \n",
      "\n",
      "[(u'job', 0.13801409069869797), (u'concept', 0.00068028379825395974), (u'approximation', 0.00064664799687722853), (u'rate', 0.00062139356608129461), (u'positive', 0.00060642558490200363), (u'prior', 0.00059585580690812588), (u'series', 0.00058351254944747396), (u'hypothesis', 0.00055741076959087892), (u'state', 0.00054959245508515631), (u'posterior', 0.0005433337547529728)] \n",
      "\n",
      "[(u'clustering', 0.16902563208901178), (u'language', 0.064770866351768042), (u'dependency', 0.055198442456061793), (u'clustering.', 0.043548247496583335), (u'unsupervised', 0.036502659111949193), (u'cluster', 0.034290032312123318), (u'{0,', 0.02603092226978174), (u'document', 0.020961542633513779), (u'partitioning', 0.016859517884715885), (u'partition', 0.016611419155191636)] \n",
      "\n",
      "[(u'working', 0.042749084995753681), (u'risk', 0.019483281790808247), (u'machine', 0.016380005233068498), (u'training', 0.012510124572198897), (u'support', 0.010985634478416854), (u'integer', 0.010754789280704159), (u'class', 0.0090379191882739435), (u'structural', 0.0088471025043751848), (u'overall', 0.0083261811414485527), (u'report', 0.0079553625036208626)] \n",
      "\n",
      "[(u'image', 0.0025402168655870925), (u'optical', 0.0019419807023685093), (u'scene', 0.0012256671194468963), (u'gaussian', 0.001037346386137778), (u'constraint', 0.00097094158552185541), (u'state', 0.00096443163075924819), (u'sensor', 0.00095880622510488057), (u'local', 0.00094104166054826148), (u'flow', 0.0008358490802974146), (u'call', 0.00083044592512084936)] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for position in range(10):\n",
    "    for topic in range(60, 65):\n",
    "        print model.show_topic(topic),\n",
    "        print('')\n",
    "        print('')\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы посмотрели на часть матрицы Phi - вероятностей слов в темах, теперь посомтрим на часть матрицы Theta - вероятностей тем в документах. Ниже выведены номера тем и вероятности этих тем для некоторого документа. Заметим, что это очень разреженный вектор. На самом деле, модель строит абсолютно плотный вектор (и это плохо), а функция вывода просто обнуляет все вероятнсти, меньшие 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(30, 0.43798289478503871), (43, 0.017991202744811446), (56, 0.011569795781367303), (60, 0.023868140551495297), (63, 0.088212817954809258), (72, 0.233923711353552), (73, 0.1420425878178217), (74, 0.014116903023921427)]\n"
     ]
    }
   ],
   "source": [
    "some_document = corpus[0]\n",
    "print model[some_document]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оценка моделей с помощью перплексии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перплексия:\n",
    "$$\n",
    "\\mathcal{P} = \\exp\\bigl( -\\frac1{n}\\,L(D) \\bigr)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хочется оценить модель чем-то более убедительным, чем разглядывание профилей тем и профилей документов. Это необходимо для возможноси сравнения разных моделей, например полученных с разными параметрами запуска. Научимся мерить перплексию. Функция model.state.get_lambda возвращает ненормированную матрицу Phi, model.inference оценивает ненормированную матрицу Theta для списка документов. Проходим по коллекции и считаем перплексию по формуле. Чем меньше перплексия, тем лучше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perplexity(model, corpus):\n",
    "    corpus_length = 0\n",
    "    log_likelihood = 0\n",
    "    topic_profiles = model.state.get_lambda() / np.sum(model.state.get_lambda(), axis=1)[:, np.newaxis]\n",
    "    for document in corpus:\n",
    "        gamma, _ = model.inference([document])\n",
    "        document_profile = gamma / np.sum(gamma)\n",
    "        for term_id, term_count in document:\n",
    "            corpus_length += term_count\n",
    "            term_probability = np.dot(document_profile, topic_profiles[:, term_id])\n",
    "            log_likelihood += term_count * log(term_probability)\n",
    "    perplexity = np.exp(-log_likelihood / corpus_length)\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 2206.82903488\n"
     ]
    }
   ],
   "source": [
    "print 'Perplexity: {}'.format(perplexity(model, corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вернемся к параметрам построения модели online LDA. Можно задать: num_topics (100) - число тем, chunksize (2000) - размер блока, passes - число проходов по все коллекции, update_every (1) - каждые сколько блоков обновлять Phi, decay (0.5) - коэффициент забывания при обновлениях.\n",
    "Таким образом, при обучении первой модели мы совершили два полных прохода по коллекции, обновляя Phi после каждых 50 документов. Сделаем 40 проходов по коллекции с обновлениями Phi раз в коллекцию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-11-20 21:20:49,512 : INFO : using symmetric alpha at 0.01\n",
      "2017-11-20 21:20:49,514 : INFO : using symmetric eta at 0.000189573459716\n",
      "2017-11-20 21:20:49,517 : INFO : using serial LDA version on this node\n",
      "2017-11-20 21:20:53,328 : INFO : running batch LDA training, 100 topics, 40 passes over the supplied corpus of 151 documents, updating model once every 151 documents, evaluating perplexity every 151 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2017-11-20 21:21:02,463 : INFO : -19.307 per-word bound, 648632.5 perplexity estimate based on a held-out corpus of 151 documents with 163809 words\n",
      "2017-11-20 21:21:02,464 : INFO : PROGRESS: pass 0, at document #151/151\n",
      "2017-11-20 21:21:04,504 : INFO : topic #21 (0.010): 0.005*\"&\" + 0.004*\"r\" + 0.004*\"state\" + 0.003*\"margin\" + 0.003*\"curve\" + 0.003*\"component\" + 0.003*\"signal\" + 0.003*\"training\" + 0.003*\"cell\" + 0.003*\"control\"\n",
      "2017-11-20 21:21:04,505 : INFO : topic #5 (0.010): 0.008*\"training\" + 0.006*\"synaptic\" + 0.004*\"&\" + 0.004*\"state\" + 0.003*\"synapsis\" + 0.003*\"neuron\" + 0.003*\"mixture\" + 0.003*\"policy\" + 0.003*\"gaussian\" + 0.003*\"prior\"\n",
      "2017-11-20 21:21:04,506 : INFO : topic #68 (0.010): 0.005*\"state\" + 0.005*\"approximation\" + 0.004*\"training\" + 0.003*\"component\" + 0.003*\"image\" + 0.003*\"field\" + 0.003*\"cell\" + 0.003*\"noise\" + 0.003*\"dynamic\" + 0.002*\"control\"\n",
      "2017-11-20 21:21:04,508 : INFO : topic #99 (0.010): 0.008*\"image\" + 0.005*\"training\" + 0.004*\"rule\" + 0.004*\"noise\" + 0.004*\"distance\" + 0.003*\"curve\" + 0.003*\"digit\" + 0.003*\"mixture\" + 0.003*\"component\" + 0.003*\"class\"\n",
      "2017-11-20 21:21:04,509 : INFO : topic #24 (0.010): 0.005*\"state\" + 0.005*\"component\" + 0.005*\"distance\" + 0.004*\"image\" + 0.004*\"gaussian\" + 0.004*\"independent\" + 0.003*\"training\" + 0.003*\"w\" + 0.003*\"graph\" + 0.003*\"mixture\"\n",
      "2017-11-20 21:21:04,513 : INFO : topic diff=11.329132, rho=1.000000\n",
      "2017-11-20 21:21:10,840 : INFO : -13.964 per-word bound, 15982.2 perplexity estimate based on a held-out corpus of 151 documents with 163809 words\n",
      "2017-11-20 21:21:10,841 : INFO : PROGRESS: pass 1, at document #151/151\n",
      "2017-11-20 21:21:12,755 : INFO : topic #98 (0.010): 0.009*\"synaptic\" + 0.007*\"&\" + 0.005*\"cell\" + 0.004*\"neuron\" + 0.004*\"rate\" + 0.003*\"firing\" + 0.003*\"distance\" + 0.003*\"response\" + 0.003*\"image\" + 0.003*\"labeled\"\n",
      "2017-11-20 21:21:12,757 : INFO : topic #42 (0.010): 0.006*\"state\" + 0.005*\"image\" + 0.004*\"rate\" + 0.003*\"visual\" + 0.003*\"training\" + 0.003*\"density\" + 0.003*\"noise\" + 0.003*\"gaussian\" + 0.003*\"neuron\" + 0.003*\"sound\"\n",
      "2017-11-20 21:21:12,758 : INFO : topic #51 (0.010): 0.018*\"conditional\" + 0.015*\"likelihood\" + 0.012*\"gate\" + 0.012*\"bound\" + 0.009*\"q\" + 0.009*\"mixture\" + 0.008*\"em\" + 0.008*\"maximum\" + 0.008*\"density\" + 0.007*\"expert\"\n",
      "2017-11-20 21:21:12,759 : INFO : topic #77 (0.010): 0.006*\"search\" + 0.005*\"image\" + 0.005*\"state\" + 0.004*\"visual\" + 0.004*\"local\" + 0.004*\"analog\" + 0.003*\"kernel\" + 0.003*\"classifier\" + 0.003*\"cell\" + 0.003*\"gaussian\"\n",
      "2017-11-20 21:21:12,761 : INFO : topic #70 (0.010): 0.008*\"state\" + 0.005*\"cell\" + 0.004*\"&\" + 0.004*\"bound\" + 0.004*\"synaptic\" + 0.003*\"mixture\" + 0.003*\"neuron\" + 0.003*\"policy\" + 0.003*\"goal\" + 0.003*\"part\"\n",
      "2017-11-20 21:21:12,767 : INFO : topic diff=8.389327, rho=0.577350\n",
      "2017-11-20 21:21:18,248 : INFO : -11.786 per-word bound, 3531.7 perplexity estimate based on a held-out corpus of 151 documents with 163809 words\n",
      "2017-11-20 21:21:18,249 : INFO : PROGRESS: pass 2, at document #151/151\n",
      "2017-11-20 21:21:19,867 : INFO : topic #34 (0.010): 0.040*\"latent\" + 0.026*\"kernel\" + 0.008*\"principal\" + 0.007*\"constraint\" + 0.007*\"basis\" + 0.007*\"rbf\" + 0.007*\"radial\" + 0.007*\"pdf\" + 0.006*\"space.\" + 0.006*\"mixture\"\n",
      "2017-11-20 21:21:19,868 : INFO : topic #92 (0.010): 0.019*\"state\" + 0.014*\"approximation\" + 0.012*\"control\" + 0.007*\"mode\" + 0.007*\"trained\" + 0.007*\"fisher\" + 0.007*\"dynamic\" + 0.007*\"approximate\" + 0.007*\"mixture\" + 0.007*\"physical\"\n",
      "2017-11-20 21:21:19,869 : INFO : topic #2 (0.010): 0.034*\"tree\" + 0.017*\"node\" + 0.016*\"image\" + 0.013*\"posterior\" + 0.013*\"prior\" + 0.013*\"balanced\" + 0.010*\"dynamic\" + 0.009*\"parent\" + 0.008*\"structure\" + 0.008*\"dt\"\n",
      "2017-11-20 21:21:19,871 : INFO : topic #38 (0.010): 0.025*\"analog\" + 0.018*\"net\" + 0.015*\"noise\" + 0.015*\"language\" + 0.013*\"w\" + 0.012*\"state\" + 0.012*\"measure\" + 0.012*\"l\" + 0.009*\"gaussian\" + 0.009*\"theorem\"\n",
      "2017-11-20 21:21:19,873 : INFO : topic #51 (0.010): 0.040*\"conditional\" + 0.027*\"bound\" + 0.026*\"likelihood\" + 0.021*\"gate\" + 0.020*\"em\" + 0.015*\"joint\" + 0.015*\"density\" + 0.014*\"mixture\" + 0.013*\"q\" + 0.013*\"expert\"\n",
      "2017-11-20 21:21:19,877 : INFO : topic diff=9.215757, rho=0.500000\n",
      "2017-11-20 21:21:24,877 : INFO : -10.594 per-word bound, 1545.3 perplexity estimate based on a held-out corpus of 151 documents with 163809 words\n",
      "2017-11-20 21:21:24,878 : INFO : PROGRESS: pass 3, at document #151/151\n",
      "2017-11-20 21:21:26,323 : INFO : topic #4 (0.010): 0.016*\"noise\" + 0.012*\"fig.\" + 0.011*\"cell\" + 0.010*\"image\" + 0.010*\"delay\" + 0.010*\"pixel\" + 0.009*\"complex\" + 0.008*\"current\" + 0.007*\"channel\" + 0.007*\"source\"\n",
      "2017-11-20 21:21:26,324 : INFO : topic #12 (0.010): 0.018*\"mass\" + 0.015*\"architecture\" + 0.014*\"positive\" + 0.014*\"detection\" + 0.013*\"%\" + 0.010*\"resolution\" + 0.010*\"false\" + 0.009*\"pixel\" + 0.009*\"unit\" + 0.009*\"low\"\n",
      "2017-11-20 21:21:26,325 : INFO : topic #77 (0.010): 0.005*\"search\" + 0.004*\"image\" + 0.004*\"state\" + 0.004*\"visual\" + 0.003*\"local\" + 0.003*\"analog\" + 0.003*\"kernel\" + 0.002*\"classifier\" + 0.002*\"cell\" + 0.002*\"gaussian\"\n",
      "2017-11-20 21:21:26,327 : INFO : topic #86 (0.010): 0.005*\"sensor\" + 0.004*\"field\" + 0.004*\"image\" + 0.004*\"gaussian\" + 0.004*\"noise\" + 0.004*\"visual\" + 0.004*\"motion\" + 0.004*\"local\" + 0.004*\"binary\" + 0.003*\"flow\"\n",
      "2017-11-20 21:21:26,328 : INFO : topic #83 (0.010): 0.026*\"front\" + 0.022*\"field\" + 0.014*\"latent\" + 0.013*\"along\" + 0.012*\"discontinuity\" + 0.010*\"covariance\" + 0.010*\"sample\" + 0.009*\"convolution\" + 0.009*\"posterior\" + 0.008*\"constrained\"\n",
      "2017-11-20 21:21:26,332 : INFO : topic diff=9.202573, rho=0.447214\n",
      "2017-11-20 21:21:31,710 : INFO : -9.822 per-word bound, 905.2 perplexity estimate based on a held-out corpus of 151 documents with 163809 words\n",
      "2017-11-20 21:21:31,711 : INFO : PROGRESS: pass 4, at document #151/151\n",
      "2017-11-20 21:21:33,244 : INFO : topic #6 (0.010): 0.003*\"state\" + 0.002*\"direction\" + 0.002*\"population\" + 0.002*\"cell\" + 0.002*\"task\" + 0.002*\"training\" + 0.002*\"&\" + 0.002*\"subject\" + 0.002*\"agent\" + 0.002*\"visual\"\n",
      "2017-11-20 21:21:33,246 : INFO : topic #86 (0.010): 0.005*\"sensor\" + 0.004*\"image\" + 0.004*\"gaussian\" + 0.004*\"noise\" + 0.004*\"local\" + 0.004*\"binary\" + 0.004*\"field\" + 0.004*\"visual\" + 0.004*\"motion\" + 0.003*\"correlation\"\n",
      "2017-11-20 21:21:33,247 : INFO : topic #59 (0.010): 0.025*\"training\" + 0.020*\"class\" + 0.019*\"during\" + 0.016*\"discrimination\" + 0.015*\"threshold\" + 0.013*\"curve\" + 0.012*\"range\" + 0.012*\"rate\" + 0.011*\"target\" + 0.011*\"node\"\n",
      "2017-11-20 21:21:33,248 : INFO : topic #79 (0.010): 0.019*\"forward\" + 0.018*\"motor\" + 0.017*\"module\" + 0.017*\"object\" + 0.015*\"inverse\" + 0.014*\"multiple\" + 0.012*\"control\" + 0.011*\"architecture\" + 0.010*\"signal\" + 0.008*\"layer\"\n",
      "2017-11-20 21:21:33,250 : INFO : topic #96 (0.010): 0.029*\"segment\" + 0.028*\"classifier\" + 0.018*\"image\" + 0.015*\"people\" + 0.014*\">\" + 0.013*\"projected\" + 0.013*\"body\" + 0.011*\"configuration\" + 0.010*\"node\" + 0.009*\"positive\"\n",
      "2017-11-20 21:21:33,253 : INFO : topic diff=8.571042, rho=0.408248\n",
      "2017-11-20 21:21:39,936 : INFO : -9.309 per-word bound, 634.4 perplexity estimate based on a held-out corpus of 151 documents with 163809 words\n",
      "2017-11-20 21:21:39,938 : INFO : PROGRESS: pass 5, at document #151/151\n",
      "2017-11-20 21:21:41,618 : INFO : topic #61 (0.010): 0.032*\"entropic\" + 0.021*\"entropy\" + 0.020*\"oi\" + 0.019*\"estimator\" + 0.014*\"state\" + 0.013*\"map\" + 0.012*\"murphy,\" + 0.010*\"model's\" + 0.010*\"pruning\" + 0.010*\"discovery\"\n",
      "2017-11-20 21:21:41,620 : INFO : topic #85 (0.010): 0.003*\"training\" + 0.003*\"bound\" + 0.003*\"image\" + 0.002*\"rule\" + 0.002*\"state\" + 0.002*\"class\" + 0.002*\"node\" + 0.002*\"noise\" + 0.002*\"unit\" + 0.001*\"code\"\n",
      "2017-11-20 21:21:41,621 : INFO : topic #55 (0.010): 0.003*\"image\" + 0.002*\"state\" + 0.002*\"unit\" + 0.002*\"spike\" + 0.002*\"cell\" + 0.002*\"mixture\" + 0.002*\"hidden\" + 0.002*\"flow\" + 0.002*\"component\" + 0.002*\"em\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-11-20 21:21:41,623 : INFO : topic #89 (0.010): 0.002*\"training\" + 0.002*\"image\" + 0.001*\"control\" + 0.001*\"&\" + 0.001*\"gaussian\" + 0.001*\"state\" + 0.001*\"transformation\" + 0.001*\"dynamic\" + 0.001*\"prior\" + 0.001*\"transition\"\n",
      "2017-11-20 21:21:41,624 : INFO : topic #52 (0.010): 0.020*\"state\" + 0.009*\"call\" + 0.008*\"convergence\" + 0.006*\"rl\" + 0.006*\"rate\" + 0.006*\"control\" + 0.006*\"policy\" + 0.006*\"reinforcement\" + 0.006*\"reward\" + 0.005*\"node\"\n",
      "2017-11-20 21:21:41,628 : INFO : topic diff=7.593844, rho=0.377964\n",
      "2017-11-20 21:21:47,532 : INFO : -8.965 per-word bound, 499.7 perplexity estimate based on a held-out corpus of 151 documents with 163809 words\n",
      "2017-11-20 21:21:47,533 : INFO : PROGRESS: pass 6, at document #151/151\n",
      "2017-11-20 21:21:49,035 : INFO : topic #60 (0.010): 0.046*\"gaussian\" + 0.044*\"predictor\" + 0.036*\"regression\" + 0.024*\"lemma\" + 0.019*\"i.\" + 0.016*\"di\" + 0.016*\"bayesian\" + 0.015*\"e\" + 0.014*\"opper\" + 0.014*\"h\"\n",
      "2017-11-20 21:21:49,036 : INFO : topic #21 (0.010): 0.002*\"&\" + 0.002*\"r\" + 0.002*\"state\" + 0.002*\"margin\" + 0.002*\"curve\" + 0.002*\"component\" + 0.002*\"signal\" + 0.001*\"training\" + 0.001*\"cell\" + 0.001*\"control\"\n",
      "2017-11-20 21:21:49,037 : INFO : topic #35 (0.010): 0.002*\"image\" + 0.002*\"direction\" + 0.001*\"kernel\" + 0.001*\"training\" + 0.001*\"visual\" + 0.001*\"response\" + 0.001*\"motion\" + 0.001*\"bound\" + 0.001*\"population\" + 0.001*\"cell\"\n",
      "2017-11-20 21:21:49,038 : INFO : topic #81 (0.010): 0.060*\"spike\" + 0.031*\"transfer\" + 0.016*\"cell\" + 0.014*\"complex\" + 0.013*\"ratio\" + 0.012*\"frequency\" + 0.012*\"clustering\" + 0.011*\"shape\" + 0.010*\"cluster\" + 0.010*\"spectrum\"\n",
      "2017-11-20 21:21:49,040 : INFO : topic #47 (0.010): 0.023*\"clustering\" + 0.019*\"aspect\" + 0.012*\"latent\" + 0.011*\"em\" + 0.011*\"mixture\" + 0.010*\"32\" + 0.009*\":\" + 0.009*\"!\" + 0.009*\"class\" + 0.008*\"observation\"\n",
      "2017-11-20 21:21:49,044 : INFO : topic diff=6.495204, rho=0.353553\n",
      "2017-11-20 21:21:54,063 : INFO : -8.732 per-word bound, 425.2 perplexity estimate based on a held-out corpus of 151 documents with 163809 words\n",
      "2017-11-20 21:21:54,064 : INFO : PROGRESS: pass 7, at document #151/151\n",
      "2017-11-20 21:21:55,697 : INFO : topic #22 (0.010): 0.002*\"control\" + 0.001*\"noise\" + 0.001*\"signal\" + 0.001*\"change\" + 0.001*\"positive\" + 0.001*\"controller\" + 0.001*\"rate\" + 0.001*\"neuron\" + 0.001*\"firing\" + 0.001*\"feedback\"\n",
      "2017-11-20 21:21:55,698 : INFO : topic #72 (0.010): 0.011*\"visual\" + 0.009*\"distance\" + 0.007*\"search\" + 0.007*\"state\" + 0.006*\"ei\" + 0.006*\"fig.\" + 0.006*\"target\" + 0.005*\"environment\" + 0.005*\"v1\" + 0.004*\"bar\"\n",
      "2017-11-20 21:21:55,699 : INFO : topic #83 (0.010): 0.033*\"front\" + 0.028*\"field\" + 0.016*\"along\" + 0.015*\"discontinuity\" + 0.013*\"covariance\" + 0.011*\"constrained\" + 0.010*\"posterior\" + 0.010*\"sample\" + 0.009*\"prior\" + 0.009*\"(b)\"\n",
      "2017-11-20 21:21:55,700 : INFO : topic #61 (0.010): 0.058*\"entropic\" + 0.037*\"entropy\" + 0.035*\"estimator\" + 0.034*\"oi\" + 0.022*\"map\" + 0.017*\"state\" + 0.015*\"murphy,\" + 0.014*\"discovery\" + 0.014*\"pruning\" + 0.014*\"model's\"\n",
      "2017-11-20 21:21:55,702 : INFO : topic #21 (0.010): 0.002*\"&\" + 0.002*\"r\" + 0.001*\"state\" + 0.001*\"margin\" + 0.001*\"curve\" + 0.001*\"component\" + 0.001*\"signal\" + 0.001*\"training\" + 0.001*\"cell\" + 0.001*\"control\"\n",
      "2017-11-20 21:21:55,706 : INFO : topic diff=5.419982, rho=0.333333\n",
      "2017-11-20 21:22:01,081 : INFO : -8.573 per-word bound, 380.8 perplexity estimate based on a held-out corpus of 151 documents with 163809 words\n",
      "2017-11-20 21:22:01,082 : INFO : PROGRESS: pass 8, at document #151/151\n",
      "2017-11-20 21:22:02,539 : INFO : topic #9 (0.010): 0.094*\"similarity\" + 0.079*\"matching\" + 0.040*\"measure\" + 0.039*\"probabilistic\" + 0.034*\"subspace\" + 0.030*\"variation\" + 0.030*\"recognition\" + 0.026*\"image\" + 0.022*\"intensity\" + 0.017*\"normalized\"\n",
      "2017-11-20 21:22:02,540 : INFO : topic #11 (0.010): 0.042*\"sparse\" + 0.023*\"code\" + 0.021*\"component\" + 0.020*\"coding\" + 0.019*\"density\" + 0.019*\"shrinkage\" + 0.015*\"image\" + 0.011*\"noise\" + 0.010*\"gaussian\" + 0.008*\"estimation\"\n",
      "2017-11-20 21:22:02,541 : INFO : topic #5 (0.010): 0.044*\"synaptic\" + 0.027*\"synapsis\" + 0.017*\"prior\" + 0.015*\"modification\" + 0.014*\"pruning\" + 0.014*\"memory\" + 0.012*\"neuronal\" + 0.009*\"level\" + 0.009*\"gaussians\" + 0.009*\"mixture\"\n",
      "2017-11-20 21:22:02,543 : INFO : topic #52 (0.010): 0.021*\"state\" + 0.010*\"call\" + 0.008*\"convergence\" + 0.007*\"control\" + 0.007*\"rl\" + 0.006*\"rate\" + 0.006*\"reinforcement\" + 0.006*\"policy\" + 0.005*\"node\" + 0.005*\"reward\"\n",
      "2017-11-20 21:22:02,544 : INFO : topic #70 (0.010): 0.002*\"state\" + 0.001*\"cell\" + 0.001*\"&\" + 0.001*\"bound\" + 0.001*\"synaptic\" + 0.001*\"mixture\" + 0.001*\"neuron\" + 0.001*\"policy\" + 0.001*\"goal\" + 0.001*\"part\"\n",
      "2017-11-20 21:22:02,548 : INFO : topic diff=4.445492, rho=0.316228\n",
      "2017-11-20 21:22:07,857 : INFO : -8.463 per-word bound, 352.9 perplexity estimate based on a held-out corpus of 151 documents with 163809 words\n",
      "2017-11-20 21:22:07,858 : INFO : PROGRESS: pass 9, at document #151/151\n",
      "2017-11-20 21:22:09,402 : INFO : topic #46 (0.010): 0.002*\"neuron\" + 0.001*\"firing\" + 0.001*\"&\" + 0.001*\"visual\" + 0.001*\"correlation\" + 0.001*\"z\" + 0.001*\"layer\" + 0.001*\"spike\" + 0.001*\"image\" + 0.001*\"positive\"\n",
      "2017-11-20 21:22:09,403 : INFO : topic #79 (0.010): 0.022*\"forward\" + 0.021*\"motor\" + 0.019*\"object\" + 0.019*\"module\" + 0.019*\"inverse\" + 0.016*\"multiple\" + 0.016*\"control\" + 0.013*\"architecture\" + 0.011*\"signal\" + 0.009*\"variational\"\n",
      "2017-11-20 21:22:09,404 : INFO : topic #91 (0.010): 0.019*\"visual\" + 0.017*\"centroid\" + 0.015*\"edge\" + 0.012*\"attention\" + 0.009*\"orientation\" + 0.009*\"contrast\" + 0.008*\"task\" + 0.008*\"q-\" + 0.007*\"circuit\" + 0.007*\"stage\"\n",
      "2017-11-20 21:22:09,406 : INFO : topic #39 (0.010): 0.023*\"curve\" + 0.012*\"principal\" + 0.010*\"neuron\" + 0.009*\"h\" + 0.008*\"line\" + 0.008*\"utility\" + 0.006*\"vertex\" + 0.006*\"segment\" + 0.006*\"node\" + 0.006*\"squared\"\n",
      "2017-11-20 21:22:09,407 : INFO : topic #82 (0.010): 0.064*\"loss\" + 0.024*\"threshold\" + 0.023*\"classification\" + 0.018*\"bound\" + 0.018*\"perceptron\" + 0.016*\"update\" + 0.013*\"gradient\" + 0.013*\"regression\" + 0.012*\"divergence\" + 0.012*\"matching\"\n",
      "2017-11-20 21:22:09,411 : INFO : topic diff=3.603490, rho=0.301511\n",
      "2017-11-20 21:22:14,289 : INFO : -8.386 per-word bound, 334.6 perplexity estimate based on a held-out corpus of 151 documents with 163809 words\n",
      "2017-11-20 21:22:14,290 : INFO : PROGRESS: pass 10, at document #151/151\n",
      "2017-11-20 21:22:15,838 : INFO : topic #4 (0.010): 0.018*\"noise\" + 0.013*\"cell\" + 0.012*\"fig.\" + 0.010*\"delay\" + 0.010*\"pixel\" + 0.009*\"image\" + 0.009*\"source\" + 0.009*\"complex\" + 0.008*\"current\" + 0.008*\"&\"\n",
      "2017-11-20 21:22:15,840 : INFO : topic #3 (0.010): 0.007*\"gaussian\" + 0.007*\"training\" + 0.006*\"kernel\" + 0.005*\"pca\" + 0.004*\"distance\" + 0.004*\"component\" + 0.004*\"classification\" + 0.004*\"data.\" + 0.004*\"z\" + 0.004*\"p\"\n",
      "2017-11-20 21:22:15,841 : INFO : topic #97 (0.010): 0.126*\"cell\" + 0.033*\"modulated\" + 0.016*\"frequency\" + 0.015*\"complex\" + 0.014*\"manner.\" + 0.014*\"2).\" + 0.013*\"spatial\" + 0.013*\"k.,\" + 0.009*\"function,\" + 0.008*\"mixture\"\n",
      "2017-11-20 21:22:15,843 : INFO : topic #77 (0.010): 0.001*\"search\" + 0.001*\"image\" + 0.001*\"state\" + 0.001*\"visual\" + 0.001*\"local\" + 0.001*\"analog\" + 0.001*\"kernel\" + 0.001*\"classifier\" + 0.001*\"cell\" + 0.001*\"gaussian\"\n",
      "2017-11-20 21:22:15,844 : INFO : topic #16 (0.010): 0.024*\"analog\" + 0.023*\"convolution\" + 0.022*\"chip\" + 0.020*\"impulse\" + 0.020*\"noise\" + 0.018*\"signal\" + 0.014*\"cell\" + 0.013*\"polynomial\" + 0.011*\"ratio\" + 0.011*\"speed\"\n",
      "2017-11-20 21:22:15,847 : INFO : topic diff=2.898141, rho=0.288675\n",
      "2017-11-20 21:22:21,260 : INFO : -8.332 per-word bound, 322.2 perplexity estimate based on a held-out corpus of 151 documents with 163809 words\n",
      "2017-11-20 21:22:21,261 : INFO : PROGRESS: pass 11, at document #151/151\n",
      "2017-11-20 21:22:23,011 : INFO : topic #43 (0.010): 0.015*\"local\" + 0.010*\"field\" + 0.007*\"contour\" + 0.006*\"prediction\" + 0.006*\"mutual\" + 0.006*\"bound\" + 0.005*\"square\" + 0.005*\"<\" + 0.005*\"p\" + 0.005*\"gaussian\"\n",
      "2017-11-20 21:22:23,012 : INFO : topic #14 (0.010): 0.025*\"conductance\" + 0.022*\"firing\" + 0.022*\"rate\" + 0.021*\"cell\" + 0.015*\"mutual\" + 0.015*\"neuron\" + 0.014*\"stimulus\" + 0.011*\"among\" + 0.010*\"spike\" + 0.009*\"change\"\n",
      "2017-11-20 21:22:23,013 : INFO : topic #28 (0.010): 0.060*\"hmm\" + 0.028*\"emission\" + 0.028*\"regularization\" + 0.025*\"training\" + 0.020*\"mixture\" + 0.017*\"prototype\" + 0.017*\"speech\" + 0.017*\"discrete\" + 0.013*\"state\" + 0.013*\"complexity\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-11-20 21:22:23,015 : INFO : topic #97 (0.010): 0.144*\"cell\" + 0.037*\"modulated\" + 0.018*\"frequency\" + 0.016*\"manner.\" + 0.015*\"2).\" + 0.014*\"complex\" + 0.013*\"k.,\" + 0.012*\"spatial\" + 0.009*\"function,\" + 0.009*\"mixture\"\n",
      "2017-11-20 21:22:23,017 : INFO : topic #1 (0.010): 0.029*\"hand\" + 0.025*\"control\" + 0.022*\"inverse\" + 0.022*\"position\" + 0.022*\"feedback\" + 0.021*\"movement\" + 0.019*\"arm\" + 0.018*\"forward\" + 0.016*\"desired\" + 0.015*\"controller\"\n",
      "2017-11-20 21:22:23,021 : INFO : topic diff=2.319572, rho=0.277350\n",
      "2017-11-20 21:22:30,326 : INFO : -8.292 per-word bound, 313.4 perplexity estimate based on a held-out corpus of 151 documents with 163809 words\n",
      "2017-11-20 21:22:30,330 : INFO : PROGRESS: pass 12, at document #151/151\n",
      "2017-11-20 21:22:32,484 : INFO : topic #3 (0.010): 0.007*\"training\" + 0.006*\"gaussian\" + 0.006*\"kernel\" + 0.005*\"pca\" + 0.005*\"distance\" + 0.004*\"p\" + 0.004*\"classification\" + 0.004*\"w\" + 0.004*\"data.\" + 0.004*\"z\"\n",
      "2017-11-20 21:22:32,493 : INFO : topic #4 (0.010): 0.018*\"noise\" + 0.013*\"cell\" + 0.012*\"fig.\" + 0.010*\"delay\" + 0.010*\"pixel\" + 0.009*\"source\" + 0.009*\"image\" + 0.009*\"complex\" + 0.008*\"&\" + 0.008*\"current\"\n",
      "2017-11-20 21:22:32,495 : INFO : topic #86 (0.010): 0.006*\"sensor\" + 0.005*\"image\" + 0.005*\"noise\" + 0.005*\"binary\" + 0.004*\"correlation\" + 0.004*\"gaussian\" + 0.004*\"local\" + 0.003*\"p\" + 0.003*\"r\" + 0.003*\"line\"\n",
      "2017-11-20 21:22:32,496 : INFO : topic #74 (0.010): 0.019*\"kernel\" + 0.011*\"search\" + 0.011*\"local\" + 0.008*\"sample\" + 0.008*\"mixture\" + 0.006*\"bound\" + 0.006*\"instance\" + 0.006*\"cost\" + 0.005*\"level\" + 0.004*\"object\"\n",
      "2017-11-20 21:22:32,503 : INFO : topic #82 (0.010): 0.067*\"loss\" + 0.025*\"threshold\" + 0.023*\"classification\" + 0.018*\"bound\" + 0.018*\"perceptron\" + 0.017*\"update\" + 0.013*\"gradient\" + 0.013*\"regression\" + 0.012*\"divergence\" + 0.012*\"relative\"\n",
      "2017-11-20 21:22:32,516 : INFO : topic diff=1.852081, rho=0.267261\n",
      "2017-11-20 21:22:40,206 : INFO : -8.262 per-word bound, 307.1 perplexity estimate based on a held-out corpus of 151 documents with 163809 words\n",
      "2017-11-20 21:22:40,207 : INFO : PROGRESS: pass 13, at document #151/151\n",
      "2017-11-20 21:22:42,507 : INFO : topic #30 (0.010): 0.000*\"image\" + 0.000*\"<\" + 0.000*\"training\" + 0.000*\"approximation\" + 0.000*\"state\" + 0.000*\"8\" + 0.000*\"filter\" + 0.000*\"24\" + 0.000*\"&\" + 0.000*\"rate\"\n",
      "2017-11-20 21:22:42,509 : INFO : topic #52 (0.010): 0.022*\"state\" + 0.010*\"call\" + 0.008*\"control\" + 0.007*\"convergence\" + 0.007*\"rl\" + 0.006*\"rate\" + 0.006*\"node\" + 0.006*\"reinforcement\" + 0.006*\"v\" + 0.006*\"policy\"\n",
      "2017-11-20 21:22:42,511 : INFO : topic #32 (0.010): 0.062*\"sound\" + 0.025*\"signal\" + 0.022*\"circuit\" + 0.018*\"pulse\" + 0.017*\"delay\" + 0.015*\"surface\" + 0.015*\"onset\" + 0.014*\"source\" + 0.012*\"threshold\" + 0.012*\"generating\"\n",
      "2017-11-20 21:22:42,513 : INFO : topic #79 (0.010): 0.023*\"forward\" + 0.021*\"motor\" + 0.020*\"object\" + 0.020*\"inverse\" + 0.020*\"module\" + 0.017*\"control\" + 0.016*\"multiple\" + 0.013*\"architecture\" + 0.011*\"signal\" + 0.011*\"variational\"\n",
      "2017-11-20 21:22:42,514 : INFO : topic #55 (0.010): 0.000*\"image\" + 0.000*\"state\" + 0.000*\"unit\" + 0.000*\"spike\" + 0.000*\"cell\" + 0.000*\"mixture\" + 0.000*\"hidden\" + 0.000*\"flow\" + 0.000*\"component\" + 0.000*\"em\"\n",
      "2017-11-20 21:22:42,519 : INFO : topic diff=1.478153, rho=0.258199\n",
      "2017-11-20 21:22:51,028 : INFO : -8.240 per-word bound, 302.4 perplexity estimate based on a held-out corpus of 151 documents with 163809 words\n",
      "2017-11-20 21:22:51,030 : INFO : PROGRESS: pass 14, at document #151/151\n",
      "2017-11-20 21:22:53,351 : INFO : topic #34 (0.010): 0.161*\"latent\" + 0.049*\"principal\" + 0.043*\"component\" + 0.029*\"sample\" + 0.025*\"bishop\" + 0.023*\"basis\" + 0.023*\"w\" + 0.021*\"kernel\" + 0.021*\"nonlinear\" + 0.019*\"radial\"\n",
      "2017-11-20 21:22:53,352 : INFO : topic #41 (0.010): 0.000*\"state\" + 0.000*\"rule\" + 0.000*\"neuron\" + 0.000*\"noise\" + 0.000*\"training\" + 0.000*\"forward\" + 0.000*\"motor\" + 0.000*\"bound\" + 0.000*\"path\" + 0.000*\"action\"\n",
      "2017-11-20 21:22:53,354 : INFO : topic #60 (0.010): 0.095*\"gaussian\" + 0.050*\"regression\" + 0.041*\"bound\" + 0.038*\"bayesian\" + 0.036*\"generalization\" + 0.035*\"prediction\" + 0.033*\"predictor\" + 0.031*\"i.\" + 0.028*\"covariance\" + 0.025*\"curve\"\n",
      "2017-11-20 21:22:53,355 : INFO : topic #76 (0.010): 0.073*\"flow\" + 0.054*\"optical\" + 0.046*\"motion\" + 0.040*\"field\" + 0.039*\"chip\" + 0.020*\"sensor\" + 0.018*\"analog\" + 0.018*\"pixel\" + 0.018*\"computation\" + 0.015*\"current\"\n",
      "2017-11-20 21:22:53,357 : INFO : topic #44 (0.010): 0.023*\"regression\" + 0.022*\"adaptive\" + 0.018*\"support\" + 0.015*\"parametric\" + 0.014*\"sv\" + 0.013*\"constraint\" + 0.012*\"regularization\" + 0.012*\"fraction\" + 0.012*\"quadratic\" + 0.010*\"nonparametric\"\n",
      "2017-11-20 21:22:53,362 : INFO : topic diff=1.181266, rho=0.250000\n",
      "2017-11-20 21:23:00,928 : INFO : -8.223 per-word bound, 298.7 perplexity estimate based on a held-out corpus of 151 documents with 163809 words\n",
      "2017-11-20 21:23:00,929 : INFO : PROGRESS: pass 15, at document #151/151\n",
      "2017-11-20 21:23:02,677 : INFO : topic #30 (0.010): 0.000*\"image\" + 0.000*\"<\" + 0.000*\"training\" + 0.000*\"approximation\" + 0.000*\"state\" + 0.000*\"8\" + 0.000*\"filter\" + 0.000*\"24\" + 0.000*\"&\" + 0.000*\"rate\"\n",
      "2017-11-20 21:23:02,678 : INFO : topic #65 (0.010): 0.032*\"state\" + 0.022*\"action\" + 0.019*\"search\" + 0.018*\"goal\" + 0.013*\"v\" + 0.011*\"environment\" + 0.010*\"policy\" + 0.009*\"planning\" + 0.009*\"reinforcement\" + 0.007*\"singh,\"\n",
      "2017-11-20 21:23:02,680 : INFO : topic #36 (0.010): 0.000*\"training\" + 0.000*\"state\" + 0.000*\"binary\" + 0.000*\"rule\" + 0.000*\"control\" + 0.000*\"forward\" + 0.000*\"correlation\" + 0.000*\"node\" + 0.000*\"kernel\" + 0.000*\"inverse\"\n",
      "2017-11-20 21:23:02,681 : INFO : topic #38 (0.010): 0.036*\"analog\" + 0.024*\"net\" + 0.020*\"language\" + 0.019*\"noise\" + 0.018*\"w\" + 0.016*\"measure\" + 0.016*\"l\" + 0.014*\"state\" + 0.013*\"theorem\" + 0.012*\"gaussian\"\n",
      "2017-11-20 21:23:02,683 : INFO : topic #14 (0.010): 0.026*\"conductance\" + 0.022*\"firing\" + 0.022*\"rate\" + 0.021*\"cell\" + 0.015*\"mutual\" + 0.015*\"neuron\" + 0.014*\"stimulus\" + 0.011*\"among\" + 0.010*\"spike\" + 0.009*\"change\"\n",
      "2017-11-20 21:23:02,688 : INFO : topic diff=0.946466, rho=0.242536\n",
      "2017-11-20 21:23:09,400 : INFO : -8.209 per-word bound, 295.9 perplexity estimate based on a held-out corpus of 151 documents with 163809 words\n",
      "2017-11-20 21:23:09,401 : INFO : PROGRESS: pass 16, at document #151/151\n",
      "2017-11-20 21:23:11,095 : INFO : topic #20 (0.010): 0.035*\"policy\" + 0.018*\"state\" + 0.014*\"reward\" + 0.013*\"transition\" + 0.011*\"rl\" + 0.011*\"block\" + 0.011*\"stochastic\" + 0.011*\"reinforcement\" + 0.010*\"a)\" + 0.009*\"every\"\n",
      "2017-11-20 21:23:11,096 : INFO : topic #99 (0.010): 0.001*\"rule\" + 0.000*\"image\" + 0.000*\"classifier\" + 0.000*\"training\" + 0.000*\"distance\" + 0.000*\"noise\" + 0.000*\"d\" + 0.000*\"face\" + 0.000*\"sensor\" + 0.000*\"principal\"\n",
      "2017-11-20 21:23:11,097 : INFO : topic #76 (0.010): 0.071*\"flow\" + 0.054*\"optical\" + 0.047*\"motion\" + 0.039*\"field\" + 0.039*\"chip\" + 0.020*\"sensor\" + 0.019*\"analog\" + 0.018*\"pixel\" + 0.018*\"computation\" + 0.015*\"current\"\n",
      "2017-11-20 21:23:11,099 : INFO : topic #37 (0.010): 0.000*\"cell\" + 0.000*\"neuron\" + 0.000*\"complex\" + 0.000*\"cortical\" + 0.000*\"spatial\" + 0.000*\"&\" + 0.000*\"density\" + 0.000*\"recurrent\" + 0.000*\"state\" + 0.000*\"response\"\n",
      "2017-11-20 21:23:11,101 : INFO : topic #28 (0.010): 0.060*\"hmm\" + 0.028*\"regularization\" + 0.027*\"emission\" + 0.026*\"training\" + 0.020*\"mixture\" + 0.017*\"prototype\" + 0.017*\"discrete\" + 0.016*\"speech\" + 0.014*\"state\" + 0.013*\"complexity\"\n",
      "2017-11-20 21:23:11,106 : INFO : topic diff=0.761219, rho=0.235702\n",
      "2017-11-20 21:23:18,497 : INFO : -8.197 per-word bound, 293.6 perplexity estimate based on a held-out corpus of 151 documents with 163809 words\n",
      "2017-11-20 21:23:18,499 : INFO : PROGRESS: pass 17, at document #151/151\n",
      "2017-11-20 21:23:20,944 : INFO : topic #62 (0.010): 0.027*\"face\" + 0.023*\"image\" + 0.022*\"labeled\" + 0.019*\"density\" + 0.017*\"prior\" + 0.016*\"estimation\" + 0.015*\"training\" + 0.013*\"dependency\" + 0.010*\"data.\" + 0.009*\"bayesian\"\n",
      "2017-11-20 21:23:20,945 : INFO : topic #49 (0.010): 0.024*\"activity\" + 0.020*\"cortical\" + 0.019*\"noise\" + 0.018*\"variance\" + 0.017*\"line\" + 0.016*\"normalization\" + 0.016*\"spatial\" + 0.015*\"unit\" + 0.015*\"attractor\" + 0.015*\"ideal\"\n",
      "2017-11-20 21:23:20,949 : INFO : topic #89 (0.010): 0.000*\"training\" + 0.000*\"image\" + 0.000*\"control\" + 0.000*\"&\" + 0.000*\"gaussian\" + 0.000*\"state\" + 0.000*\"transformation\" + 0.000*\"dynamic\" + 0.000*\"prior\" + 0.000*\"transition\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-11-20 21:23:20,952 : INFO : topic #17 (0.010): 0.000*\"state\" + 0.000*\"gaussian\" + 0.000*\"neuron\" + 0.000*\"mixture\" + 0.000*\"z\" + 0.000*\"control\" + 0.000*\"training\" + 0.000*\"component\" + 0.000*\"cortical\" + 0.000*\"activity\"\n",
      "2017-11-20 21:23:20,954 : INFO : topic #69 (0.010): 0.017*\"separating\" + 0.017*\"means,\" + 0.017*\"threshold.\" + 0.017*\"na\" + 0.001*\"texture\" + 0.001*\"labeling\" + 0.001*\"region\" + 0.001*\"homogeneous\" + 0.001*\"outlier\" + 0.001*\"label\"\n",
      "2017-11-20 21:23:20,958 : INFO : topic diff=0.615220, rho=0.229416\n",
      "2017-11-20 21:23:27,578 : INFO : -8.188 per-word bound, 291.6 perplexity estimate based on a held-out corpus of 151 documents with 163809 words\n",
      "2017-11-20 21:23:27,579 : INFO : PROGRESS: pass 18, at document #151/151\n",
      "2017-11-20 21:23:29,847 : INFO : topic #24 (0.010): 0.019*\"histogram\" + 0.019*\"image\" + 0.016*\"recognition\" + 0.016*\"attribute\" + 0.015*\"object\" + 0.014*\"matching\" + 0.014*\"graph\" + 0.012*\"euclidean\" + 0.010*\"angle\" + 0.010*\"database\"\n",
      "2017-11-20 21:23:29,850 : INFO : topic #6 (0.010): 0.000*\"state\" + 0.000*\"direction\" + 0.000*\"population\" + 0.000*\"cell\" + 0.000*\"task\" + 0.000*\"training\" + 0.000*\"&\" + 0.000*\"subject\" + 0.000*\"agent\" + 0.000*\"visual\"\n",
      "2017-11-20 21:23:29,853 : INFO : topic #94 (0.010): 0.017*\"image\" + 0.013*\"ica\" + 0.012*\"code\" + 0.009*\"filter\" + 0.008*\"statistic\" + 0.008*\"phase\" + 0.008*\"approximation\" + 0.008*\"mixture\" + 0.008*\"natural\" + 0.007*\"source\"\n",
      "2017-11-20 21:23:29,856 : INFO : topic #4 (0.010): 0.018*\"noise\" + 0.012*\"fig.\" + 0.012*\"cell\" + 0.010*\"delay\" + 0.010*\"pixel\" + 0.009*\"source\" + 0.009*\"image\" + 0.009*\"complex\" + 0.008*\"&\" + 0.008*\"current\"\n",
      "2017-11-20 21:23:29,858 : INFO : topic #38 (0.010): 0.036*\"analog\" + 0.024*\"net\" + 0.020*\"language\" + 0.019*\"noise\" + 0.018*\"w\" + 0.016*\"measure\" + 0.016*\"l\" + 0.014*\"state\" + 0.013*\"theorem\" + 0.012*\"gaussian\"\n",
      "2017-11-20 21:23:29,870 : INFO : topic diff=0.499977, rho=0.223607\n",
      "2017-11-20 21:23:36,922 : INFO : -8.180 per-word bound, 290.0 perplexity estimate based on a held-out corpus of 151 documents with 163809 words\n",
      "2017-11-20 21:23:36,923 : INFO : PROGRESS: pass 19, at document #151/151\n",
      "2017-11-20 21:23:38,625 : INFO : topic #79 (0.010): 0.023*\"forward\" + 0.021*\"motor\" + 0.020*\"inverse\" + 0.020*\"object\" + 0.020*\"module\" + 0.017*\"control\" + 0.016*\"multiple\" + 0.013*\"architecture\" + 0.012*\"variational\" + 0.012*\"signal\"\n",
      "2017-11-20 21:23:38,627 : INFO : topic #12 (0.010): 0.024*\"mass\" + 0.023*\"positive\" + 0.022*\"architecture\" + 0.019*\"detection\" + 0.017*\"%\" + 0.015*\"resolution\" + 0.015*\"unit\" + 0.014*\"false\" + 0.014*\"pixel\" + 0.014*\"low\"\n",
      "2017-11-20 21:23:38,628 : INFO : topic #86 (0.010): 0.006*\"sensor\" + 0.005*\"noise\" + 0.005*\"image\" + 0.005*\"binary\" + 0.005*\"correlation\" + 0.004*\"local\" + 0.004*\"r\" + 0.004*\"p\" + 0.003*\"gaussian\" + 0.003*\"line\"\n",
      "2017-11-20 21:23:38,629 : INFO : topic #50 (0.010): 0.030*\"document\" + 0.023*\"cell\" + 0.017*\"word\" + 0.017*\"partition\" + 0.013*\"partitioning\" + 0.010*\"goal\" + 0.009*\"retrieval\" + 0.009*\"along\" + 0.008*\"agent\" + 0.008*\"largest\"\n",
      "2017-11-20 21:23:38,631 : INFO : topic #30 (0.010): 0.000*\"image\" + 0.000*\"<\" + 0.000*\"training\" + 0.000*\"approximation\" + 0.000*\"state\" + 0.000*\"8\" + 0.000*\"filter\" + 0.000*\"24\" + 0.000*\"&\" + 0.000*\"rate\"\n",
      "2017-11-20 21:23:38,635 : INFO : topic diff=0.408760, rho=0.218218\n",
      "2017-11-20 21:23:44,879 : INFO : -8.173 per-word bound, 288.6 perplexity estimate based on a held-out corpus of 151 documents with 163809 words\n",
      "2017-11-20 21:23:44,880 : INFO : PROGRESS: pass 20, at document #151/151\n",
      "2017-11-20 21:23:46,483 : INFO : topic #51 (0.010): 0.099*\"em\" + 0.082*\"mixture\" + 0.053*\"likelihood\" + 0.042*\"density\" + 0.034*\"conditional\" + 0.034*\"update\" + 0.030*\"bound\" + 0.027*\"q\" + 0.024*\"maximum\" + 0.020*\"gaussian\"\n",
      "2017-11-20 21:23:46,484 : INFO : topic #64 (0.010): 0.048*\"series\" + 0.021*\"stationary\" + 0.014*\"markov\" + 0.013*\"connection\" + 0.012*\"&\" + 0.012*\"asymptotically\" + 0.012*\"t\" + 0.012*\"chain\" + 0.011*\"g\" + 0.009*\"i.e.,\"\n",
      "2017-11-20 21:23:46,486 : INFO : topic #46 (0.010): 0.000*\"neuron\" + 0.000*\"firing\" + 0.000*\"&\" + 0.000*\"visual\" + 0.000*\"correlation\" + 0.000*\"z\" + 0.000*\"layer\" + 0.000*\"spike\" + 0.000*\"image\" + 0.000*\"positive\"\n",
      "2017-11-20 21:23:46,488 : INFO : topic #86 (0.010): 0.006*\"sensor\" + 0.005*\"noise\" + 0.005*\"binary\" + 0.005*\"image\" + 0.005*\"correlation\" + 0.004*\"local\" + 0.004*\"r\" + 0.004*\"p\" + 0.003*\"gaussian\" + 0.003*\"line\"\n",
      "2017-11-20 21:23:46,490 : INFO : topic #78 (0.010): 0.012*\"class\" + 0.011*\"clustering\" + 0.010*\"r\" + 0.010*\"cluster\" + 0.010*\"cut\" + 0.009*\"distance\" + 0.008*\"node\" + 0.007*\"similarity\" + 0.006*\"every\" + 0.006*\"partition\"\n",
      "2017-11-20 21:23:46,495 : INFO : topic diff=0.336362, rho=0.213201\n",
      "2017-11-20 21:23:53,101 : INFO : -8.167 per-word bound, 287.4 perplexity estimate based on a held-out corpus of 151 documents with 163809 words\n",
      "2017-11-20 21:23:53,102 : INFO : PROGRESS: pass 21, at document #151/151\n",
      "2017-11-20 21:23:54,788 : INFO : topic #88 (0.010): 0.000*\"training\" + 0.000*\"kernel\" + 0.000*\"spike\" + 0.000*\"machine\" + 0.000*\"support\" + 0.000*\"classification\" + 0.000*\"density\" + 0.000*\"w\" + 0.000*\"gaussian\" + 0.000*\"p\"\n",
      "2017-11-20 21:23:54,790 : INFO : topic #16 (0.010): 0.023*\"convolution\" + 0.023*\"analog\" + 0.022*\"chip\" + 0.020*\"impulse\" + 0.019*\"noise\" + 0.019*\"signal\" + 0.013*\"cell\" + 0.013*\"polynomial\" + 0.011*\"speed\" + 0.011*\"ratio\"\n",
      "2017-11-20 21:23:54,797 : INFO : topic #86 (0.010): 0.006*\"sensor\" + 0.005*\"noise\" + 0.005*\"binary\" + 0.005*\"correlation\" + 0.005*\"image\" + 0.004*\"r\" + 0.004*\"local\" + 0.004*\"p\" + 0.003*\"gaussian\" + 0.003*\"line\"\n",
      "2017-11-20 21:23:54,803 : INFO : topic #89 (0.010): 0.000*\"training\" + 0.000*\"image\" + 0.000*\"control\" + 0.000*\"&\" + 0.000*\"gaussian\" + 0.000*\"state\" + 0.000*\"transformation\" + 0.000*\"dynamic\" + 0.000*\"prior\" + 0.000*\"transition\"\n",
      "2017-11-20 21:23:54,805 : INFO : topic #72 (0.010): 0.013*\"visual\" + 0.009*\"distance\" + 0.008*\"search\" + 0.007*\"ei\" + 0.007*\"target\" + 0.007*\"fig.\" + 0.005*\"v1\" + 0.005*\"bar\" + 0.005*\"diagram\" + 0.004*\"interaction\"\n",
      "2017-11-20 21:23:54,814 : INFO : topic diff=0.278684, rho=0.208514\n",
      "2017-11-20 21:24:03,213 : INFO : -8.162 per-word bound, 286.4 perplexity estimate based on a held-out corpus of 151 documents with 163809 words\n",
      "2017-11-20 21:24:03,214 : INFO : PROGRESS: pass 22, at document #151/151\n",
      "2017-11-20 21:24:04,952 : INFO : topic #38 (0.010): 0.036*\"analog\" + 0.024*\"net\" + 0.020*\"language\" + 0.019*\"noise\" + 0.018*\"w\" + 0.016*\"measure\" + 0.016*\"l\" + 0.014*\"state\" + 0.013*\"theorem\" + 0.012*\"gaussian\"\n",
      "2017-11-20 21:24:04,954 : INFO : topic #57 (0.010): 0.033*\"speech\" + 0.030*\"path\" + 0.020*\"acoustic\" + 0.016*\"continuity\" + 0.013*\"hidden\" + 0.011*\"recognition\" + 0.010*\"optimization\" + 0.009*\"hmms\" + 0.009*\"&\" + 0.009*\"hmm\"\n",
      "2017-11-20 21:24:04,955 : INFO : topic #89 (0.010): 0.000*\"training\" + 0.000*\"image\" + 0.000*\"control\" + 0.000*\"&\" + 0.000*\"gaussian\" + 0.000*\"state\" + 0.000*\"transformation\" + 0.000*\"dynamic\" + 0.000*\"prior\" + 0.000*\"transition\"\n",
      "2017-11-20 21:24:04,957 : INFO : topic #79 (0.010): 0.023*\"forward\" + 0.021*\"motor\" + 0.020*\"inverse\" + 0.020*\"object\" + 0.020*\"module\" + 0.017*\"control\" + 0.016*\"multiple\" + 0.013*\"architecture\" + 0.012*\"variational\" + 0.012*\"signal\"\n",
      "2017-11-20 21:24:04,959 : INFO : topic #67 (0.010): 0.000*\"state\" + 0.000*\"&\" + 0.000*\"rate\" + 0.000*\"rule\" + 0.000*\"training\" + 0.000*\"control\" + 0.000*\"image\" + 0.000*\"kernel\" + 0.000*\"sparse\" + 0.000*\"spike\"\n",
      "2017-11-20 21:24:04,964 : INFO : topic diff=0.232555, rho=0.204124\n",
      "2017-11-20 21:24:10,540 : INFO : -8.157 per-word bound, 285.4 perplexity estimate based on a held-out corpus of 151 documents with 163809 words\n",
      "2017-11-20 21:24:10,541 : INFO : PROGRESS: pass 23, at document #151/151\n",
      "2017-11-20 21:24:12,194 : INFO : topic #40 (0.010): 0.023*\"wavelet\" + 0.016*\"basis\" + 0.011*\"selection\" + 0.010*\"training\" + 0.009*\"memory\" + 0.009*\"filter\" + 0.008*\"threshold\" + 0.007*\"binary\" + 0.007*\"speed\" + 0.006*\"table\"\n",
      "2017-11-20 21:24:12,196 : INFO : topic #63 (0.010): 0.035*\"policy\" + 0.034*\"risk\" + 0.020*\"state\" + 0.018*\"price\" + 0.018*\"q-learning\" + 0.017*\"<\" + 0.017*\"return\" + 0.015*\"u)\" + 0.013*\"reward\" + 0.013*\"worst\"\n",
      "2017-11-20 21:24:12,197 : INFO : topic #52 (0.010): 0.021*\"state\" + 0.010*\"call\" + 0.008*\"control\" + 0.007*\"convergence\" + 0.007*\"rl\" + 0.006*\"rate\" + 0.006*\"node\" + 0.006*\"v\" + 0.006*\"reinforcement\" + 0.006*\"policy\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-11-20 21:24:12,199 : INFO : topic #36 (0.010): 0.000*\"training\" + 0.000*\"state\" + 0.000*\"binary\" + 0.000*\"rule\" + 0.000*\"control\" + 0.000*\"forward\" + 0.000*\"correlation\" + 0.000*\"node\" + 0.000*\"kernel\" + 0.000*\"inverse\"\n",
      "2017-11-20 21:24:12,201 : INFO : topic #49 (0.010): 0.025*\"activity\" + 0.019*\"cortical\" + 0.019*\"noise\" + 0.018*\"variance\" + 0.017*\"line\" + 0.016*\"normalization\" + 0.016*\"spatial\" + 0.015*\"unit\" + 0.015*\"attractor\" + 0.015*\"ideal\"\n",
      "2017-11-20 21:24:12,206 : INFO : topic diff=0.195454, rho=0.200000\n",
      "2017-11-20 21:24:18,589 : INFO : -8.153 per-word bound, 284.6 perplexity estimate based on a held-out corpus of 151 documents with 163809 words\n",
      "2017-11-20 21:24:18,592 : INFO : PROGRESS: pass 24, at document #151/151\n",
      "2017-11-20 21:24:20,176 : INFO : topic #8 (0.010): 0.039*\"policy\" + 0.035*\"action\" + 0.028*\"state\" + 0.027*\"agent\" + 0.024*\"partially\" + 0.023*\"observable\" + 0.019*\"trace\" + 0.019*\"observation\" + 0.019*\"decision\" + 0.017*\"reward\"\n",
      "2017-11-20 21:24:20,177 : INFO : topic #34 (0.010): 0.133*\"latent\" + 0.085*\"pca\" + 0.067*\"component\" + 0.063*\"principal\" + 0.033*\"kernel\" + 0.027*\"nonlinear\" + 0.025*\"bishop\" + 0.025*\"sample\" + 0.023*\"w\" + 0.020*\"basis\"\n",
      "2017-11-20 21:24:20,178 : INFO : topic #11 (0.010): 0.048*\"sparse\" + 0.027*\"code\" + 0.025*\"coding\" + 0.023*\"component\" + 0.021*\"density\" + 0.020*\"shrinkage\" + 0.016*\"image\" + 0.012*\"noise\" + 0.010*\"gaussian\" + 0.008*\"noisy\"\n",
      "2017-11-20 21:24:20,181 : INFO : topic #75 (0.010): 0.050*\"support\" + 0.034*\"machine\" + 0.032*\"training\" + 0.023*\"working\" + 0.016*\"class\" + 0.016*\"programming\" + 0.015*\"risk\" + 0.012*\"minimization\" + 0.011*\"classification\" + 0.011*\"decision\"\n",
      "2017-11-20 21:24:20,182 : INFO : topic #45 (0.010): 0.050*\"state\" + 0.045*\"gaussian\" + 0.041*\"kalman\" + 0.040*\"nonlinear\" + 0.030*\"hidden\" + 0.024*\"em\" + 0.022*\"extended\" + 0.021*\"density\" + 0.021*\"covariance\" + 0.020*\"dynamical\"\n",
      "2017-11-20 21:24:20,186 : INFO : topic diff=0.165427, rho=0.196116\n",
      "2017-11-20 21:24:25,966 : INFO : -8.149 per-word bound, 283.8 perplexity estimate based on a held-out corpus of 151 documents with 163809 words\n",
      "2017-11-20 21:24:25,967 : INFO : PROGRESS: pass 25, at document #151/151\n",
      "2017-11-20 21:24:27,662 : INFO : topic #21 (0.010): 0.000*\"&\" + 0.000*\"r\" + 0.000*\"state\" + 0.000*\"margin\" + 0.000*\"curve\" + 0.000*\"component\" + 0.000*\"signal\" + 0.000*\"training\" + 0.000*\"cell\" + 0.000*\"control\"\n",
      "2017-11-20 21:24:27,663 : INFO : topic #94 (0.010): 0.017*\"image\" + 0.014*\"ica\" + 0.012*\"code\" + 0.009*\"filter\" + 0.009*\"statistic\" + 0.008*\"phase\" + 0.008*\"source\" + 0.008*\"approximation\" + 0.008*\"natural\" + 0.007*\"class\"\n",
      "2017-11-20 21:24:27,665 : INFO : topic #43 (0.010): 0.015*\"local\" + 0.011*\"field\" + 0.008*\"contour\" + 0.006*\"<\" + 0.006*\"mutual\" + 0.006*\"p\" + 0.006*\"square\" + 0.005*\"phys.\" + 0.005*\"prediction\" + 0.005*\"bound\"\n",
      "2017-11-20 21:24:27,666 : INFO : topic #88 (0.010): 0.000*\"training\" + 0.000*\"kernel\" + 0.000*\"spike\" + 0.000*\"machine\" + 0.000*\"support\" + 0.000*\"classification\" + 0.000*\"density\" + 0.000*\"w\" + 0.000*\"gaussian\" + 0.000*\"p\"\n",
      "2017-11-20 21:24:27,668 : INFO : topic #5 (0.010): 0.045*\"synaptic\" + 0.028*\"synapsis\" + 0.017*\"prior\" + 0.015*\"modification\" + 0.015*\"pruning\" + 0.014*\"memory\" + 0.012*\"neuronal\" + 0.009*\"level\" + 0.009*\"robot\" + 0.008*\"gaussians\"\n",
      "2017-11-20 21:24:27,672 : INFO : topic diff=0.140984, rho=0.192450\n",
      "2017-11-20 21:24:34,237 : INFO : -8.145 per-word bound, 283.1 perplexity estimate based on a held-out corpus of 151 documents with 163809 words\n",
      "2017-11-20 21:24:34,238 : INFO : PROGRESS: pass 26, at document #151/151\n",
      "2017-11-20 21:24:36,013 : INFO : topic #50 (0.010): 0.030*\"document\" + 0.023*\"cell\" + 0.017*\"word\" + 0.017*\"partition\" + 0.013*\"partitioning\" + 0.010*\"goal\" + 0.009*\"retrieval\" + 0.009*\"along\" + 0.008*\"agent\" + 0.008*\"largest\"\n",
      "2017-11-20 21:24:36,015 : INFO : topic #35 (0.010): 0.000*\"image\" + 0.000*\"direction\" + 0.000*\"kernel\" + 0.000*\"training\" + 0.000*\"visual\" + 0.000*\"response\" + 0.000*\"motion\" + 0.000*\"bound\" + 0.000*\"population\" + 0.000*\"cell\"\n",
      "2017-11-20 21:24:36,017 : INFO : topic #63 (0.010): 0.035*\"policy\" + 0.034*\"risk\" + 0.021*\"state\" + 0.018*\"price\" + 0.018*\"q-learning\" + 0.017*\"<\" + 0.017*\"return\" + 0.015*\"u)\" + 0.013*\"reward\" + 0.013*\"worst\"\n",
      "2017-11-20 21:24:36,019 : INFO : topic #78 (0.010): 0.012*\"class\" + 0.011*\"clustering\" + 0.010*\"r\" + 0.010*\"cut\" + 0.010*\"cluster\" + 0.009*\"distance\" + 0.008*\"node\" + 0.007*\"similarity\" + 0.006*\"every\" + 0.006*\"graph\"\n",
      "2017-11-20 21:24:36,021 : INFO : topic #22 (0.010): 0.000*\"control\" + 0.000*\"noise\" + 0.000*\"signal\" + 0.000*\"change\" + 0.000*\"positive\" + 0.000*\"controller\" + 0.000*\"rate\" + 0.000*\"neuron\" + 0.000*\"firing\" + 0.000*\"feedback\"\n",
      "2017-11-20 21:24:36,031 : INFO : topic diff=0.120994, rho=0.188982\n",
      "2017-11-20 21:24:42,098 : INFO : -8.142 per-word bound, 282.5 perplexity estimate based on a held-out corpus of 151 documents with 163809 words\n",
      "2017-11-20 21:24:42,099 : INFO : PROGRESS: pass 27, at document #151/151\n",
      "2017-11-20 21:24:43,747 : INFO : topic #79 (0.010): 0.023*\"forward\" + 0.021*\"motor\" + 0.020*\"inverse\" + 0.020*\"object\" + 0.020*\"module\" + 0.017*\"control\" + 0.016*\"multiple\" + 0.013*\"architecture\" + 0.013*\"variational\" + 0.012*\"signal\"\n",
      "2017-11-20 21:24:43,749 : INFO : topic #41 (0.010): 0.000*\"state\" + 0.000*\"rule\" + 0.000*\"neuron\" + 0.000*\"noise\" + 0.000*\"training\" + 0.000*\"forward\" + 0.000*\"motor\" + 0.000*\"bound\" + 0.000*\"path\" + 0.000*\"action\"\n",
      "2017-11-20 21:24:43,750 : INFO : topic #24 (0.010): 0.019*\"histogram\" + 0.019*\"image\" + 0.016*\"recognition\" + 0.016*\"attribute\" + 0.015*\"euclidean\" + 0.014*\"graph\" + 0.013*\"object\" + 0.013*\"matching\" + 0.012*\"pairwise\" + 0.010*\"database\"\n",
      "2017-11-20 21:24:43,752 : INFO : topic #38 (0.010): 0.036*\"analog\" + 0.024*\"net\" + 0.020*\"language\" + 0.019*\"noise\" + 0.018*\"w\" + 0.016*\"measure\" + 0.016*\"l\" + 0.014*\"state\" + 0.013*\"theorem\" + 0.012*\"gaussian\"\n",
      "2017-11-20 21:24:43,754 : INFO : topic #34 (0.010): 0.126*\"latent\" + 0.102*\"pca\" + 0.070*\"component\" + 0.064*\"principal\" + 0.037*\"kernel\" + 0.028*\"nonlinear\" + 0.024*\"bishop\" + 0.024*\"sample\" + 0.022*\"w\" + 0.020*\"basis\"\n",
      "2017-11-20 21:24:43,758 : INFO : topic diff=0.104534, rho=0.185695\n",
      "2017-11-20 21:24:51,025 : INFO : -8.139 per-word bound, 281.9 perplexity estimate based on a held-out corpus of 151 documents with 163809 words\n",
      "2017-11-20 21:24:51,026 : INFO : PROGRESS: pass 28, at document #151/151\n",
      "2017-11-20 21:24:53,716 : INFO : topic #34 (0.010): 0.124*\"latent\" + 0.107*\"pca\" + 0.070*\"component\" + 0.064*\"principal\" + 0.038*\"kernel\" + 0.029*\"nonlinear\" + 0.024*\"bishop\" + 0.023*\"sample\" + 0.022*\"w\" + 0.020*\"basis\"\n",
      "2017-11-20 21:24:53,717 : INFO : topic #53 (0.010): 0.076*\"group\" + 0.055*\"cluster\" + 0.050*\"structure\" + 0.046*\"clustering\" + 0.043*\"probabilistic\" + 0.033*\"object\" + 0.033*\"visualization\" + 0.032*\"assignment\" + 0.024*\"data.\" + 0.023*\"dimensional\"\n",
      "2017-11-20 21:24:53,719 : INFO : topic #58 (0.010): 0.022*\"digit\" + 0.019*\"neuron\" + 0.018*\"cell\" + 0.018*\"spatial\" + 0.017*\"&\" + 0.016*\"response\" + 0.015*\"visual\" + 0.014*\"image\" + 0.012*\"complex\" + 0.011*\"cortical\"\n",
      "2017-11-20 21:24:53,723 : INFO : topic #26 (0.010): 0.032*\"approximation\" + 0.018*\"bound\" + 0.015*\"field\" + 0.014*\"h\" + 0.011*\"<\" + 0.010*\"theorem\" + 0.009*\"q\" + 0.009*\"_<\" + 0.009*\">\" + 0.009*\"incremental\"\n",
      "2017-11-20 21:24:53,726 : INFO : topic #83 (0.010): 0.036*\"front\" + 0.030*\"field\" + 0.017*\"along\" + 0.016*\"discontinuity\" + 0.016*\"covariance\" + 0.012*\"prior\" + 0.012*\"constrained\" + 0.010*\"(a)\" + 0.010*\"(b)\" + 0.010*\"frontal\"\n",
      "2017-11-20 21:24:53,743 : INFO : topic diff=0.090925, rho=0.182574\n",
      "2017-11-20 21:25:00,624 : INFO : -8.136 per-word bound, 281.4 perplexity estimate based on a held-out corpus of 151 documents with 163809 words\n",
      "2017-11-20 21:25:00,625 : INFO : PROGRESS: pass 29, at document #151/151\n",
      "2017-11-20 21:25:02,296 : INFO : topic #20 (0.010): 0.034*\"policy\" + 0.018*\"state\" + 0.014*\"reward\" + 0.013*\"transition\" + 0.012*\"rl\" + 0.011*\"block\" + 0.011*\"reinforcement\" + 0.010*\"stochastic\" + 0.010*\"a)\" + 0.010*\"every\"\n",
      "2017-11-20 21:25:02,297 : INFO : topic #82 (0.010): 0.071*\"loss\" + 0.025*\"threshold\" + 0.021*\"classification\" + 0.019*\"update\" + 0.018*\"bound\" + 0.016*\"perceptron\" + 0.013*\"gradient\" + 0.012*\"regression\" + 0.012*\"relative\" + 0.011*\"divergence\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-11-20 21:25:02,298 : INFO : topic #63 (0.010): 0.035*\"policy\" + 0.034*\"risk\" + 0.021*\"state\" + 0.018*\"price\" + 0.018*\"q-learning\" + 0.017*\"<\" + 0.017*\"return\" + 0.015*\"u)\" + 0.013*\"reward\" + 0.013*\"sensitive\"\n",
      "2017-11-20 21:25:02,300 : INFO : topic #38 (0.010): 0.036*\"analog\" + 0.024*\"net\" + 0.020*\"language\" + 0.019*\"noise\" + 0.018*\"w\" + 0.016*\"measure\" + 0.016*\"l\" + 0.014*\"state\" + 0.013*\"theorem\" + 0.012*\"gaussian\"\n",
      "2017-11-20 21:25:02,302 : INFO : topic #48 (0.010): 0.000*\"image\" + 0.000*\"training\" + 0.000*\"face\" + 0.000*\"visual\" + 0.000*\"prior\" + 0.000*\"recognition\" + 0.000*\"class\" + 0.000*\"distance\" + 0.000*\"estimation\" + 0.000*\"table\"\n",
      "2017-11-20 21:25:02,306 : INFO : topic diff=0.079600, rho=0.179605\n",
      "2017-11-20 21:25:08,795 : INFO : -8.134 per-word bound, 280.9 perplexity estimate based on a held-out corpus of 151 documents with 163809 words\n",
      "2017-11-20 21:25:08,798 : INFO : PROGRESS: pass 30, at document #151/151\n",
      "2017-11-20 21:25:11,389 : INFO : topic #49 (0.010): 0.025*\"activity\" + 0.019*\"cortical\" + 0.019*\"noise\" + 0.018*\"variance\" + 0.017*\"line\" + 0.016*\"normalization\" + 0.016*\"spatial\" + 0.015*\"unit\" + 0.015*\"attractor\" + 0.015*\"ideal\"\n",
      "2017-11-20 21:25:11,391 : INFO : topic #14 (0.010): 0.029*\"conductance\" + 0.023*\"firing\" + 0.023*\"rate\" + 0.021*\"cell\" + 0.016*\"mutual\" + 0.015*\"neuron\" + 0.015*\"stimulus\" + 0.011*\"among\" + 0.010*\"spike\" + 0.009*\"change\"\n",
      "2017-11-20 21:25:11,392 : INFO : topic #7 (0.010): 0.014*\"&\" + 0.013*\"state\" + 0.009*\"markov\" + 0.009*\"split\" + 0.008*\"arc\" + 0.008*\"agent\" + 0.007*\"probabilistic\" + 0.007*\"speech\" + 0.006*\"task\" + 0.006*\"hmms\"\n",
      "2017-11-20 21:25:11,394 : INFO : topic #10 (0.010): 0.000*\"document\" + 0.000*\"clustering\" + 0.000*\"image\" + 0.000*\"training\" + 0.000*\"em\" + 0.000*\"mixture\" + 0.000*\"&\" + 0.000*\"component\" + 0.000*\"node\" + 0.000*\"aspect\"\n",
      "2017-11-20 21:25:11,396 : INFO : topic #83 (0.010): 0.036*\"front\" + 0.030*\"field\" + 0.017*\"along\" + 0.016*\"discontinuity\" + 0.016*\"covariance\" + 0.012*\"prior\" + 0.012*\"constrained\" + 0.010*\"(a)\" + 0.010*\"(b)\" + 0.010*\"frontal\"\n",
      "2017-11-20 21:25:11,408 : INFO : topic diff=0.070136, rho=0.176777\n",
      "2017-11-20 21:25:18,850 : INFO : -8.132 per-word bound, 280.4 perplexity estimate based on a held-out corpus of 151 documents with 163809 words\n",
      "2017-11-20 21:25:18,851 : INFO : PROGRESS: pass 31, at document #151/151\n",
      "2017-11-20 21:25:20,540 : INFO : topic #24 (0.010): 0.019*\"histogram\" + 0.019*\"image\" + 0.016*\"recognition\" + 0.016*\"attribute\" + 0.016*\"euclidean\" + 0.014*\"graph\" + 0.013*\"matching\" + 0.013*\"object\" + 0.013*\"pairwise\" + 0.010*\"database\"\n",
      "2017-11-20 21:25:20,541 : INFO : topic #52 (0.010): 0.021*\"state\" + 0.010*\"call\" + 0.008*\"control\" + 0.007*\"convergence\" + 0.007*\"rl\" + 0.006*\"rate\" + 0.006*\"v\" + 0.006*\"node\" + 0.006*\"reinforcement\" + 0.006*\"policy\"\n",
      "2017-11-20 21:25:20,543 : INFO : topic #75 (0.010): 0.051*\"support\" + 0.035*\"machine\" + 0.032*\"training\" + 0.023*\"working\" + 0.017*\"class\" + 0.016*\"programming\" + 0.014*\"risk\" + 0.012*\"decision\" + 0.012*\"minimization\" + 0.011*\"classification\"\n",
      "2017-11-20 21:25:20,544 : INFO : topic #16 (0.010): 0.023*\"convolution\" + 0.023*\"analog\" + 0.022*\"chip\" + 0.020*\"impulse\" + 0.020*\"signal\" + 0.019*\"noise\" + 0.013*\"cell\" + 0.013*\"polynomial\" + 0.011*\"speed\" + 0.011*\"ratio\"\n",
      "2017-11-20 21:25:20,546 : INFO : topic #22 (0.010): 0.000*\"control\" + 0.000*\"noise\" + 0.000*\"signal\" + 0.000*\"change\" + 0.000*\"positive\" + 0.000*\"controller\" + 0.000*\"rate\" + 0.000*\"neuron\" + 0.000*\"firing\" + 0.000*\"feedback\"\n",
      "2017-11-20 21:25:20,550 : INFO : topic diff=0.062203, rho=0.174078\n",
      "2017-11-20 21:25:26,574 : INFO : -8.129 per-word bound, 280.0 perplexity estimate based on a held-out corpus of 151 documents with 163809 words\n",
      "2017-11-20 21:25:26,575 : INFO : PROGRESS: pass 32, at document #151/151\n",
      "2017-11-20 21:25:28,210 : INFO : topic #31 (0.010): 0.041*\"detection\" + 0.031*\"state\" + 0.030*\"account\" + 0.030*\"behavior\" + 0.027*\"call\" + 0.021*\"st\" + 0.019*\"hierarchical\" + 0.019*\"hidden\" + 0.018*\"em\" + 0.018*\"i,\"\n",
      "2017-11-20 21:25:28,211 : INFO : topic #97 (0.010): 0.353*\"cell\" + 0.071*\"frequency\" + 0.038*\"modulated\" + 0.027*\"1995;\" + 0.017*\"manner.\" + 0.017*\"2).\" + 0.012*\"respond\" + 0.011*\"k.,\" + 0.011*\"excitation\" + 0.010*\"equation,\"\n",
      "2017-11-20 21:25:28,212 : INFO : topic #42 (0.010): 0.000*\"state\" + 0.000*\"image\" + 0.000*\"rate\" + 0.000*\"visual\" + 0.000*\"training\" + 0.000*\"density\" + 0.000*\"noise\" + 0.000*\"gaussian\" + 0.000*\"neuron\" + 0.000*\"sound\"\n",
      "2017-11-20 21:25:28,214 : INFO : topic #55 (0.010): 0.000*\"image\" + 0.000*\"state\" + 0.000*\"unit\" + 0.000*\"spike\" + 0.000*\"cell\" + 0.000*\"mixture\" + 0.000*\"hidden\" + 0.000*\"flow\" + 0.000*\"component\" + 0.000*\"em\"\n",
      "2017-11-20 21:25:28,216 : INFO : topic #45 (0.010): 0.054*\"state\" + 0.044*\"gaussian\" + 0.042*\"kalman\" + 0.039*\"nonlinear\" + 0.030*\"hidden\" + 0.023*\"em\" + 0.022*\"density\" + 0.022*\"sample\" + 0.021*\"extended\" + 0.021*\"covariance\"\n",
      "2017-11-20 21:25:28,221 : INFO : topic diff=0.055471, rho=0.171499\n",
      "2017-11-20 21:25:34,331 : INFO : -8.127 per-word bound, 279.6 perplexity estimate based on a held-out corpus of 151 documents with 163809 words\n",
      "2017-11-20 21:25:34,332 : INFO : PROGRESS: pass 33, at document #151/151\n",
      "2017-11-20 21:25:35,982 : INFO : topic #17 (0.010): 0.000*\"state\" + 0.000*\"gaussian\" + 0.000*\"neuron\" + 0.000*\"mixture\" + 0.000*\"z\" + 0.000*\"control\" + 0.000*\"training\" + 0.000*\"component\" + 0.000*\"cortical\" + 0.000*\"activity\"\n",
      "2017-11-20 21:25:35,983 : INFO : topic #91 (0.010): 0.020*\"visual\" + 0.017*\"centroid\" + 0.013*\"attention\" + 0.012*\"edge\" + 0.011*\"orientation\" + 0.010*\"contrast\" + 0.008*\"task\" + 0.008*\"q-\" + 0.008*\"circuit\" + 0.007*\"threshold\"\n",
      "2017-11-20 21:25:35,985 : INFO : topic #37 (0.010): 0.000*\"cell\" + 0.000*\"neuron\" + 0.000*\"complex\" + 0.000*\"cortical\" + 0.000*\"spatial\" + 0.000*\"&\" + 0.000*\"density\" + 0.000*\"recurrent\" + 0.000*\"state\" + 0.000*\"response\"\n",
      "2017-11-20 21:25:35,986 : INFO : topic #8 (0.010): 0.039*\"policy\" + 0.038*\"action\" + 0.028*\"state\" + 0.028*\"agent\" + 0.023*\"partially\" + 0.022*\"observable\" + 0.019*\"observation\" + 0.019*\"decision\" + 0.018*\"trace\" + 0.017*\"reward\"\n",
      "2017-11-20 21:25:35,988 : INFO : topic #56 (0.010): 0.018*\"control\" + 0.017*\"contrast\" + 0.014*\"p\" + 0.013*\"adaptation\" + 0.013*\"neuron\" + 0.011*\"correlation\" + 0.010*\"response\" + 0.010*\"population\" + 0.010*\"j\" + 0.009*\"visual\"\n",
      "2017-11-20 21:25:35,992 : INFO : topic diff=0.049755, rho=0.169031\n",
      "2017-11-20 21:25:41,586 : INFO : -8.125 per-word bound, 279.2 perplexity estimate based on a held-out corpus of 151 documents with 163809 words\n",
      "2017-11-20 21:25:41,587 : INFO : PROGRESS: pass 34, at document #151/151\n",
      "2017-11-20 21:25:43,424 : INFO : topic #18 (0.010): 0.000*\"image\" + 0.000*\"mixture\" + 0.000*\"training\" + 0.000*\"&\" + 0.000*\"local\" + 0.000*\"state\" + 0.000*\"component\" + 0.000*\"texture\" + 0.000*\"region\" + 0.000*\"rate\"\n",
      "2017-11-20 21:25:43,425 : INFO : topic #22 (0.010): 0.000*\"control\" + 0.000*\"noise\" + 0.000*\"signal\" + 0.000*\"change\" + 0.000*\"positive\" + 0.000*\"controller\" + 0.000*\"rate\" + 0.000*\"neuron\" + 0.000*\"firing\" + 0.000*\"feedback\"\n",
      "2017-11-20 21:25:43,427 : INFO : topic #2 (0.010): 0.062*\"tree\" + 0.025*\"node\" + 0.020*\"posterior\" + 0.017*\"prior\" + 0.016*\"image\" + 0.014*\"balanced\" + 0.012*\"structure\" + 0.012*\"dt\" + 0.012*\"dynamic\" + 0.011*\"parent\"\n",
      "2017-11-20 21:25:43,429 : INFO : topic #71 (0.010): 0.087*\"graph\" + 0.032*\"maximum\" + 0.029*\"g\" + 0.029*\"vol.\" + 0.028*\"pp.\" + 0.024*\"maximal\" + 0.021*\"equations,\" + 0.021*\"theorem\" + 0.019*\"vertex\" + 0.018*\"association\"\n",
      "2017-11-20 21:25:43,431 : INFO : topic #98 (0.010): 0.000*\"synaptic\" + 0.000*\"&\" + 0.000*\"cell\" + 0.000*\"neuron\" + 0.000*\"rate\" + 0.000*\"firing\" + 0.000*\"distance\" + 0.000*\"response\" + 0.000*\"image\" + 0.000*\"labeled\"\n",
      "2017-11-20 21:25:43,436 : INFO : topic diff=0.044864, rho=0.166667\n",
      "2017-11-20 21:25:49,284 : INFO : -8.123 per-word bound, 278.9 perplexity estimate based on a held-out corpus of 151 documents with 163809 words\n",
      "2017-11-20 21:25:49,286 : INFO : PROGRESS: pass 35, at document #151/151\n",
      "2017-11-20 21:25:50,925 : INFO : topic #87 (0.010): 0.013*\"training\" + 0.010*\"reinforcement\" + 0.009*\"posterior\" + 0.008*\"variational\" + 0.007*\"return\" + 0.006*\"y\" + 0.006*\"observation\" + 0.006*\"year\" + 0.006*\"&\" + 0.005*\"sequence\"\n",
      "2017-11-20 21:25:50,927 : INFO : topic #56 (0.010): 0.018*\"control\" + 0.017*\"contrast\" + 0.014*\"p\" + 0.013*\"adaptation\" + 0.013*\"neuron\" + 0.011*\"correlation\" + 0.010*\"response\" + 0.010*\"population\" + 0.010*\"j\" + 0.009*\"visual\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-11-20 21:25:50,930 : INFO : topic #95 (0.010): 0.019*\"training\" + 0.017*\"8\" + 0.017*\"measurement\" + 0.016*\"direction\" + 0.015*\"24\" + 0.014*\"subject\" + 0.014*\"task\" + 0.012*\"trained\" + 0.011*\"30\" + 0.010*\"stimulus\"\n",
      "2017-11-20 21:25:50,933 : INFO : topic #17 (0.010): 0.000*\"state\" + 0.000*\"gaussian\" + 0.000*\"neuron\" + 0.000*\"mixture\" + 0.000*\"z\" + 0.000*\"control\" + 0.000*\"training\" + 0.000*\"component\" + 0.000*\"cortical\" + 0.000*\"activity\"\n",
      "2017-11-20 21:25:50,939 : INFO : topic #68 (0.010): 0.020*\"inference\" + 0.019*\"state\" + 0.019*\"em\" + 0.018*\"approximation\" + 0.017*\"approximate\" + 0.017*\"message\" + 0.013*\"online\" + 0.013*\"dynamic\" + 0.013*\"observation\" + 0.012*\"window\"\n",
      "2017-11-20 21:25:50,943 : INFO : topic diff=0.040664, rho=0.164399\n",
      "2017-11-20 21:25:56,528 : INFO : -8.122 per-word bound, 278.5 perplexity estimate based on a held-out corpus of 151 documents with 163809 words\n",
      "2017-11-20 21:25:56,529 : INFO : PROGRESS: pass 36, at document #151/151\n",
      "2017-11-20 21:25:58,251 : INFO : topic #5 (0.010): 0.046*\"synaptic\" + 0.029*\"synapsis\" + 0.017*\"prior\" + 0.015*\"modification\" + 0.015*\"pruning\" + 0.015*\"memory\" + 0.012*\"neuronal\" + 0.009*\"level\" + 0.009*\"robot\" + 0.008*\"gaussians\"\n",
      "2017-11-20 21:25:58,253 : INFO : topic #76 (0.010): 0.067*\"flow\" + 0.053*\"optical\" + 0.052*\"motion\" + 0.040*\"chip\" + 0.039*\"field\" + 0.021*\"sensor\" + 0.021*\"analog\" + 0.020*\"pixel\" + 0.020*\"computation\" + 0.017*\"coordinate\"\n",
      "2017-11-20 21:25:58,258 : INFO : topic #28 (0.010): 0.063*\"hmm\" + 0.027*\"emission\" + 0.027*\"regularization\" + 0.027*\"training\" + 0.020*\"mixture\" + 0.017*\"prototype\" + 0.016*\"discrete\" + 0.016*\"speech\" + 0.013*\"state\" + 0.013*\"complexity\"\n",
      "2017-11-20 21:25:58,260 : INFO : topic #17 (0.010): 0.000*\"state\" + 0.000*\"gaussian\" + 0.000*\"neuron\" + 0.000*\"mixture\" + 0.000*\"z\" + 0.000*\"control\" + 0.000*\"training\" + 0.000*\"component\" + 0.000*\"cortical\" + 0.000*\"activity\"\n",
      "2017-11-20 21:25:58,265 : INFO : topic #12 (0.010): 0.024*\"mass\" + 0.023*\"positive\" + 0.023*\"architecture\" + 0.019*\"detection\" + 0.017*\"%\" + 0.015*\"resolution\" + 0.015*\"unit\" + 0.014*\"false\" + 0.014*\"low\" + 0.014*\"pixel\"\n",
      "2017-11-20 21:25:58,275 : INFO : topic diff=0.037063, rho=0.162221\n",
      "2017-11-20 21:26:04,433 : INFO : -8.120 per-word bound, 278.2 perplexity estimate based on a held-out corpus of 151 documents with 163809 words\n",
      "2017-11-20 21:26:04,434 : INFO : PROGRESS: pass 37, at document #151/151\n",
      "2017-11-20 21:26:06,037 : INFO : topic #4 (0.010): 0.018*\"noise\" + 0.012*\"fig.\" + 0.010*\"delay\" + 0.010*\"pixel\" + 0.010*\"source\" + 0.009*\"image\" + 0.009*\"complex\" + 0.009*\"cell\" + 0.009*\"&\" + 0.008*\"current\"\n",
      "2017-11-20 21:26:06,039 : INFO : topic #80 (0.010): 0.048*\"bound\" + 0.043*\"layer\" + 0.042*\"unit\" + 0.024*\"polynomial\" + 0.021*\"lower\" + 0.018*\"activation\" + 0.016*\"piecewise\" + 0.014*\"upper\" + 0.014*\"l\" + 0.012*\"dimension\"\n",
      "2017-11-20 21:26:06,040 : INFO : topic #34 (0.010): 0.134*\"pca\" + 0.114*\"latent\" + 0.073*\"component\" + 0.064*\"principal\" + 0.047*\"kernel\" + 0.032*\"nonlinear\" + 0.022*\"bishop\" + 0.022*\"sample\" + 0.021*\"w\" + 0.019*\"basis\"\n",
      "2017-11-20 21:26:06,042 : INFO : topic #75 (0.010): 0.052*\"support\" + 0.036*\"machine\" + 0.033*\"training\" + 0.022*\"working\" + 0.017*\"class\" + 0.016*\"programming\" + 0.014*\"risk\" + 0.013*\"decision\" + 0.012*\"minimization\" + 0.011*\"classification\"\n",
      "2017-11-20 21:26:06,045 : INFO : topic #89 (0.010): 0.000*\"training\" + 0.000*\"image\" + 0.000*\"control\" + 0.000*\"&\" + 0.000*\"gaussian\" + 0.000*\"state\" + 0.000*\"transformation\" + 0.000*\"dynamic\" + 0.000*\"prior\" + 0.000*\"transition\"\n",
      "2017-11-20 21:26:06,051 : INFO : topic diff=0.033924, rho=0.160128\n",
      "2017-11-20 21:26:11,760 : INFO : -8.118 per-word bound, 277.9 perplexity estimate based on a held-out corpus of 151 documents with 163809 words\n",
      "2017-11-20 21:26:11,761 : INFO : PROGRESS: pass 38, at document #151/151\n",
      "2017-11-20 21:26:13,534 : INFO : topic #17 (0.010): 0.000*\"state\" + 0.000*\"gaussian\" + 0.000*\"neuron\" + 0.000*\"mixture\" + 0.000*\"z\" + 0.000*\"control\" + 0.000*\"training\" + 0.000*\"component\" + 0.000*\"cortical\" + 0.000*\"activity\"\n",
      "2017-11-20 21:26:13,536 : INFO : topic #0 (0.010): 0.063*\"margin\" + 0.022*\"cost\" + 0.021*\"training\" + 0.015*\"generalization\" + 0.013*\"hypothesis\" + 0.011*\"classifier\" + 0.011*\"complexity\" + 0.008*\"0.\" + 0.007*\"chosen\" + 0.007*\"validation\"\n",
      "2017-11-20 21:26:13,538 : INFO : topic #62 (0.010): 0.032*\"face\" + 0.022*\"labeled\" + 0.019*\"density\" + 0.017*\"prior\" + 0.017*\"estimation\" + 0.016*\"training\" + 0.014*\"dependency\" + 0.013*\"image\" + 0.010*\"data.\" + 0.009*\"bayesian\"\n",
      "2017-11-20 21:26:13,541 : INFO : topic #13 (0.010): 0.030*\"component\" + 0.029*\"face\" + 0.018*\"independent\" + 0.014*\"subject\" + 0.012*\"ica\" + 0.011*\"response\" + 0.011*\"activity\" + 0.011*\"stimulus\" + 0.010*\"representation\" + 0.009*\"study\"\n",
      "2017-11-20 21:26:13,542 : INFO : topic #93 (0.010): 0.017*\"policy\" + 0.014*\"reinforcement\" + 0.013*\"&\" + 0.013*\"state\" + 0.011*\"on-line\" + 0.011*\"em\" + 0.010*\"unit\" + 0.010*\"stochastic\" + 0.009*\"gradient\" + 0.009*\"rl\"\n",
      "2017-11-20 21:26:13,547 : INFO : topic diff=0.031185, rho=0.158114\n",
      "2017-11-20 21:26:19,626 : INFO : -8.117 per-word bound, 277.6 perplexity estimate based on a held-out corpus of 151 documents with 163809 words\n",
      "2017-11-20 21:26:19,629 : INFO : PROGRESS: pass 39, at document #151/151\n",
      "2017-11-20 21:26:21,212 : INFO : topic #83 (0.010): 0.036*\"front\" + 0.030*\"field\" + 0.017*\"along\" + 0.016*\"discontinuity\" + 0.016*\"covariance\" + 0.012*\"prior\" + 0.012*\"constrained\" + 0.010*\"(a)\" + 0.010*\"(b)\" + 0.010*\"frontal\"\n",
      "2017-11-20 21:26:21,213 : INFO : topic #86 (0.010): 0.006*\"sensor\" + 0.005*\"noise\" + 0.005*\"correlation\" + 0.005*\"binary\" + 0.004*\"r\" + 0.004*\"p\" + 0.004*\"local\" + 0.004*\"image\" + 0.003*\"line\" + 0.003*\"gaussian\"\n",
      "2017-11-20 21:26:21,215 : INFO : topic #5 (0.010): 0.046*\"synaptic\" + 0.029*\"synapsis\" + 0.017*\"prior\" + 0.015*\"modification\" + 0.015*\"pruning\" + 0.015*\"memory\" + 0.012*\"neuronal\" + 0.009*\"level\" + 0.009*\"robot\" + 0.008*\"object\"\n",
      "2017-11-20 21:26:21,216 : INFO : topic #21 (0.010): 0.000*\"&\" + 0.000*\"r\" + 0.000*\"state\" + 0.000*\"margin\" + 0.000*\"curve\" + 0.000*\"component\" + 0.000*\"signal\" + 0.000*\"training\" + 0.000*\"cell\" + 0.000*\"control\"\n",
      "2017-11-20 21:26:21,218 : INFO : topic #49 (0.010): 0.025*\"activity\" + 0.019*\"cortical\" + 0.019*\"noise\" + 0.018*\"variance\" + 0.017*\"line\" + 0.016*\"normalization\" + 0.016*\"spatial\" + 0.015*\"unit\" + 0.015*\"attractor\" + 0.015*\"ideal\"\n",
      "2017-11-20 21:26:21,223 : INFO : topic diff=0.028792, rho=0.156174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 5.52863933643\n",
      "Perplexity: 924.316031243\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "model2 = models.ldamodel.LdaModel(corpus, id2word=dictionary, num_topics=100, update_every=0, passes=40)\n",
    "print 'Evaluation time: {}'.format((time()-start) / 60)\n",
    "print 'Perplexity: {}'.format(perplexity(model2, corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель достигла лучшей перплексии, однако обучалась существенно дольше. Необходим подбор оптимального сочетания параметров, это требует большого числа экспериментов.\n",
    "Вернемся к первому набору параметров и изменим число тем со 100 на 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-11-20 21:26:22,332 : INFO : using symmetric alpha at 0.1\n",
      "2017-11-20 21:26:22,334 : INFO : using symmetric eta at 0.000189573459716\n",
      "2017-11-20 21:26:22,338 : INFO : using serial LDA version on this node\n",
      "2017-11-20 21:26:22,754 : INFO : running online (multi-pass) LDA training, 10 topics, 2 passes over the supplied corpus of 151 documents, updating model once every 50 documents, evaluating perplexity every 151 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2017-11-20 21:26:22,755 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2017-11-20 21:26:22,756 : INFO : PROGRESS: pass 0, at document #50/151\n",
      "2017-11-20 21:26:22,908 : INFO : merging changes from 50 documents into a model of 151 documents\n",
      "2017-11-20 21:26:23,163 : INFO : topic #2 (0.100): 0.008*\"state\" + 0.004*\"training\" + 0.004*\"control\" + 0.003*\"gaussian\" + 0.003*\"image\" + 0.003*\"&\" + 0.003*\"mixture\" + 0.003*\"rate\" + 0.003*\"dynamic\" + 0.003*\"p\"\n",
      "2017-11-20 21:26:23,165 : INFO : topic #8 (0.100): 0.005*\"state\" + 0.005*\"&\" + 0.004*\"image\" + 0.004*\"local\" + 0.003*\"visual\" + 0.003*\"gaussian\" + 0.003*\"em\" + 0.003*\"neuron\" + 0.003*\"mixture\" + 0.003*\"scene\"\n",
      "2017-11-20 21:26:23,166 : INFO : topic #5 (0.100): 0.008*\"state\" + 0.004*\"&\" + 0.004*\"control\" + 0.003*\"gaussian\" + 0.003*\"prior\" + 0.003*\"training\" + 0.003*\"correlation\" + 0.003*\"inverse\" + 0.003*\"dynamic\" + 0.003*\"p\"\n",
      "2017-11-20 21:26:23,167 : INFO : topic #0 (0.100): 0.006*\"image\" + 0.005*\"&\" + 0.004*\"state\" + 0.004*\"training\" + 0.004*\"noise\" + 0.003*\"prior\" + 0.003*\"sensor\" + 0.003*\"p\" + 0.003*\"control\" + 0.003*\"em\"\n",
      "2017-11-20 21:26:23,168 : INFO : topic #1 (0.100): 0.008*\"state\" + 0.005*\"policy\" + 0.004*\"&\" + 0.004*\"mode\" + 0.004*\"sample\" + 0.003*\"gaussian\" + 0.003*\"mixture\" + 0.003*\"firing\" + 0.003*\"neuron\" + 0.003*\"rate\"\n",
      "2017-11-20 21:26:23,170 : INFO : topic diff=1.733012, rho=1.000000\n",
      "2017-11-20 21:26:23,172 : INFO : PROGRESS: pass 0, at document #100/151\n",
      "2017-11-20 21:26:23,337 : INFO : merging changes from 50 documents into a model of 151 documents\n",
      "2017-11-20 21:26:23,555 : INFO : topic #5 (0.100): 0.008*\"state\" + 0.006*\"training\" + 0.005*\"entropic\" + 0.005*\"control\" + 0.005*\"bound\" + 0.004*\"&\" + 0.004*\"hand\" + 0.004*\"gaussian\" + 0.003*\"field\" + 0.003*\"prior\"\n",
      "2017-11-20 21:26:23,556 : INFO : topic #9 (0.100): 0.006*\"component\" + 0.005*\"bound\" + 0.005*\"kernel\" + 0.005*\"density\" + 0.004*\"gaussian\" + 0.004*\"training\" + 0.004*\"ica\" + 0.004*\"image\" + 0.004*\"mixture\" + 0.004*\"state\"\n",
      "2017-11-20 21:26:23,558 : INFO : topic #0 (0.100): 0.006*\"training\" + 0.005*\"image\" + 0.003*\"kernel\" + 0.003*\"classification\" + 0.003*\"&\" + 0.003*\"state\" + 0.002*\"noise\" + 0.002*\"recognition\" + 0.002*\"structure\" + 0.002*\"class\"\n",
      "2017-11-20 21:26:23,560 : INFO : topic #3 (0.100): 0.006*\"image\" + 0.006*\"chip\" + 0.006*\"training\" + 0.006*\"noise\" + 0.005*\"template\" + 0.005*\"analog\" + 0.004*\"signal\" + 0.004*\"classification\" + 0.003*\"pixel\" + 0.003*\"circuit\"\n",
      "2017-11-20 21:26:23,563 : INFO : topic #4 (0.100): 0.007*\"sound\" + 0.007*\"cell\" + 0.006*\"neuron\" + 0.006*\"response\" + 0.006*\"rate\" + 0.006*\"&\" + 0.005*\"firing\" + 0.004*\"visual\" + 0.004*\"synaptic\" + 0.004*\"stimulus\"\n",
      "2017-11-20 21:26:23,566 : INFO : topic diff=1.222573, rho=0.707107\n",
      "2017-11-20 21:26:23,567 : INFO : PROGRESS: pass 0, at document #150/151\n",
      "2017-11-20 21:26:23,762 : INFO : merging changes from 50 documents into a model of 151 documents\n",
      "2017-11-20 21:26:23,945 : INFO : topic #6 (0.100): 0.005*\"state\" + 0.004*\"image\" + 0.003*\"latent\" + 0.002*\"em\" + 0.002*\"&\" + 0.002*\"local\" + 0.002*\"neuron\" + 0.002*\"mixture\" + 0.002*\"sample\" + 0.002*\"human\"\n",
      "2017-11-20 21:26:23,947 : INFO : topic #4 (0.100): 0.016*\"synaptic\" + 0.011*\"spike\" + 0.010*\"neuron\" + 0.010*\"firing\" + 0.009*\"cell\" + 0.008*\"&\" + 0.007*\"response\" + 0.007*\"potential\" + 0.005*\"synapsis\" + 0.005*\"visual\"\n",
      "2017-11-20 21:26:23,953 : INFO : topic #1 (0.100): 0.029*\"policy\" + 0.024*\"state\" + 0.015*\"action\" + 0.011*\"agent\" + 0.009*\"reward\" + 0.008*\"environment\" + 0.007*\"markov\" + 0.007*\"observable\" + 0.006*\"decision\" + 0.006*\"reinforcement\"\n",
      "2017-11-20 21:26:23,955 : INFO : topic #3 (0.100): 0.008*\"image\" + 0.007*\"analog\" + 0.005*\"noise\" + 0.005*\"training\" + 0.004*\"signal\" + 0.004*\"cell\" + 0.003*\"search\" + 0.003*\"chip\" + 0.003*\"threshold\" + 0.003*\"visual\"\n",
      "2017-11-20 21:26:23,957 : INFO : topic #5 (0.100): 0.009*\"state\" + 0.007*\"dynamic\" + 0.006*\"bound\" + 0.006*\"training\" + 0.006*\"field\" + 0.005*\"approximation\" + 0.005*\"gaussian\" + 0.005*\"dynamical\" + 0.004*\"theory\" + 0.004*\"replica\"\n",
      "2017-11-20 21:26:23,959 : INFO : topic diff=0.930968, rho=0.577350\n",
      "2017-11-20 21:26:24,120 : INFO : -8.544 per-word bound, 373.2 perplexity estimate based on a held-out corpus of 1 documents with 1004 words\n",
      "2017-11-20 21:26:24,121 : INFO : PROGRESS: pass 0, at document #151/151\n",
      "2017-11-20 21:26:24,135 : INFO : merging changes from 1 documents into a model of 151 documents\n",
      "2017-11-20 21:26:24,314 : INFO : topic #8 (0.100): 0.006*\"state\" + 0.004*\"goal\" + 0.003*\"visual\" + 0.003*\"local\" + 0.003*\"&\" + 0.003*\"search\" + 0.003*\"centroid\" + 0.003*\"cell\" + 0.003*\"action\" + 0.002*\"task\"\n",
      "2017-11-20 21:26:24,315 : INFO : topic #3 (0.100): 0.007*\"training\" + 0.007*\"image\" + 0.006*\"analog\" + 0.005*\"noise\" + 0.004*\"classification\" + 0.004*\"excessive\" + 0.003*\"signal\" + 0.003*\"search\" + 0.003*\"cell\" + 0.003*\"chip\"\n",
      "2017-11-20 21:26:24,316 : INFO : topic #5 (0.100): 0.009*\"state\" + 0.007*\"dynamic\" + 0.006*\"bound\" + 0.006*\"training\" + 0.006*\"field\" + 0.005*\"approximation\" + 0.005*\"gaussian\" + 0.004*\"dynamical\" + 0.004*\"theory\" + 0.004*\"replica\"\n",
      "2017-11-20 21:26:24,318 : INFO : topic #7 (0.100): 0.028*\"working\" + 0.020*\"[19]\" + 0.010*\"[20]\" + 0.009*\"[18]\" + 0.009*\"[21]\" + 0.008*\"image\" + 0.006*\"subject\" + 0.006*\"field\" + 0.006*\"visual\" + 0.005*\"direction\"\n",
      "2017-11-20 21:26:24,321 : INFO : topic #2 (0.100): 0.014*\"control\" + 0.009*\"controller\" + 0.009*\"motor\" + 0.008*\"movement\" + 0.007*\"inverse\" + 0.006*\"arm\" + 0.006*\"forward\" + 0.006*\"position\" + 0.005*\"feedback\" + 0.005*\"visual\"\n",
      "2017-11-20 21:26:24,322 : INFO : topic diff=0.829243, rho=0.500000\n",
      "2017-11-20 21:26:24,324 : INFO : PROGRESS: pass 1, at document #50/151\n",
      "2017-11-20 21:26:24,654 : INFO : merging changes from 50 documents into a model of 151 documents\n",
      "2017-11-20 21:26:24,842 : INFO : topic #5 (0.100): 0.012*\"state\" + 0.008*\"gaussian\" + 0.008*\"approximation\" + 0.007*\"dynamic\" + 0.007*\"prior\" + 0.006*\"field\" + 0.006*\"p\" + 0.004*\"prediction\" + 0.004*\"posterior\" + 0.004*\"continuous\"\n",
      "2017-11-20 21:26:24,847 : INFO : topic #1 (0.100): 0.030*\"policy\" + 0.029*\"state\" + 0.017*\"action\" + 0.014*\"reinforcement\" + 0.011*\"agent\" + 0.011*\"reward\" + 0.009*\"&\" + 0.008*\"call\" + 0.008*\"markov\" + 0.008*\"q-learning\"\n",
      "2017-11-20 21:26:24,851 : INFO : topic #7 (0.100): 0.014*\"working\" + 0.012*\"population\" + 0.012*\"image\" + 0.010*\"scene\" + 0.009*\"[19]\" + 0.009*\"motion\" + 0.007*\"direction\" + 0.007*\"response\" + 0.007*\"visual\" + 0.006*\"field\"\n",
      "2017-11-20 21:26:24,855 : INFO : topic #3 (0.100): 0.010*\"image\" + 0.006*\"noise\" + 0.005*\"local\" + 0.004*\"positive\" + 0.004*\"training\" + 0.004*\"signal\" + 0.004*\"digit\" + 0.004*\"correlation\" + 0.003*\"sensor\" + 0.003*\"filter\"\n",
      "2017-11-20 21:26:24,857 : INFO : topic #9 (0.100): 0.013*\"working\" + 0.010*\"risk\" + 0.009*\"training\" + 0.007*\"class\" + 0.007*\"machine\" + 0.006*\"support\" + 0.005*\"mixture\" + 0.005*\"separation\" + 0.004*\"report\" + 0.004*\"generalization\"\n",
      "2017-11-20 21:26:24,863 : INFO : topic diff=0.959450, rho=0.447214\n",
      "2017-11-20 21:26:24,864 : INFO : PROGRESS: pass 1, at document #100/151\n",
      "2017-11-20 21:26:25,041 : INFO : merging changes from 50 documents into a model of 151 documents\n",
      "2017-11-20 21:26:25,144 : INFO : topic #7 (0.100): 0.014*\"motion\" + 0.012*\"direction\" + 0.011*\"image\" + 0.010*\"field\" + 0.009*\"code\" + 0.008*\"scene\" + 0.008*\"visual\" + 0.008*\"flow\" + 0.008*\"subject\" + 0.007*\"population\"\n",
      "2017-11-20 21:26:25,145 : INFO : topic #5 (0.100): 0.011*\"state\" + 0.009*\"gaussian\" + 0.007*\"field\" + 0.006*\"prior\" + 0.006*\"bound\" + 0.006*\"approximation\" + 0.005*\"dynamic\" + 0.005*\"training\" + 0.004*\"bayesian\" + 0.004*\"z\"\n",
      "2017-11-20 21:26:25,146 : INFO : topic #9 (0.100): 0.009*\"training\" + 0.008*\"working\" + 0.006*\"class\" + 0.006*\"risk\" + 0.006*\"kernel\" + 0.005*\"mixture\" + 0.005*\"bound\" + 0.004*\"machine\" + 0.004*\"component\" + 0.004*\"data.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-11-20 21:26:25,147 : INFO : topic #1 (0.100): 0.032*\"state\" + 0.022*\"policy\" + 0.018*\"action\" + 0.016*\"reinforcement\" + 0.011*\"reward\" + 0.009*\"agent\" + 0.009*\"goal\" + 0.008*\"rl\" + 0.008*\"call\" + 0.008*\"&\"\n",
      "2017-11-20 21:26:25,149 : INFO : topic #3 (0.100): 0.009*\"image\" + 0.006*\"noise\" + 0.005*\"signal\" + 0.004*\"local\" + 0.004*\"training\" + 0.003*\"chip\" + 0.003*\"positive\" + 0.003*\"analog\" + 0.003*\"classification\" + 0.003*\"table\"\n",
      "2017-11-20 21:26:25,150 : INFO : topic diff=0.748878, rho=0.447214\n",
      "2017-11-20 21:26:25,151 : INFO : PROGRESS: pass 1, at document #150/151\n",
      "2017-11-20 21:26:25,322 : INFO : merging changes from 50 documents into a model of 151 documents\n",
      "2017-11-20 21:26:25,432 : INFO : topic #3 (0.100): 0.010*\"image\" + 0.005*\"noise\" + 0.004*\"local\" + 0.004*\"signal\" + 0.003*\"threshold\" + 0.003*\"analog\" + 0.003*\"positive\" + 0.003*\"face\" + 0.003*\"search\" + 0.003*\"object\"\n",
      "2017-11-20 21:26:25,434 : INFO : topic #6 (0.100): 0.008*\"24\" + 0.005*\"42\" + 0.004*\"64\" + 0.004*\"32\" + 0.003*\"anderson\" + 0.003*\"49\" + 0.003*\"36\" + 0.002*\"human\" + 0.002*\"8\" + 0.002*\"56\"\n",
      "2017-11-20 21:26:25,435 : INFO : topic #8 (0.100): 0.023*\"centroid\" + 0.013*\"hmm\" + 0.010*\"real-time\" + 0.009*\"behavior\" + 0.006*\"state\" + 0.005*\"utility\" + 0.004*\"edge\" + 0.004*\"traffic\" + 0.004*\"hmms\" + 0.004*\"goal\"\n",
      "2017-11-20 21:26:25,437 : INFO : topic #9 (0.100): 0.006*\"training\" + 0.006*\"bound\" + 0.005*\"class\" + 0.005*\"mixture\" + 0.005*\"kernel\" + 0.004*\"gaussian\" + 0.004*\"working\" + 0.004*\"component\" + 0.004*\"w\" + 0.003*\"basis\"\n",
      "2017-11-20 21:26:25,439 : INFO : topic #0 (0.100): 0.022*\"training\" + 0.018*\"support\" + 0.013*\"machine\" + 0.010*\"class\" + 0.009*\"working\" + 0.007*\"classification\" + 0.007*\"programming\" + 0.005*\"generalization\" + 0.005*\"r\" + 0.005*\"minimization\"\n",
      "2017-11-20 21:26:25,441 : INFO : topic diff=0.661249, rho=0.447214\n",
      "2017-11-20 21:26:25,532 : INFO : -6.847 per-word bound, 115.1 perplexity estimate based on a held-out corpus of 1 documents with 1004 words\n",
      "2017-11-20 21:26:25,533 : INFO : PROGRESS: pass 1, at document #151/151\n",
      "2017-11-20 21:26:25,541 : INFO : merging changes from 1 documents into a model of 151 documents\n",
      "2017-11-20 21:26:25,653 : INFO : topic #4 (0.100): 0.014*\"synaptic\" + 0.014*\"neuron\" + 0.013*\"cell\" + 0.011*\"spike\" + 0.010*\"&\" + 0.009*\"firing\" + 0.008*\"response\" + 0.007*\"visual\" + 0.006*\"rate\" + 0.006*\"potential\"\n",
      "2017-11-20 21:26:25,654 : INFO : topic #5 (0.100): 0.010*\"state\" + 0.009*\"gaussian\" + 0.009*\"approximation\" + 0.008*\"field\" + 0.008*\"bound\" + 0.007*\"dynamic\" + 0.006*\"prior\" + 0.005*\"<\" + 0.005*\"approximate\" + 0.004*\"p\"\n",
      "2017-11-20 21:26:25,656 : INFO : topic #6 (0.100): 0.005*\"24\" + 0.003*\"42\" + 0.003*\"64\" + 0.003*\"32\" + 0.002*\"anderson\" + 0.002*\"49\" + 0.002*\"36\" + 0.002*\"human\" + 0.001*\"8\" + 0.001*\"56\"\n",
      "2017-11-20 21:26:25,657 : INFO : topic #7 (0.100): 0.028*\"[19]\" + 0.014*\"[20]\" + 0.014*\"[18]\" + 0.014*\"[21]\" + 0.012*\"image\" + 0.010*\"direction\" + 0.009*\"visual\" + 0.008*\"field\" + 0.008*\"motion\" + 0.008*\"subject\"\n",
      "2017-11-20 21:26:25,659 : INFO : topic #1 (0.100): 0.031*\"state\" + 0.026*\"policy\" + 0.018*\"action\" + 0.012*\"reinforcement\" + 0.011*\"agent\" + 0.011*\"reward\" + 0.009*\"markov\" + 0.009*\"rule\" + 0.008*\"goal\" + 0.008*\"environment\"\n",
      "2017-11-20 21:26:25,660 : INFO : topic diff=0.581420, rho=0.447214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.0555105487506\n",
      "Perplexity: 2209.30254877\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "model3 = models.ldamodel.LdaModel(corpus, id2word=dictionary, num_topics=10, chunksize=50, update_every=1, passes=2)\n",
    "print 'Evaluation time: {}'.format((time()-start) / 60)\n",
    "print 'Perplexity: {}'.format(perplexity(model3, corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'support', 0.029594530878726873), (u'working', 0.028824752811899751), (u'training', 0.027516832356565924), (u'machine', 0.021043665306824198), (u'risk', 0.013302220106854666), (u'class', 0.012630401324539856), (u'programming', 0.012238905652198663), (u'minimization', 0.0094320478359836112), (u'generalization', 0.0094017053733239861), (u'report', 0.009215761728858898)]\n",
      "\n",
      "\n",
      "[(u'image', 0.010090392053099801), (u'noise', 0.0046954181204268974), (u'local', 0.0039500088225083597), (u'signal', 0.0037404104351476393), (u'threshold', 0.0033781726334125867), (u'analog', 0.0032772846987465659), (u'positive', 0.0029807202894130591), (u'face', 0.002883885140207345), (u'search', 0.0028752837119423707), (u'object', 0.0028203075582538756)]\n",
      "\n",
      "\n",
      "[(u'state', 0.01045846117756415), (u'gaussian', 0.009328695143350902), (u'approximation', 0.0088967206012617647), (u'field', 0.0080576052730342573), (u'bound', 0.0076814415549904379), (u'dynamic', 0.0067732571423206123), (u'prior', 0.0060379594504235742), (u'<', 0.0049668532336510623), (u'approximate', 0.0046865197369878493), (u'p', 0.004441916511274166)]\n",
      "\n",
      "\n",
      "[(u'24', 0.0050961195521310697), (u'42', 0.0033779547353989495), (u'64', 0.0027822998062662268), (u'32', 0.0026369064739531051), (u'anderson', 0.0017292322872529944), (u'49', 0.0016682489463024598), (u'36', 0.0016437099466024344), (u'human', 0.0015363751235594198), (u'8', 0.0014276802043636677), (u'56', 0.0012515908922609254)]\n",
      "\n",
      "\n",
      "[(u'[19]', 0.027933105677298977), (u'[20]', 0.014157259944852195), (u'[18]', 0.013987975301298208), (u'[21]', 0.013765767915714275), (u'image', 0.012184307073574733), (u'direction', 0.0095769356326792215), (u'visual', 0.0089375876072701442), (u'field', 0.0082523725882935779), (u'motion', 0.0078297616933250356), (u'subject', 0.0078040042766423633)]\n",
      "\n",
      "\n",
      "[(u'centroid', 0.0166159420061835), (u'hmm', 0.0093036286809894536), (u'real-time', 0.0076914361314824103), (u'behavior', 0.0065849733143975653), (u'state', 0.0047414620208485365), (u'utility', 0.0033789228526008323), (u'edge', 0.0032536774792371864), (u'traffic', 0.0032106540523451563), (u'hmms', 0.0031335046879144416), (u'goal', 0.0030683948594422039)]\n",
      "\n",
      "\n",
      "[(u'training', 0.0062428165257174973), (u'bound', 0.0060933377503196535), (u'class', 0.0055231178476598721), (u'mixture', 0.0051298654463248312), (u'kernel', 0.0045839615705869242), (u'working', 0.0043745309558141758), (u'w', 0.0039376071928261952), (u'risk', 0.003756400183336667), (u'gaussian', 0.0037525628050480292), (u'component', 0.003692970586852909)]\n",
      "\n",
      "\n",
      "\n",
      "[(u'support', 0.029594530878726873), (u'working', 0.028824752811899751), (u'training', 0.027516832356565924), (u'machine', 0.021043665306824198), (u'risk', 0.013302220106854666), (u'class', 0.012630401324539856), (u'programming', 0.012238905652198663), (u'minimization', 0.0094320478359836112), (u'generalization', 0.0094017053733239861), (u'report', 0.009215761728858898)]\n",
      "\n",
      "\n",
      "[(u'image', 0.010090392053099801), (u'noise', 0.0046954181204268974), (u'local', 0.0039500088225083597), (u'signal', 0.0037404104351476393), (u'threshold', 0.0033781726334125867), (u'analog', 0.0032772846987465659), (u'positive', 0.0029807202894130591), (u'face', 0.002883885140207345), (u'search', 0.0028752837119423707), (u'object', 0.0028203075582538756)]\n",
      "\n",
      "\n",
      "[(u'state', 0.01045846117756415), (u'gaussian', 0.009328695143350902), (u'approximation', 0.0088967206012617647), (u'field', 0.0080576052730342573), (u'bound', 0.0076814415549904379), (u'dynamic', 0.0067732571423206123), (u'prior', 0.0060379594504235742), (u'<', 0.0049668532336510623), (u'approximate', 0.0046865197369878493), (u'p', 0.004441916511274166)]\n",
      "\n",
      "\n",
      "[(u'24', 0.0050961195521310697), (u'42', 0.0033779547353989495), (u'64', 0.0027822998062662268), (u'32', 0.0026369064739531051), (u'anderson', 0.0017292322872529944), (u'49', 0.0016682489463024598), (u'36', 0.0016437099466024344), (u'human', 0.0015363751235594198), (u'8', 0.0014276802043636677), (u'56', 0.0012515908922609254)]\n",
      "\n",
      "\n",
      "[(u'[19]', 0.027933105677298977), (u'[20]', 0.014157259944852195), (u'[18]', 0.013987975301298208), (u'[21]', 0.013765767915714275), (u'image', 0.012184307073574733), (u'direction', 0.0095769356326792215), (u'visual', 0.0089375876072701442), (u'field', 0.0082523725882935779), (u'motion', 0.0078297616933250356), (u'subject', 0.0078040042766423633)]\n",
      "\n",
      "\n",
      "[(u'centroid', 0.0166159420061835), (u'hmm', 0.0093036286809894536), (u'real-time', 0.0076914361314824103), (u'behavior', 0.0065849733143975653), (u'state', 0.0047414620208485365), (u'utility', 0.0033789228526008323), (u'edge', 0.0032536774792371864), (u'traffic', 0.0032106540523451563), (u'hmms', 0.0031335046879144416), (u'goal', 0.0030683948594422039)]\n",
      "\n",
      "\n",
      "[(u'training', 0.0062428165257174973), (u'bound', 0.0060933377503196535), (u'class', 0.0055231178476598721), (u'mixture', 0.0051298654463248312), (u'kernel', 0.0045839615705869242), (u'working', 0.0043745309558141758), (u'w', 0.0039376071928261952), (u'risk', 0.003756400183336667), (u'gaussian', 0.0037525628050480292), (u'component', 0.003692970586852909)]\n",
      "\n",
      "\n",
      "\n",
      "[(u'support', 0.029594530878726873), (u'working', 0.028824752811899751), (u'training', 0.027516832356565924), (u'machine', 0.021043665306824198), (u'risk', 0.013302220106854666), (u'class', 0.012630401324539856), (u'programming', 0.012238905652198663), (u'minimization', 0.0094320478359836112), (u'generalization', 0.0094017053733239861), (u'report', 0.009215761728858898)]\n",
      "\n",
      "\n",
      "[(u'image', 0.010090392053099801), (u'noise', 0.0046954181204268974), (u'local', 0.0039500088225083597), (u'signal', 0.0037404104351476393), (u'threshold', 0.0033781726334125867), (u'analog', 0.0032772846987465659), (u'positive', 0.0029807202894130591), (u'face', 0.002883885140207345), (u'search', 0.0028752837119423707), (u'object', 0.0028203075582538756)]\n",
      "\n",
      "\n",
      "[(u'state', 0.01045846117756415), (u'gaussian', 0.009328695143350902), (u'approximation', 0.0088967206012617647), (u'field', 0.0080576052730342573), (u'bound', 0.0076814415549904379), (u'dynamic', 0.0067732571423206123), (u'prior', 0.0060379594504235742), (u'<', 0.0049668532336510623), (u'approximate', 0.0046865197369878493), (u'p', 0.004441916511274166)]\n",
      "\n",
      "\n",
      "[(u'24', 0.0050961195521310697), (u'42', 0.0033779547353989495), (u'64', 0.0027822998062662268), (u'32', 0.0026369064739531051), (u'anderson', 0.0017292322872529944), (u'49', 0.0016682489463024598), (u'36', 0.0016437099466024344), (u'human', 0.0015363751235594198), (u'8', 0.0014276802043636677), (u'56', 0.0012515908922609254)]\n",
      "\n",
      "\n",
      "[(u'[19]', 0.027933105677298977), (u'[20]', 0.014157259944852195), (u'[18]', 0.013987975301298208), (u'[21]', 0.013765767915714275), (u'image', 0.012184307073574733), (u'direction', 0.0095769356326792215), (u'visual', 0.0089375876072701442), (u'field', 0.0082523725882935779), (u'motion', 0.0078297616933250356), (u'subject', 0.0078040042766423633)]\n",
      "\n",
      "\n",
      "[(u'centroid', 0.0166159420061835), (u'hmm', 0.0093036286809894536), (u'real-time', 0.0076914361314824103), (u'behavior', 0.0065849733143975653), (u'state', 0.0047414620208485365), (u'utility', 0.0033789228526008323), (u'edge', 0.0032536774792371864), (u'traffic', 0.0032106540523451563), (u'hmms', 0.0031335046879144416), (u'goal', 0.0030683948594422039)]\n",
      "\n",
      "\n",
      "[(u'training', 0.0062428165257174973), (u'bound', 0.0060933377503196535), (u'class', 0.0055231178476598721), (u'mixture', 0.0051298654463248312), (u'kernel', 0.0045839615705869242), (u'working', 0.0043745309558141758), (u'w', 0.0039376071928261952), (u'risk', 0.003756400183336667), (u'gaussian', 0.0037525628050480292), (u'component', 0.003692970586852909)]\n",
      "\n",
      "\n",
      "\n",
      "[(u'support', 0.029594530878726873), (u'working', 0.028824752811899751), (u'training', 0.027516832356565924), (u'machine', 0.021043665306824198), (u'risk', 0.013302220106854666), (u'class', 0.012630401324539856), (u'programming', 0.012238905652198663), (u'minimization', 0.0094320478359836112), (u'generalization', 0.0094017053733239861), (u'report', 0.009215761728858898)]\n",
      "\n",
      "\n",
      "[(u'image', 0.010090392053099801), (u'noise', 0.0046954181204268974), (u'local', 0.0039500088225083597), (u'signal', 0.0037404104351476393), (u'threshold', 0.0033781726334125867), (u'analog', 0.0032772846987465659), (u'positive', 0.0029807202894130591), (u'face', 0.002883885140207345), (u'search', 0.0028752837119423707), (u'object', 0.0028203075582538756)]\n",
      "\n",
      "\n",
      "[(u'state', 0.01045846117756415), (u'gaussian', 0.009328695143350902), (u'approximation', 0.0088967206012617647), (u'field', 0.0080576052730342573), (u'bound', 0.0076814415549904379), (u'dynamic', 0.0067732571423206123), (u'prior', 0.0060379594504235742), (u'<', 0.0049668532336510623), (u'approximate', 0.0046865197369878493), (u'p', 0.004441916511274166)]\n",
      "\n",
      "\n",
      "[(u'24', 0.0050961195521310697), (u'42', 0.0033779547353989495), (u'64', 0.0027822998062662268), (u'32', 0.0026369064739531051), (u'anderson', 0.0017292322872529944), (u'49', 0.0016682489463024598), (u'36', 0.0016437099466024344), (u'human', 0.0015363751235594198), (u'8', 0.0014276802043636677), (u'56', 0.0012515908922609254)]\n",
      "\n",
      "\n",
      "[(u'[19]', 0.027933105677298977), (u'[20]', 0.014157259944852195), (u'[18]', 0.013987975301298208), (u'[21]', 0.013765767915714275), (u'image', 0.012184307073574733), (u'direction', 0.0095769356326792215), (u'visual', 0.0089375876072701442), (u'field', 0.0082523725882935779), (u'motion', 0.0078297616933250356), (u'subject', 0.0078040042766423633)]\n",
      "\n",
      "\n",
      "[(u'centroid', 0.0166159420061835), (u'hmm', 0.0093036286809894536), (u'real-time', 0.0076914361314824103), (u'behavior', 0.0065849733143975653), (u'state', 0.0047414620208485365), (u'utility', 0.0033789228526008323), (u'edge', 0.0032536774792371864), (u'traffic', 0.0032106540523451563), (u'hmms', 0.0031335046879144416), (u'goal', 0.0030683948594422039)]\n",
      "\n",
      "\n",
      "[(u'training', 0.0062428165257174973), (u'bound', 0.0060933377503196535), (u'class', 0.0055231178476598721), (u'mixture', 0.0051298654463248312), (u'kernel', 0.0045839615705869242), (u'working', 0.0043745309558141758), (u'w', 0.0039376071928261952), (u'risk', 0.003756400183336667), (u'gaussian', 0.0037525628050480292), (u'component', 0.003692970586852909)]\n",
      "\n",
      "\n",
      "\n",
      "[(u'support', 0.029594530878726873), (u'working', 0.028824752811899751), (u'training', 0.027516832356565924), (u'machine', 0.021043665306824198), (u'risk', 0.013302220106854666), (u'class', 0.012630401324539856), (u'programming', 0.012238905652198663), (u'minimization', 0.0094320478359836112), (u'generalization', 0.0094017053733239861), (u'report', 0.009215761728858898)]\n",
      "\n",
      "\n",
      "[(u'image', 0.010090392053099801), (u'noise', 0.0046954181204268974), (u'local', 0.0039500088225083597), (u'signal', 0.0037404104351476393), (u'threshold', 0.0033781726334125867), (u'analog', 0.0032772846987465659), (u'positive', 0.0029807202894130591), (u'face', 0.002883885140207345), (u'search', 0.0028752837119423707), (u'object', 0.0028203075582538756)]\n",
      "\n",
      "\n",
      "[(u'state', 0.01045846117756415), (u'gaussian', 0.009328695143350902), (u'approximation', 0.0088967206012617647), (u'field', 0.0080576052730342573), (u'bound', 0.0076814415549904379), (u'dynamic', 0.0067732571423206123), (u'prior', 0.0060379594504235742), (u'<', 0.0049668532336510623), (u'approximate', 0.0046865197369878493), (u'p', 0.004441916511274166)]\n",
      "\n",
      "\n",
      "[(u'24', 0.0050961195521310697), (u'42', 0.0033779547353989495), (u'64', 0.0027822998062662268), (u'32', 0.0026369064739531051), (u'anderson', 0.0017292322872529944), (u'49', 0.0016682489463024598), (u'36', 0.0016437099466024344), (u'human', 0.0015363751235594198), (u'8', 0.0014276802043636677), (u'56', 0.0012515908922609254)]\n",
      "\n",
      "\n",
      "[(u'[19]', 0.027933105677298977), (u'[20]', 0.014157259944852195), (u'[18]', 0.013987975301298208), (u'[21]', 0.013765767915714275), (u'image', 0.012184307073574733), (u'direction', 0.0095769356326792215), (u'visual', 0.0089375876072701442), (u'field', 0.0082523725882935779), (u'motion', 0.0078297616933250356), (u'subject', 0.0078040042766423633)]\n",
      "\n",
      "\n",
      "[(u'centroid', 0.0166159420061835), (u'hmm', 0.0093036286809894536), (u'real-time', 0.0076914361314824103), (u'behavior', 0.0065849733143975653), (u'state', 0.0047414620208485365), (u'utility', 0.0033789228526008323), (u'edge', 0.0032536774792371864), (u'traffic', 0.0032106540523451563), (u'hmms', 0.0031335046879144416), (u'goal', 0.0030683948594422039)]\n",
      "\n",
      "\n",
      "[(u'training', 0.0062428165257174973), (u'bound', 0.0060933377503196535), (u'class', 0.0055231178476598721), (u'mixture', 0.0051298654463248312), (u'kernel', 0.0045839615705869242), (u'working', 0.0043745309558141758), (u'w', 0.0039376071928261952), (u'risk', 0.003756400183336667), (u'gaussian', 0.0037525628050480292), (u'component', 0.003692970586852909)]\n",
      "\n",
      "\n",
      "\n",
      "[(u'support', 0.029594530878726873), (u'working', 0.028824752811899751), (u'training', 0.027516832356565924), (u'machine', 0.021043665306824198), (u'risk', 0.013302220106854666), (u'class', 0.012630401324539856), (u'programming', 0.012238905652198663), (u'minimization', 0.0094320478359836112), (u'generalization', 0.0094017053733239861), (u'report', 0.009215761728858898)]\n",
      "\n",
      "\n",
      "[(u'image', 0.010090392053099801), (u'noise', 0.0046954181204268974), (u'local', 0.0039500088225083597), (u'signal', 0.0037404104351476393), (u'threshold', 0.0033781726334125867), (u'analog', 0.0032772846987465659), (u'positive', 0.0029807202894130591), (u'face', 0.002883885140207345), (u'search', 0.0028752837119423707), (u'object', 0.0028203075582538756)]\n",
      "\n",
      "\n",
      "[(u'state', 0.01045846117756415), (u'gaussian', 0.009328695143350902), (u'approximation', 0.0088967206012617647), (u'field', 0.0080576052730342573), (u'bound', 0.0076814415549904379), (u'dynamic', 0.0067732571423206123), (u'prior', 0.0060379594504235742), (u'<', 0.0049668532336510623), (u'approximate', 0.0046865197369878493), (u'p', 0.004441916511274166)]\n",
      "\n",
      "\n",
      "[(u'24', 0.0050961195521310697), (u'42', 0.0033779547353989495), (u'64', 0.0027822998062662268), (u'32', 0.0026369064739531051), (u'anderson', 0.0017292322872529944), (u'49', 0.0016682489463024598), (u'36', 0.0016437099466024344), (u'human', 0.0015363751235594198), (u'8', 0.0014276802043636677), (u'56', 0.0012515908922609254)]\n",
      "\n",
      "\n",
      "[(u'[19]', 0.027933105677298977), (u'[20]', 0.014157259944852195), (u'[18]', 0.013987975301298208), (u'[21]', 0.013765767915714275), (u'image', 0.012184307073574733), (u'direction', 0.0095769356326792215), (u'visual', 0.0089375876072701442), (u'field', 0.0082523725882935779), (u'motion', 0.0078297616933250356), (u'subject', 0.0078040042766423633)]\n",
      "\n",
      "\n",
      "[(u'centroid', 0.0166159420061835), (u'hmm', 0.0093036286809894536), (u'real-time', 0.0076914361314824103), (u'behavior', 0.0065849733143975653), (u'state', 0.0047414620208485365), (u'utility', 0.0033789228526008323), (u'edge', 0.0032536774792371864), (u'traffic', 0.0032106540523451563), (u'hmms', 0.0031335046879144416), (u'goal', 0.0030683948594422039)]\n",
      "\n",
      "\n",
      "[(u'training', 0.0062428165257174973), (u'bound', 0.0060933377503196535), (u'class', 0.0055231178476598721), (u'mixture', 0.0051298654463248312), (u'kernel', 0.0045839615705869242), (u'working', 0.0043745309558141758), (u'w', 0.0039376071928261952), (u'risk', 0.003756400183336667), (u'gaussian', 0.0037525628050480292), (u'component', 0.003692970586852909)]\n",
      "\n",
      "\n",
      "\n",
      "[(u'support', 0.029594530878726873), (u'working', 0.028824752811899751), (u'training', 0.027516832356565924), (u'machine', 0.021043665306824198), (u'risk', 0.013302220106854666), (u'class', 0.012630401324539856), (u'programming', 0.012238905652198663), (u'minimization', 0.0094320478359836112), (u'generalization', 0.0094017053733239861), (u'report', 0.009215761728858898)]\n",
      "\n",
      "\n",
      "[(u'image', 0.010090392053099801), (u'noise', 0.0046954181204268974), (u'local', 0.0039500088225083597), (u'signal', 0.0037404104351476393), (u'threshold', 0.0033781726334125867), (u'analog', 0.0032772846987465659), (u'positive', 0.0029807202894130591), (u'face', 0.002883885140207345), (u'search', 0.0028752837119423707), (u'object', 0.0028203075582538756)]\n",
      "\n",
      "\n",
      "[(u'state', 0.01045846117756415), (u'gaussian', 0.009328695143350902), (u'approximation', 0.0088967206012617647), (u'field', 0.0080576052730342573), (u'bound', 0.0076814415549904379), (u'dynamic', 0.0067732571423206123), (u'prior', 0.0060379594504235742), (u'<', 0.0049668532336510623), (u'approximate', 0.0046865197369878493), (u'p', 0.004441916511274166)]\n",
      "\n",
      "\n",
      "[(u'24', 0.0050961195521310697), (u'42', 0.0033779547353989495), (u'64', 0.0027822998062662268), (u'32', 0.0026369064739531051), (u'anderson', 0.0017292322872529944), (u'49', 0.0016682489463024598), (u'36', 0.0016437099466024344), (u'human', 0.0015363751235594198), (u'8', 0.0014276802043636677), (u'56', 0.0012515908922609254)]\n",
      "\n",
      "\n",
      "[(u'[19]', 0.027933105677298977), (u'[20]', 0.014157259944852195), (u'[18]', 0.013987975301298208), (u'[21]', 0.013765767915714275), (u'image', 0.012184307073574733), (u'direction', 0.0095769356326792215), (u'visual', 0.0089375876072701442), (u'field', 0.0082523725882935779), (u'motion', 0.0078297616933250356), (u'subject', 0.0078040042766423633)]\n",
      "\n",
      "\n",
      "[(u'centroid', 0.0166159420061835), (u'hmm', 0.0093036286809894536), (u'real-time', 0.0076914361314824103), (u'behavior', 0.0065849733143975653), (u'state', 0.0047414620208485365), (u'utility', 0.0033789228526008323), (u'edge', 0.0032536774792371864), (u'traffic', 0.0032106540523451563), (u'hmms', 0.0031335046879144416), (u'goal', 0.0030683948594422039)]\n",
      "\n",
      "\n",
      "[(u'training', 0.0062428165257174973), (u'bound', 0.0060933377503196535), (u'class', 0.0055231178476598721), (u'mixture', 0.0051298654463248312), (u'kernel', 0.0045839615705869242), (u'working', 0.0043745309558141758), (u'w', 0.0039376071928261952), (u'risk', 0.003756400183336667), (u'gaussian', 0.0037525628050480292), (u'component', 0.003692970586852909)]\n",
      "\n",
      "\n",
      "\n",
      "[(u'support', 0.029594530878726873), (u'working', 0.028824752811899751), (u'training', 0.027516832356565924), (u'machine', 0.021043665306824198), (u'risk', 0.013302220106854666), (u'class', 0.012630401324539856), (u'programming', 0.012238905652198663), (u'minimization', 0.0094320478359836112), (u'generalization', 0.0094017053733239861), (u'report', 0.009215761728858898)]\n",
      "\n",
      "\n",
      "[(u'image', 0.010090392053099801), (u'noise', 0.0046954181204268974), (u'local', 0.0039500088225083597), (u'signal', 0.0037404104351476393), (u'threshold', 0.0033781726334125867), (u'analog', 0.0032772846987465659), (u'positive', 0.0029807202894130591), (u'face', 0.002883885140207345), (u'search', 0.0028752837119423707), (u'object', 0.0028203075582538756)]\n",
      "\n",
      "\n",
      "[(u'state', 0.01045846117756415), (u'gaussian', 0.009328695143350902), (u'approximation', 0.0088967206012617647), (u'field', 0.0080576052730342573), (u'bound', 0.0076814415549904379), (u'dynamic', 0.0067732571423206123), (u'prior', 0.0060379594504235742), (u'<', 0.0049668532336510623), (u'approximate', 0.0046865197369878493), (u'p', 0.004441916511274166)]\n",
      "\n",
      "\n",
      "[(u'24', 0.0050961195521310697), (u'42', 0.0033779547353989495), (u'64', 0.0027822998062662268), (u'32', 0.0026369064739531051), (u'anderson', 0.0017292322872529944), (u'49', 0.0016682489463024598), (u'36', 0.0016437099466024344), (u'human', 0.0015363751235594198), (u'8', 0.0014276802043636677), (u'56', 0.0012515908922609254)]\n",
      "\n",
      "\n",
      "[(u'[19]', 0.027933105677298977), (u'[20]', 0.014157259944852195), (u'[18]', 0.013987975301298208), (u'[21]', 0.013765767915714275), (u'image', 0.012184307073574733), (u'direction', 0.0095769356326792215), (u'visual', 0.0089375876072701442), (u'field', 0.0082523725882935779), (u'motion', 0.0078297616933250356), (u'subject', 0.0078040042766423633)]\n",
      "\n",
      "\n",
      "[(u'centroid', 0.0166159420061835), (u'hmm', 0.0093036286809894536), (u'real-time', 0.0076914361314824103), (u'behavior', 0.0065849733143975653), (u'state', 0.0047414620208485365), (u'utility', 0.0033789228526008323), (u'edge', 0.0032536774792371864), (u'traffic', 0.0032106540523451563), (u'hmms', 0.0031335046879144416), (u'goal', 0.0030683948594422039)]\n",
      "\n",
      "\n",
      "[(u'training', 0.0062428165257174973), (u'bound', 0.0060933377503196535), (u'class', 0.0055231178476598721), (u'mixture', 0.0051298654463248312), (u'kernel', 0.0045839615705869242), (u'working', 0.0043745309558141758), (u'w', 0.0039376071928261952), (u'risk', 0.003756400183336667), (u'gaussian', 0.0037525628050480292), (u'component', 0.003692970586852909)]\n",
      "\n",
      "\n",
      "\n",
      "[(u'support', 0.029594530878726873), (u'working', 0.028824752811899751), (u'training', 0.027516832356565924), (u'machine', 0.021043665306824198), (u'risk', 0.013302220106854666), (u'class', 0.012630401324539856), (u'programming', 0.012238905652198663), (u'minimization', 0.0094320478359836112), (u'generalization', 0.0094017053733239861), (u'report', 0.009215761728858898)]\n",
      "\n",
      "\n",
      "[(u'image', 0.010090392053099801), (u'noise', 0.0046954181204268974), (u'local', 0.0039500088225083597), (u'signal', 0.0037404104351476393), (u'threshold', 0.0033781726334125867), (u'analog', 0.0032772846987465659), (u'positive', 0.0029807202894130591), (u'face', 0.002883885140207345), (u'search', 0.0028752837119423707), (u'object', 0.0028203075582538756)]\n",
      "\n",
      "\n",
      "[(u'state', 0.01045846117756415), (u'gaussian', 0.009328695143350902), (u'approximation', 0.0088967206012617647), (u'field', 0.0080576052730342573), (u'bound', 0.0076814415549904379), (u'dynamic', 0.0067732571423206123), (u'prior', 0.0060379594504235742), (u'<', 0.0049668532336510623), (u'approximate', 0.0046865197369878493), (u'p', 0.004441916511274166)]\n",
      "\n",
      "\n",
      "[(u'24', 0.0050961195521310697), (u'42', 0.0033779547353989495), (u'64', 0.0027822998062662268), (u'32', 0.0026369064739531051), (u'anderson', 0.0017292322872529944), (u'49', 0.0016682489463024598), (u'36', 0.0016437099466024344), (u'human', 0.0015363751235594198), (u'8', 0.0014276802043636677), (u'56', 0.0012515908922609254)]\n",
      "\n",
      "\n",
      "[(u'[19]', 0.027933105677298977), (u'[20]', 0.014157259944852195), (u'[18]', 0.013987975301298208), (u'[21]', 0.013765767915714275), (u'image', 0.012184307073574733), (u'direction', 0.0095769356326792215), (u'visual', 0.0089375876072701442), (u'field', 0.0082523725882935779), (u'motion', 0.0078297616933250356), (u'subject', 0.0078040042766423633)]\n",
      "\n",
      "\n",
      "[(u'centroid', 0.0166159420061835), (u'hmm', 0.0093036286809894536), (u'real-time', 0.0076914361314824103), (u'behavior', 0.0065849733143975653), (u'state', 0.0047414620208485365), (u'utility', 0.0033789228526008323), (u'edge', 0.0032536774792371864), (u'traffic', 0.0032106540523451563), (u'hmms', 0.0031335046879144416), (u'goal', 0.0030683948594422039)]\n",
      "\n",
      "\n",
      "[(u'training', 0.0062428165257174973), (u'bound', 0.0060933377503196535), (u'class', 0.0055231178476598721), (u'mixture', 0.0051298654463248312), (u'kernel', 0.0045839615705869242), (u'working', 0.0043745309558141758), (u'w', 0.0039376071928261952), (u'risk', 0.003756400183336667), (u'gaussian', 0.0037525628050480292), (u'component', 0.003692970586852909)]\n",
      "\n",
      "\n",
      "\n",
      "[(u'support', 0.029594530878726873), (u'working', 0.028824752811899751), (u'training', 0.027516832356565924), (u'machine', 0.021043665306824198), (u'risk', 0.013302220106854666), (u'class', 0.012630401324539856), (u'programming', 0.012238905652198663), (u'minimization', 0.0094320478359836112), (u'generalization', 0.0094017053733239861), (u'report', 0.009215761728858898)]\n",
      "\n",
      "\n",
      "[(u'image', 0.010090392053099801), (u'noise', 0.0046954181204268974), (u'local', 0.0039500088225083597), (u'signal', 0.0037404104351476393), (u'threshold', 0.0033781726334125867), (u'analog', 0.0032772846987465659), (u'positive', 0.0029807202894130591), (u'face', 0.002883885140207345), (u'search', 0.0028752837119423707), (u'object', 0.0028203075582538756)]\n",
      "\n",
      "\n",
      "[(u'state', 0.01045846117756415), (u'gaussian', 0.009328695143350902), (u'approximation', 0.0088967206012617647), (u'field', 0.0080576052730342573), (u'bound', 0.0076814415549904379), (u'dynamic', 0.0067732571423206123), (u'prior', 0.0060379594504235742), (u'<', 0.0049668532336510623), (u'approximate', 0.0046865197369878493), (u'p', 0.004441916511274166)]\n",
      "\n",
      "\n",
      "[(u'24', 0.0050961195521310697), (u'42', 0.0033779547353989495), (u'64', 0.0027822998062662268), (u'32', 0.0026369064739531051), (u'anderson', 0.0017292322872529944), (u'49', 0.0016682489463024598), (u'36', 0.0016437099466024344), (u'human', 0.0015363751235594198), (u'8', 0.0014276802043636677), (u'56', 0.0012515908922609254)]\n",
      "\n",
      "\n",
      "[(u'[19]', 0.027933105677298977), (u'[20]', 0.014157259944852195), (u'[18]', 0.013987975301298208), (u'[21]', 0.013765767915714275), (u'image', 0.012184307073574733), (u'direction', 0.0095769356326792215), (u'visual', 0.0089375876072701442), (u'field', 0.0082523725882935779), (u'motion', 0.0078297616933250356), (u'subject', 0.0078040042766423633)]\n",
      "\n",
      "\n",
      "[(u'centroid', 0.0166159420061835), (u'hmm', 0.0093036286809894536), (u'real-time', 0.0076914361314824103), (u'behavior', 0.0065849733143975653), (u'state', 0.0047414620208485365), (u'utility', 0.0033789228526008323), (u'edge', 0.0032536774792371864), (u'traffic', 0.0032106540523451563), (u'hmms', 0.0031335046879144416), (u'goal', 0.0030683948594422039)]\n",
      "\n",
      "\n",
      "[(u'training', 0.0062428165257174973), (u'bound', 0.0060933377503196535), (u'class', 0.0055231178476598721), (u'mixture', 0.0051298654463248312), (u'kernel', 0.0045839615705869242), (u'working', 0.0043745309558141758), (u'w', 0.0039376071928261952), (u'risk', 0.003756400183336667), (u'gaussian', 0.0037525628050480292), (u'component', 0.003692970586852909)]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for position in range(10):\n",
    "    for topic in [0, 3, 5, 6, 7, 8, 9]:\n",
    "        print model3.show_topic(topic)\n",
    "        print('')\n",
    "        print('')\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перплексия заметно ухудшилась. При этом визуально темы стали более интепретируемыми. Перплексия не отражает интерпретируемость модели!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Ручная\" обработка текстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')\n",
    "from nltk import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если есть какие-то знания о формате текста и желание использовать (или удалить?) метаданные, имеет смысл писать \"ручную\" обработку с использованием регулярных выражений. \n",
    "\n",
    "Пример такой обработки приведен ниже:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CleanAndSplitText(textDataFrame):\n",
    "\n",
    "    textDataOut = [] \n",
    "   \n",
    "    # This regular expression is for section headers in the bill summaries that we wish to ignore\n",
    "    reHeaders = re.compile(r\" *TABLE OF CONTENTS:? *\"\n",
    "                           \"| *Title [IVXLC]+:? *\"\n",
    "                           \"| *Subtitle [A-Z]+:? *\"\n",
    "                           \"| *\\(Sec\\. \\d+\\) *\")\n",
    "\n",
    "    # This regular expression is for punctuation that we wish to clean out\n",
    "    # We also will split sentences into smaller phrase like units using this expression\n",
    "    rePhraseBreaks = re.compile(\"[\\\"\\!\\?\\)\\]\\}\\,\\:\\;\\*\\-]*\\s+\\([0-9]+\\)\\s+[\\(\\[\\{\\\"\\*\\-]*\"                             \n",
    "                                \"|[\\\"\\!\\?\\)\\]\\}\\,\\:\\;\\*\\-]+\\s+[\\(\\[\\{\\\"\\*\\-]*\"\n",
    "                                \"|\\.\\.+\"\n",
    "                                \"|\\s*\\-\\-+\\s*\"\n",
    "                                \"|\\s+\\-\\s+\"\n",
    "                                \"|\\:\\:+\"\n",
    "                                \"|\\s+[\\/\\(\\[\\{\\\"\\-\\*]+\\s*\"\n",
    "                                \"|[\\,!\\?\\\"\\)\\(\\]\\[\\}\\{\\:\\;\\*](?=[a-zA-Z])\"\n",
    "                                \"|[\\\"\\!\\?\\)\\]\\}\\,\\:\\;]+[\\.]*$\"\n",
    "                             )\n",
    "    \n",
    "    # Regex for underbars\n",
    "    regexUnderbar = re.compile('_')\n",
    "    \n",
    "    # Regex for space\n",
    "    regexSpace = re.compile(' +')\n",
    " \n",
    "    # Regex for sentence final period\n",
    "    regexPeriod = re.compile(\"\\.$\")\n",
    "\n",
    "    # Iterate through each document and do:\n",
    "    #    (1) Split documents into sections based on section headers and remove section headers\n",
    "    #    (2) Split the sections into sentences using NLTK sentence tokenizer\n",
    "    #    (3) Further split sentences into phrasal units based on punctuation and remove punctuation\n",
    "    #    (4) Remove sentence final periods when not part of an abbreviation \n",
    "\n",
    "    for i in range(0, len(frame)):     \n",
    "        # Extract one document from frame\n",
    "        docID = frame['ID'][i]\n",
    "        docText = str(frame['Text'][i])\n",
    "\n",
    "        # Set counter for output line count for this document\n",
    "        lineIndex=0;\n",
    "\n",
    "        # Split document into sections by finding sections headers and splitting on them \n",
    "        sections = reHeaders.split(docText)\n",
    "        \n",
    "        for section in sections:\n",
    "            # Split section into sentence using NLTK tokenizer \n",
    "            sentences = tokenize.sent_tokenize(section)\n",
    "            \n",
    "            for sentence in sentences:\n",
    "                # Split each sentence into phrase level chunks based on punctuation\n",
    "                textSegs = rePhraseBreaks.split(sentence)\n",
    "                numSegs = len(textSegs)\n",
    "                \n",
    "                for j in range(0,numSegs):\n",
    "                    if len(textSegs[j])>0:\n",
    "                        # Convert underbars to spaces \n",
    "                        # Underbars are reserved for building the compound word phrases                   \n",
    "                        textSegs[j] = regexUnderbar.sub(\" \",textSegs[j])\n",
    "                    \n",
    "                        # Split out the words so we can specially handle the last word\n",
    "                        words = regexSpace.split(textSegs[j])\n",
    "                        phraseOut = \"\"\n",
    "                        # If the last word ends in a period then remove the period\n",
    "                        words[-1] = regexPeriod.sub(\"\", words[-1])\n",
    "                        # If the last word is an abbreviation like \"U.S.\"\n",
    "                        # then add the word final period back on\n",
    "                        if \"\\.\" in words[-1]:\n",
    "                            words[-1] += \".\"\n",
    "                        phraseOut = \" \".join(words)  \n",
    "\n",
    "                        textDataOut.append([docID, lineIndex, phraseOut])\n",
    "                        lineIndex += 1\n",
    "                        \n",
    "    # Convert to pandas frame \n",
    "    frameOut = pandas.DataFrame(textDataOut, columns=['DocID', 'DocLine', 'CleanedText'])                      \n",
    "    \n",
    "    return frameOut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Еще одна причина воспользоваться \"ручной\" предобработкой - написать что-нибудь \"этакое\" с выделением n-грамм, например. Пример такой обработки можно найти по ссылке: \n",
    "https://docs.microsoft.com/ru-ru/azure/machine-learning/preview/scenario-document-collection-analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ARTM** - аддитивная регуляризация тематической модели:\n",
    "    \n",
    "Пусть, наряду с правдоподобием, требуется максимизировать ещё $n$ критериев\n",
    "    $R_i(\\Phi,\\Theta)$, $i=1,\\dots,n$ - \n",
    "    **регуляризаторов**.\n",
    "\n",
    "Метод многокритериальной оптимизации - **скаляризация**.\n",
    "\n",
    "**Задача:** максимизировать регуляризованное правдоподобие\n",
    "$$\n",
    "            \\underbrace{\n",
    "                \\sum_{d\\in D} \\sum_{w\\in d} \\!n_{dw} \\ln \\sum_{t\\in T} \\phi_{wt}\\theta_{td}\n",
    "            }_{\\text{log-likelihood~} L(\\Phi,\\Theta)}\n",
    "            {\n",
    "            \\;+\\;\n",
    "            \\underbrace{\n",
    "                \\sum_{i=1}^n \\tau_i R_i(\\Phi,\\Theta)\n",
    "            }_{R(\\Phi,\\Theta)}}\n",
    "            \\to \\max_{\\Phi,\\Theta},\n",
    "$$\n",
    "\n",
    "при ограничениях неотрицательности и нормировки\n",
    "\n",
    "$$\n",
    "            \\phi_{wt}\\geq 0;\\quad\n",
    "            \\sum_{w\\in W} \\phi_{wt}=1;\n",
    "            \\qquad\n",
    "            \\theta_{td}\\geq 0;\\quad\n",
    "            \\sum_{t\\in T} \\theta_{td}=1\n",
    "$$\n",
    "\n",
    "где $\\tau_i>0$ - **коэффициенты регуляризации**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BigARTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://docs.bigartm.org/en/stable/index.html\n",
    "\n",
    "библиотека для тематического моделирования с открытым кодом   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом эксперименте для обучения ARTM воспользуемся первыми тремя регуляризаторами. ARTM без регуляризации соответствует PLSA.\n",
    "\n",
    "#### Коллекция:\n",
    "Воспользуемся небольшой коллекцией 'kos', доступной в репозитории UCI https://archive.ics.uci.edu/ml/machine-learning-databases/bag-of-words/. Параметры коллекции следующие:\n",
    "\n",
    "- 3430 документов;\n",
    "- 6906 слов в словаре;\n",
    "- 467714 ненулевых счётчиков в \"мешке слов\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9.0\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import artm\n",
    "\n",
    "print artm.version()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прежде всего необходимо подготовить входные данные. BigARTM имеет собственный формат документов для обработки, называемый батчами. В библиотеке присутствуют средства по созданию батчей из файлов в форматах Bag-Of-Words UCI и Vowpal Wabbit (подробности можно найти в http://docs.bigartm.org/en/latest/formats.html).\n",
    "\n",
    "В Python API, по аналогии с алгоритмами из scikit-learn, входные данные представлены одним классом BatchVectorizer. Объект этого класса принимает на вход батчи или файлы UCI / VW и подаётся на вход всем методам. В случае, если входные данные не являются батчами, он создаёт их и сохраняет на диск для последующего быстрого использования.\n",
    "\n",
    "Итак, создадим объект BatchVectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_vectorizer = None\n",
    "if len(glob.glob(os.path.join('kos', '*.batch'))) < 1:\n",
    "    batch_vectorizer = artm.BatchVectorizer(data_path='', data_format='bow_uci', collection_name='kos', target_folder='kos')\n",
    "else:\n",
    "    batch_vectorizer = artm.BatchVectorizer(data_path='kos', data_format='batches')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ARTM &ndash; это класс, представляющий собой Python API BigARTM, и позволяющий использовать практически все возможности библиотеки в стиле scikit-learn. Создадим две тематические модели для нашего эксперимента. Наиболее важным параметром модели является число тем. Опционально можно указать списки регуляризаторов и функционалов качества, которые следует использовать для данной модели. Если этого не сделать, то регуляризаторы и функционалы всегда можно добавить позднее. Обратите внимание, что каждая модель задаёт своё пространство имён для названий регуляризаторов и функционалов качества."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = artm.Dictionary()\n",
    "\n",
    "model_plsa = artm.ARTM(topic_names=['topic_{}'.format(i) for i in xrange(15)],\n",
    "                       scores=[artm.PerplexityScore(name='PerplexityScore',\n",
    "                                                    dictionary=dictionary)],\n",
    "                       cache_theta=True)\n",
    "\n",
    "model_artm = artm.ARTM(topic_names=['topic_{}'.format(i) for i in xrange(15)],\n",
    "                       scores=[artm.PerplexityScore(name='PerplexityScore',\n",
    "                                                    dictionary=dictionary)],\n",
    "                       regularizers=[artm.SmoothSparseThetaRegularizer(name='SparseTheta', tau=-0.15)],\n",
    "                       cache_theta=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Следующий шаг — инициализация моделей. Сделаем это по словарю, что означает, что\n",
    "- будет создана матрица $\\Phi$ с именем 'pwt', число строк и столбцов в ней будет взято исходя из числа слов в словаре и заданного в модели числа тем;\n",
    "- эта матрица будет заполнена случайными значениями из диапазона (0, 1) и нормализована.\n",
    "\n",
    "Надо отметить, что этот шаг является опциональным, поскольку модель может быть автоматически инициализирована во время вызовов fit_offline() / fit_online().\n",
    "\n",
    "Словарь &ndash; это объект BigARTM, содержащий информацию о коллекции (словарь коллекции, различные величины и счётчики, связанные со словами). Создать словарь можно на основе папки с батчами. Затем собранный словарь можно сохранять на диск и позже подгрузить вновь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.isfile('kos/dictionary.dict'):\n",
    "    dictionary.gather(data_path=batch_vectorizer.data_path)\n",
    "    dictionary.save(dictionary_path='kos/dictionary.dict')\n",
    "\n",
    "dictionary.load(dictionary_path='kos/dictionary.dict')\n",
    "dictionary.load(dictionary_path='kos/dictionary.dict')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Затем словари можно использовать, чтобы инициализировать модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_plsa.initialize(dictionary=dictionary)\n",
    "model_artm.initialize(dictionary=dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как уже было сказано, ARTM предоставляет возможность использовать все функционалы качества, имеющиеся в BigARTM. Если функционал подключен к модели, то модель будет сохранять все его значения, полученные на момент каждого обновления матрицы $\\Phi$. Добавим функционалы качества, нужные для нашего эксперимента, которые отсутствовали в конструкторах:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_plsa.scores.add(artm.SparsityPhiScore(name='SparsityPhiScore'))\n",
    "model_plsa.scores.add(artm.SparsityThetaScore(name='SparsityThetaScore'))\n",
    "model_plsa.scores.add(artm.TopicKernelScore(name='TopicKernelScore', probability_mass_threshold=0.3))\n",
    "\n",
    "model_artm.scores.add(artm.SparsityPhiScore(name='SparsityPhiScore'))\n",
    "model_artm.scores.add(artm.SparsityThetaScore(name='SparsityThetaScore'))\n",
    "model_artm.scores.add(artm.TopicKernelScore(name='TopicKernelScore', probability_mass_threshold=0.3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогично поступим с регуляризаторами для model_artm (зададим им стартовые коэффициенты регуляризации, которые можно будет позже изменить при необходимости):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_artm.regularizers.add(artm.SmoothSparsePhiRegularizer(name='SparsePhi', tau=-0.1))\n",
    "model_artm.regularizers.add(artm.DecorrelatorPhiRegularizer(name='DecorrelatorPhi', tau=1.5e+5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробуем обучить модели в оффлайн-режиме (т.е. обновляя Фи раз за проход по коллекции). Инициируем пятнадцать проходов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_plsa.num_document_passes = 1\n",
    "model_artm.num_document_passes = 1\n",
    "\n",
    "model_plsa.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=15)\n",
    "model_artm.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим результаты первой итерации обучения, сравнив финальные значения функционалов, а также графики перплексии (опишем печать в виде функции для возможности повторного использования):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity Phi: 0.000 (PLSA) vs. 0.469 (ARTM)\n",
      "Sparsity Theta: 0.000 (PLSA) vs. 0.001 (ARTM)\n",
      "Kernel contrast: 0.466 (PLSA) vs. 0.525 (ARTM)\n",
      "Kernel purity: 0.215 (PLSA) vs. 0.359 (ARTM)\n",
      "Perplexity: 2058.027 (PLSA) vs. 1950.716 (ARTM)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEKCAYAAADq59mMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzrlm8+LhnHOu2bx4OOeca7b/D2ZZnAe1UaG5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13317efd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def print_measures(model_plsa, model_artm):\n",
    "    print 'Sparsity Phi: {0:.3f} (PLSA) vs. {1:.3f} (ARTM)'.format(\n",
    "        model_plsa.score_tracker['SparsityPhiScore'].last_value,\n",
    "        model_artm.score_tracker['SparsityPhiScore'].last_value)\n",
    "\n",
    "    print 'Sparsity Theta: {0:.3f} (PLSA) vs. {1:.3f} (ARTM)'.format(\n",
    "        model_plsa.score_tracker['SparsityThetaScore'].last_value,\n",
    "        model_artm.score_tracker['SparsityThetaScore'].last_value)\n",
    "\n",
    "    print 'Kernel contrast: {0:.3f} (PLSA) vs. {1:.3f} (ARTM)'.format(\n",
    "        model_plsa.score_tracker['TopicKernelScore'].last_average_contrast,\n",
    "        model_artm.score_tracker['TopicKernelScore'].last_average_contrast)\n",
    "\n",
    "    print 'Kernel purity: {0:.3f} (PLSA) vs. {1:.3f} (ARTM)'.format(\n",
    "        model_plsa.score_tracker['TopicKernelScore'].last_average_purity,\n",
    "        model_artm.score_tracker['TopicKernelScore'].last_average_purity)\n",
    "\n",
    "    print 'Perplexity: {0:.3f} (PLSA) vs. {1:.3f} (ARTM)'.format(\n",
    "        model_plsa.score_tracker['PerplexityScore'].last_value,\n",
    "        model_artm.score_tracker['PerplexityScore'].last_value)\n",
    "\n",
    "    plt.plot(xrange(model_plsa.num_phi_updates), model_plsa.score_tracker['PerplexityScore'].value, 'b--',\n",
    "             xrange(model_artm.num_phi_updates), model_artm.score_tracker['PerplexityScore'].value, 'r--', linewidth=2)\n",
    "    plt.xlabel('Iterations count')\n",
    "    plt.ylabel('PLSA perp. (blue), ARTM perp. (red)')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "print_measures(model_plsa, model_artm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что улучшения разреженностей и ядровых характеристик есть, а ухудшение перплексии невелико. Попробуем увеличить по модулю значения коэффициентов регуляризации при регуляризаторах:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_artm.regularizers['SparsePhi'].tau = -0.2\n",
    "model_artm.regularizers['SparseTheta'].tau = -0.2\n",
    "model_artm.regularizers['DecorrelatorPhi'].tau = 2.5e+5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроме того, подключим к каждой из моделей функционал TopTokensScore, который позволит взглянуть на самые вероятные слова в каждой теме:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_plsa.scores.add(artm.TopTokensScore(name='TopTokensScore', num_tokens=6))\n",
    "model_artm.scores.add(artm.TopTokensScore(name='TopTokensScore', num_tokens=6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Продолжим обучение моделей, инициировав 25 проходов по коллекции, после чего снова посмотрим на значения функционалов качества:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_plsa.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=25)\n",
    "model_artm.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity Phi: 0.093 (PLSA) vs. 0.841 (ARTM)\n",
      "Sparsity Theta: 0.000 (PLSA) vs. 0.023 (ARTM)\n",
      "Kernel contrast: 0.640 (PLSA) vs. 0.739 (ARTM)\n",
      "Kernel purity: 0.674 (PLSA) vs. 0.822 (ARTM)\n",
      "Perplexity: 1619.035 (PLSA) vs. 1644.216 (ARTM)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEKCAYAAADq59mMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nERFpNSUPERFpNSUPERFptf8PQoG5gtqkpTkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1331ce490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_measures(model_plsa, model_artm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроме того, для наглядности построим графики изменения разреженностей матриц по итерациям:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XeYVOX5//H3zdJ7kyKogKDGAkQQYkQjRg2KikZjxxY1\nRE0xP7uJX5MYo0aNvUUsMUZUbERREhGwK0VAwIaACiqoFFn67t6/P56zu8O6OzsMO3NmZj+v6zrX\nzDnzzNl7Duzce55q7o6IiAhAg7gDEBGR3KGkICIiFZQURESkgpKCiIhUUFIQEZEKSgoiIlJBSUFE\nRCooKYiISAUlBRERqdAw7gC2VMeOHb1Hjx5pvXfNmjW0aNGibgOqI4otPbkcG+R2fIotPfka2/Tp\n0792921qPYm759U2YMAAT9ekSZPSfm+mKbb05HJs7rkdn2JLT77GBkzzFL5jVX0kIiIVlBRERKSC\nkoKIiFRQUhARkQpKCiIiUkFJQUREKigpiIhIhbwbvCYiUpDcYflyKC2FTp3CsSVL4O9/hy+/hO23\nh6uvzngYSgoiIpniDqtWhS/1nXaCBlHlzJ13wtSpsHRp2L78EpYtg02b4OST4aGHQrk1a+CGG8Lz\n739fSUFEJGetXQslJdC6ddh/993wZf/FF+FLvnxbvz68vmwZbBPNMvHcc2GrqnVraJjwtdytG1x7\nLXTpAmlO77OllBRERJIZPx7efx8WLoSFCxn43nuwcmWo6rnkEvjrX0O5r78OSaGqli3Dl/q331Ym\nhVGjYMQI6Nw5bF26hCqjZs02f2+LFnDRRZn9fFUoKYhI/bVqFXz0EXzwAXz4YdgWL4aXXwazUOay\ny2DWrIq3tCx/0rhx5V0AwG67wS23QNeu4Uu+a9fwhd+yJd9x2GEZ+0hbS0lBRApbSQksWgRNm0L3\n7uHYs8/CmWeG+vzqLF0avtgBfvYz2Hdf6NULevRg2rJlDDzqKOjYsbKNAMJf+r/6VUY/SjYkTQpm\ntjdwMrAv0BVYB8wBngP+5e6rMh6hiEiqZs0Kdfvvv1+5ffQRbNy4eVVP27bhi79p09AAXL716QO9\ne0O7dpXnvPzyzX5E8eTJlb2DClCNScHMngc+B54B/gIsA5oCOwFDgWfM7EZ3H5fkHMOAm4Ei4F53\nv6bK622AfwHbR7Fc7+73b9UnEpHCtmFDqO6ZOzd86V95ZWVVz2mnwcyZ333PdttBkyaV+wMHwief\nhDuHBhqulSjZncJId/+6yrFiYEa03WBmHWt6s5kVAbcDBwGLgalmNs7d5yUUOxeY5+6Hm9k2wAdm\n9rC7b0znw4hIAVq8GMaOhXfegRkz4L33Ql/+cmeeGb70AQ45JPyl/73vwS67hG2nnb5br9+0aej3\nL99RY1KoJiFsaZlBwHx3XwBgZmOAEUBiUnCglZkZof1mOVCSQtwiUmhWrIDp02HaNLZZuxb23z8c\n//RTOP/8ynINGoRqnt13D427iV04s9CPv9Alqz5aTfjSrpa7t67l3N2AzxL2FwODq5S5DRhHqKZq\nBRzn7mW1nFdECsHbb8OUKTBtWtgWLKh4qcvgwfCnP4Wdfv3C3cCAAWEA1x57QPPmMQVd+Cys0pak\ngNmfgS+AhwADTgK6uvsVtbzvGGCYu58Z7Y8EBrv7eVXK7AP8DtgR+B/Qz92/rXKus4GzATp37jxg\nzJgxW/IZKxQXF9Oyuu5hOUCxpSeXY4Pcji9rsbnTbMkS2syezdf77ktJq1YA7HL11XT53/8qipU2\nbkxxnz6s3mknlu68M6t/8pPMx5aGfP03HTp06HR3H1jrSWpbrxOYlcqxasrsDUxI2L8UuLRKmeeA\nfRP2XwIGJTuv1mjOPsWWvlyOL2Oxbdzo/vbb7jfe6P7Tn7p36uQeJnxwHzeustyjj7qfc477ffe5\nz57tvmlT5mOrA/kaGymu0ZzKOIU1ZnYSMIZQnXQCsCaF900F+phZT2AJcDxwYpUynwI/Bl4xs87A\nzsACRCQ/fftt6NGzevXmxzt1giFDQlfQcsceGzbJKakkhRMJ3UpvJiSF1/jul/t3uHuJmZ0HTCB0\nSb3P3eea2ajo9buAPwMPmNm7hKqpiz2FBm4RiZF76Ps/cWLYFi0Kk7uZhbl7dtghdBvdd9+QCIYM\nCT2CyruNSk6rNSm4+yJCr6Et5u7jgfFVjt2V8Pxz4OB0zi0iWbR+PUyaFEYCP/dc6OOfaNEi6Nkz\nPH/zzTBnj+SlWpOCme0E3Al0dvfdzawvcIS7X5Xx6EQkPps2QaNG4fkrr8Chh1a+1rEjHHAA/PjH\n4TFxBk8lhLyWSvXRP4ALgbsB3H22mf0bUFIQKSTuMG8ePPEEPPNMGBD29NPhtf32C9VABxwQJnMb\nMEAjgQtUKkmhubu/bZvXB2qAmUghcA8Dxp58MiSDDz+sfO2zz8Jkcg0bhikiXnklvjgla1JJCl+b\n2Y5EA9misQVfZDQqEcmOO++Ec8+t3O/QAY48Eo46KtwVNNREyvVNKv/i5wL3ALuY2RJgIWEAm4jk\nC/fQQ2jMmNAgXD7F8yGHwLbbhiRw9NGhx5ASQb1W29TZDYCB7n6gmbUAGrj76mTvEZEc4R6mkR4z\nJmwLF4bjO+8M50UTC/TsGSacU3dRiSRNCu5eZmYXAY+5eyoD1kQkFzzxBPzhD2FG0XJdu4bBYscf\nv3lZJQRJkMp94otmdgHwKAkjmd19ecaiEpEts3ZtWDd4223DftOmISF06ADHHBMSwb77QlFRvHFK\nzkslKRwXPSa0RuFAr7oPR0RS5h5mGr3vvlA99JOfwGOPhdd+8hN44YXQWFw+1kAkBamMaO6ZjUBE\nJEWrVoVEcO+9YVxBuS+/hLKyMH6gYcOQGES2ULL1FIa4+6tJXm8NbO/uczISmYh817hxcNJJUFwc\n9jt1gpEj4fTTw4IzIlsp2Z3C0WZ2HfACMB34irBGc2/CGs07AP8v4xGK1HfLl0P79uF5v36wbl2o\nFvrVr2D4cFUPSZ1Kthzn+WbWHjga+BnQFVgHvAfcnewuQkS2UmlpmGLixhvDMpVz5oRqoR12gI8/\nDo8iGVBbl9TlhLmP/pGdcETquZISeOQR+POfw/TUENYgmD8/LEAPSgiSUZrRSiQXlJbCv/4V2gVO\nOSUkhF694NZbwxxE5QlBJMM0nl0kF2zYABdcAEuXwo47hoFnJ52kKSck6/Q/TiQOpaUwdmyYe6h1\na2jeHK67Lhw/+WQ1Hkts0qo+MrMudR2ISL3x8sswcGAYZXzLLZXHTzkldC1VQpAYpdumMLpOoxCp\nDxYtgp/9DH70I5g5Myxw31NjQyW3pFV95O7D6zoQkYJVXAx//SvccENoO2jWDC65JLQhNG8ed3Qi\nm0kpKZjZnsAQwpxHr7n7jIxGJVJIJk6Eq68Oz088Ea65Jix1KZKDaq0+MrMrgAeBDkBH4H4z+32m\nAxPJaytWVD4/4gj4zW/g9dfh4YeVECSnpXKncBLQz93XA5jZNcBM4KpMBiaSl0pKQi+ia64JSQDC\negU33RRvXCIpSqWh+XPCnEflmgBLMhOOSB6bPx/22w8uvxxWr4YJE+KOSGSLpZIUVgFzzewBM7sf\nmAOsNLNbzOyWWt4rUvjc4a67wmR1b7wB3bqFhPD/NF+k5J9Uqo+eirZykzMTikge+uIL+PnP4fnn\nw/6JJ8Jtt0G7dvHGJZKmVBbZebD8uZm1A7Zz99kZjUokX6xZA1OmhCRw111hDWSRPFZrUjCzycAR\nUdnpwDIze83df5fh2ERyU0lJ5ZxEvXvD449D//6V6yOL5LFU2hTauPu3wE+Bf7r7YODAzIYlkqM+\n+wz22QdGJwzqP/RQJQQpGKkkhYZm1hU4Fng2w/GI5K6JE2HPPeHtt+Fvf4NNm+KOSKTOpZIU/gRM\nAOa7+1Qz6wV8lNmwRHKIO1x7LRx8MHz9dXh89VVNXCcFKZWG5seBxxP2FxCW6BQpfN9+C6edBk9F\nHfB+/3u48kooKoozKpGM0XoKIsmcempYK7l1a3jooTBlhUgBU1IQSeavf4Vly+CBB6BPn7ijEck4\nrdEsUtWMhEmAd9kltB8oIUg9UeOdgpmd7O7/MrNqxyO4+42ZC0skBu5hMrtLLoGbb4Zf/zocN4s3\nLpEsSlZ91CJ6bJWNQERiVVoK558Pt94akoB73BGJxKLGpODud0ePf8xeOCIxWL8eRo6EsWOhcePQ\noKzpKqSeSmWai22As4AeieXd/YwU3jsMuBkoAu5192uqKbM/cBPQCPja3X+UYuwiW2/FCjjySHj5\n5dDD6JlnYP/9445KJDap9D56BngFeBEoTfXEZlYE3A4cBCwGpprZOHefl1CmLXAHMMzdPzWzTlsS\nvMhWO/PMkBC23RZeeAH22CPuiERilUpSaO7uF6dx7kGEUdALAMxsDDACmJdQ5kTgSXf/FMDdl6Xx\nc0TSd8MNsGoV3HcfbL993NGIxC6VLqnPmtmhaZy7G/BZwv7i6FiinYB2ZjbZzKab2Slp/ByRLbNm\nTeXzHj3gxReVEEQi5jX0sjCz1YADRuiJtAHYFO27u7dOemKzYwjVQmdG+yOBwe5+XkKZ24CBwI+B\nZsAbwHB3/7DKuc4Gzgbo3LnzgDFjxmz5JwWKi4tp2bJlWu/NNMWWni2NrfHy5fT/7W9ZetBBfDJy\nZAYjCwrp2mWTYktPstiGDh063d0H1noSd8/IBuwNTEjYvxS4tEqZS4A/JuyPBn6W7LwDBgzwdE2a\nNCnt92aaYkvPFsX21Vfuu+3mDu59+7qvXZuxuMoVzLXLMsWWnmSxAdM8he/uGquPzKyTmd1kZs+a\n2dVmlvTOoBpTgT5m1tPMGgPHA+OqlHkGGGJmDc2sOTAYeG8Lf45I7ZYvh4MOgrlzYdddQ5VRs2Zx\nRyWSc5K1KfwTWAPcShjAdsuWnNjdS4DzCNNuvwc85u5zzWyUmY2KyrwHvADMBt4mdFuds8WfQiSZ\nVatg2DCYOTNMV/Hii7DNNnFHJZKTkvU+6urul0fPJ5jZjCRlq+Xu44HxVY7dVWX/b8DftvTcIikp\nLg4ro02dCj17wksvQdeucUclkrOSdkk1s3aEhmWAosR9d1+e4dhEtt6KFfDFF7DddiEhdO8ed0Qi\nOS1ZUmgDTKcyKQCU3y040CtTQYnUme22gylTYMOG0P1URJJKNvdRjyzGIVK33n8/THsNITGISEq0\nnoIUnokTYbfdwtTXmu1UZIsoKUhhWbwYTjgBysqgTRuthSCyhZQUpHBs3BimvP7qKzjwQLjyyrgj\nEsk7yVZea5/sjep9JDnnggvgjTdCG8K//w1FRXFHJJJ3kvU++powiV1JtJ94H67eR5JbHnkkrJrW\nqBE8/rgGp4mkKVlSuAUYCrwGPAK8Gs2fIZJbysrg2mvD85tugsGD441HJI/V2Kbg7r8F+gOPAyOB\nd8zsOjPrma3gRFLSoAFMngw33wy//GXc0YjktaQNzeUT7wEXAXcBpwMHZiMwkVol3ri2bRu6oKq3\nkchWSdbQ3IKwUtpxwDbAk8AAj1ZJE4ndPffQZ/x42HtvaNIk7mhECkKyNoVlwEfAmOjRgYFmNhDA\n3Z/MfHgiNVixAi67jG7Ll4dZT4cPjzsikYKQLCk8Fj3uHG2JnHDnIBKPP/8Zli9nRf/+tDs0ndVi\nRaQ6yZLCf3Q3IDnpww9D91MzPj73XAaqHUGkziRraP591qIQ2RIXXgglJXDGGRT37h13NCIFRdNc\nSH558UUYNw5atoSrroo7GpGCk6z6aBczm13NcSP0Vu2boZhEavbCC+HxssugS5cwRbaI1JlkSWEh\ncHi2AhFJyfXXh+U1f/jDuCMRKUjJksJGd/8ka5GIpOqAA+KOQKRgJWtTeC1rUYjU5t57Yfr0uKMQ\nKXjJ5j46z8yKzKxj+TEza2xmZ5vZe9kJTwT4+GM491wYNAgWLYo7GpGCVmNSMLPjgOXAbDObYmYH\nAwuAQ4CTshSfCFx0UVhA5+SToUePuKMRKWjJ2hT+QJjraL6Z7Qm8ARzj7v/JTmgiwJQp8OST0Lw5\nXH113NGIFLxkbQob3X0+gLvPAD5SQpCsKi2F888Pzy++GLp1izcekXog2Z1CJzP7XcJ+28R9d78x\nc2FJvecOl1wC77wD3buHpTZFJOOSJYV/AK1q2NcKbJJZ33wTlths2BBGjw7VRyKScTUmBXf/Y02v\nmdlemQlHJNKxI7z6KsyeDQcfHHc0IvVGsjuFzZjZrsAJ0bYSGJipoKQe++gj6NMnPO/RQ72NRLIs\n6YR4ZtbDzC6N5kB6CPglcKC7KyFI3Rs3DnbdFf7yl7gjEam3ko1TeAN4jnA3cbS7DwBWu/uiLMUm\n9clLL8Gxx4YpsdeujTsakXor2Z3CUkLDcmfCGs2gBmbJhLfegiOOgA0bwshlTYktEptk01wcCewB\nTAeuNLOFQDszG5St4KQemDMHDjkE1qwJI5ZvuQW0kppIbJI2NLv7KuB+4H4z6wQcC/zdzLZ39+2y\nEaAUsE8+CT2LVqyAESPg/vuhgdZ9EolTyr+B7r7M3W9z932AIRmMSeqLdeugSRMYOhTGjAljEkQk\nVmn9FmqdBakTu+wCb74ZEkPTpnFHIyJojWbJNvcwyV25zp2hbdv44hGRzSgpSHZdfz3svz9cfnnc\nkYhINbY4KZjZOWZ2nJnVWvVkZsPM7AMzm29mlyQpt5eZlZjZMVsaj+SRJ54IayMAfP/78cYiItVK\n507BCA3NTyYtZFYE3E5YlGdX4IRoqozqyl0L/DeNWCRfvPVW6HIKcO21cIzyv0gu2uKGZne/PcWi\ng4D57r4AwMzGACOAeVXK/Qp4AtAke4Vq0aIwOG39ejjrLLjwwrgjEpEapFIFNBDYF9gWWAfMAf7n\n7itqeWs34LOE/cXA4Crn7gYcBQxFSaEwrVwJw4fDsmVw0EFw++0anCaSw8y9+pkrzOx0wl/xCwmj\nmpcBTYGdgH0IyeEP7v5pDe8/Bhjm7mdG+yOBwe5+XkKZx4Eb3P1NM3sAeNbdx1ZzrrOBswE6d+48\nYMyYMWl92OLiYlq2bJnWezOtUGNr+uWX9L3oIrxBA2bcdhuldfwZc/m6QW7Hp9jSk6+xDR06dHpK\nk5m6e7UbcC7QLMnr/YEfJ3l9b2BCwv6lwKVVyiwEFkVbMSHxHFnTOd2dAQMGeLomTZqU9nszraBj\n++Yb908+qZNYqsrl6+ae2/EptvTka2zANE/y3Vq+JVtkJ2nbgbvPrCXfTAX6mFlPYAlwPHBilXP0\nLH+ecKfwdC3nlXwwZw7stluoKmrfPmwikvNq7X1kZjuZ2UQzmxPt9zWz39f2PncvAc4DJgDvAY+5\n+1wzG2Vmo7Y2cMlhL70E/fvDOeeEwWoikjdS6X30D+BC4G4Ad59tZv8Gap3f2N3HA+OrHLurhrKn\npRCL5LqPPgrdTUtLoU0bNSqL5JlUxik0d/e3qxwryUQwkudWroTDDw+znh5+OFx9ddwRicgWSiUp\nfG1mOxItsBP1Kvoio1FJ/ikpgeOPhw8+gD32gIcf1jTYInkoleqjc4F7gF3MbAmhx9DJGY1K8s8F\nF8CECdCxY1hruVWruCMSkTTUmhQ8jEg+0MxaAA3cfXXmw5K8UlwMEydCo0bw1FPQo0fcEYlImlIZ\n0XxFlX0A3P1PGYpJ8k3LlvDaa2FthCFaf0kkn6VS6bsmYSslTHDXI4MxSb74+uvKLqetW4elNUUk\nr6VSfXRD4r6ZXU8YeyD12TffwN57wz77wD33QOPGcUckInUgneU4mwPd6zoQySMbNsBRR8H8+aHq\naONGJQWRApFKm8K7RN1RgSJgG0DtCfWVO5x9NrzyCmy7LfznPyExiEhBSOVO4bCE5yXA0mgKC6mP\n/vIX+Oc/oXnzkBC666ZRpJDUmBTMrHwGs6pdUFubGe6+PHNhSU4aMwb+8IcwdcW//w177hl3RCJS\nx5LdKUwnVBtVN3mNA70yEpHkJvewQA7ADTfAiBHxxiMiGZFs6uyeNb0m9ZAZvPACPPII/PzncUcj\nIhmSUu8jM/spMIRwh/CK1jyoR9asgbKy8LxFCzjzzHjjEZGMSqX30R1Ab+CR6NAoMzvI3c/NaGQS\nv/XrYfhwdjULYxKaNYs7IhHJsFTuFA4Avhct54aZPQjMzWhUEr+SEjjhBJgyhTYdOsBXX8H228cd\nlYhkWCrTXMwHEr8NtouOSaFyh1Gj4OmnoW1bZl93nRKCSD2RrEvqfwhtCK2A98zs7Wh/MFB10R0p\nJJdfDqNHh+qiZ59lzaZNcUckIlmSrPro+qxFIbnj73+Hv/4Viorg8cfD3EaTJ8cdlYhkSbKk8HJ5\nO0JNzMxqKyN5pLQ0LJADcN99MHx4vPGISNYla1OYZGa/MrPNKpPNrLGZHRA1OJ+a2fAkq4qKYPz4\n0JZwyilxRyMiMUiWFIYR1k94xMw+N7N5ZrYQ+Ag4AbjJ3R/IQoySaR98EHobQWhH0GhlkXor2Yjm\n9cAdwB1m1gjoCKxz95XZCk6yYOZMOOCAsGLao49qLIJIPZfSiGZ33wR8keFYJNvefBMOOQRWroQG\nDcIayyJSr6UyTkEK0eTJcOCBISEcdVS4S2iYzppLIlJIlBTqo+efD3cIa9bAySfDY49BkyZxRyUi\nOUBJob559dXQkLx+fVhB7cEHdYcgIhXS+jYws3vc/ey6DkayYOBA2G8/6NcPrr8+TIktIhJJ90/E\nu+s0Csm8srLQmNy0KTz3HDRurIQgIt+RcvWRmbU2s1YA7j49cyFJnbv+ejjiCNi4Mew3aaKEICLV\nqjUpmNleZvYuMBuYY2azzGxA5kOTrbZxI/ziF3DhheHu4KWX4o5IRHJcKtVHo4Fz3P0VADMbAtwP\n9M1kYLKVli6Fo4+G114Ldwb33QfDhsUdlYjkuFSSQml5QgBw91fNrCSDMcnWmjYtjD1YvBi6d4en\nngoNzCIitUglKUwxs7sJy3E6cBww2cz2BHD3GRmMT7bUjBmw776hy+k++8DYsdClS9xRiUieSCUp\n9Ise/6/K8e8TksQBdRqRbJ1+/WDoUNhuO7j11tDLSEQkRbUmBXcfmo1AZCssXx5mOe3UKUx//dRT\nGqEsImlJpffRb6LuqGZm95rZDDM7OBvBSQreeSe0F/z0p5t3ORURSUMq4xTOcPdvgYOBDsBI4JqM\nRiWpeeAB+OEPYeHC0IawUrOai8jWSSUplI9yOhT4p7vPTTiW/I1mw8zsAzObb2aXVPP6SWY228ze\nNbPXzaxfdeeRKjZsCOMPTj89JIOzzgpzGnXqFHdkIpLnUmlonm5m/wV6ApdGo5rLanuTmRUBtwMH\nAYuBqWY2zt3nJRRbCPzI3VeY2SHAPcDgLf0Q9cqnn8Ixx8DUqaGa6I474Iwz4o5KRApEKknh50B/\nYIG7rzWzDsDpKbxvEDDf3RcAmNkYYARQkRTc/fWE8m8C3VMNvN4aMyYkhB494IknYM89445IRApI\nKr2PyoAZCfvfAN+kcO5uwGcJ+4tJfhfwc+D5FM5bv11wQag+Oucc6NAh7mhEpMCYu2fmxGbHAMPc\n/cxofyQw2N3Pq6bsUMJ60EOipFP19bOBswE6d+48YMyYMWnFVFxcTMuWLdN6b6bVFFujVavY8fbb\nWXjWWWzYZpsYIsvP65Yrcjk+xZaefI1t6NCh09299qkN3D0jG7A3MCFh/1Lg0mrK9QU+BnZK5bwD\nBgzwdE2aNCnt92ZatbFNmeLerZs7uA8fnvWYyuXddcshuRyfYktPvsYGTPMUvmNr7H1kZq2jx/bV\nbSkkralAHzPraWaNgeOBcVV+xvbAk8BId/8whXPWD6WlcNVVYWTykiWh2+kdd8QdlYjUA8naFP4N\nHAZMJ0xnkdgN1YFeyU7s7iVmdh4wASgC7nP3uWY2Knr9LuAKwtiHOyzM71/iqdzeFLIvvgjrJr/0\nUljz4NJL4Y9/hEaN4o5MROqBGpOCux8WPfZM9+TuPh4YX+XYXQnPzwTOTPf8BWfNmjA6+fPPw5iD\nhx6CgzV4XESyJ6XlOM2sG7BDYnl3fzlTQdVbLVrAuefCxInw8MOa3VREsq7WpGBm1xKmy54HlEaH\nHVBSqAuffQaffFK5f8klcPHFYWI7EZEsS+VO4UhgZ3ffkOlg6p3nnoNTTgEzmtx5ZzjWIOVls0VE\n6lwq30ALALVy1qVNm8K6yYcdFqa9HjSIMq17ICI5oMY7BTO7lVBNtBaYaWYTgYq7BXf/debDK0Cf\nfALHHw9vvhmqiK6+Gi64gE0vqzZOROKXrPpoWvQ4nSrjCyRNzz8PJ50EK1aEldHGjAljEEREckSy\nLqkPmll/oDcw193fy15YBaplS/j2Wzj8cLj/fs1dJCI5J9mI5j8AjwFHA8+Z2VlZi6qQrFlT+Xzf\nfeH11+GZZ5QQRCQnJWtoPh7o7+4nAHsRTUgnW2DiROjVC8YnjN8bNCiMVBYRyUHJksIGd18LFdNl\nq69kqsrKQgPywQfDsmVhZLKISB5I1tDcy8zKG5gN2DFhH3c/IqOR5asVK+DUU+E//wn7V1wRNhGR\nPJAsKYyosn99JgMpCDNnwtFHw4IF0K4d/OtfcOihcUclIpKyZL2PpmQzkLxXUlKZEPbcE8aOhZ5p\nzyUoIhILtRPUlYYN4cEH4Re/gNdeU0IQkbykpLA1vvkmzGZabsgQuOsuaNo0vphERLbCFicFM2tq\nZj/LRDB5Zc4c2GuvsCDOM8/EHY2ISJ1IKSmYWZGZHWpmDwGfEKbSrr+efhr23hsWLoQBA8ImIlIA\nkiYFM/uRmd0NLAJ+DhwE9HT3Y7IQW+5xhz//GY46CoqL4cQT4ZVXoHv3uCMTEakTyWZJXQx8CtwJ\nXODuq81sYfmAtnpnzRo47bTQq8gMrrkmTH+t0ckiUkCSjVMYS1hg5zig1MyeIUylXT+tXh2mu27d\nGh55ROMPRCSjvv4apk6FpUvD36PZkmycwm/N7Hxgf+AE4DqgjZkdC4x39+LshJgjunSBceOgWTPY\nZZe4oxGRArJ6NUyfDtOmhUTw9tuwaFF4rUULGDkyeyv0Jl2O090dmARMMrNGwE8ICeIOoGPmw4vZ\ns8/C7NmX9z9qAAAQGklEQVRw2WVh//vfjzceEcl7q1fDO+9Ap06Vf18++iicVWUe6mbNwjjYvfaC\ntWuhVavsxJfKGs2JlgDnA6szEEtuueUWOP/8MLndkCGw335xRyQieebzz2HWrLDNnh2SwQcfhD4r\nv/sd3HBDKDdoEAwcGDoy7rVX2HbdNYyJzbZkDc13Abe6+1wzawO8AZQC7YELgEeyE2KWlZaGZHDr\nrWH/j38M6yCIiNRg3TqYNy8MXxo5EhpE/TqPPDJUByVq1Aj22AO6das81rfvd8vFJVke2tfdR0XP\nTwc+dPcjzawL8DyFmBSKi8P6yc89B40bw+jRYXCaiEikuLghTz4J775buc2fHyoVIKyw26dPeL7f\nftC8efjS79cvbHvsAU2axBd/bZIlhY0Jzw8CHgdw9y+tELthLlkChx0WZjpt3z4MUNMdgki95A6f\nfQZz54a//rt1C8OSAJYsacqoUZuXLyqC730vfOGXllYevz4P55ZOlhRWmtlhhHaEfQiD1zCzhkCz\nLMSWXY0awcqV0Lt3WCmtPNWLSL0wdixMmBCSwNy5oUG43IEHViaFHj3WcsghsPvuIQnssUdoMC6U\nKc+SJYVfALcAXYDfuvuX0fEfA89lOrCs69Qp/I/o0EHrJ4sUoA0b4KOPwpf+7Nmh8fe22yonNH7h\nhVBjXK5jx/DFv/vu8IMfVB5v0qRssxV2C02ycQofAsOqOT7BzL6X0aiy5cUXwzTX//d/YX+nneKN\nR0S22saNoUkQwmq4Z54J770Xljopr/cv9847lUnhhBNC3f8ee8Buu4W/E+ujdDs8/Q64qS4Dybqx\nY+Gkk8L/oIEDYfjwuCMSkRR9803o2vnxx9/ddtsNXnoplGvdOvQbKSsLPYJ69w5dPfv1CwlgyJDK\nc/74x2Gr79JNCvnd0nz33fDLX4bWpN/8Bg45JO6IRCRBSYkxf/7mX/bnnAM77hhev+IKuOOO6t/b\nokXl86ZNw8z2O+wQmgkLpd4/k9JNCvk5B5I7/OUv8Pvfh/2rrgqjlQuxN5VIDisthS++CCN1y2tt\nv/kGjj02zEj/ySf7faeq54c/rEwKffuGG/wdd6zcevUKj4n9/yF0KpTUJRu8tprw5V/+jVmeCIx8\n7H1UVsaOd9xROcvpnXeGpTNFJKNeey1sCxZUbp9+Cps2wT77wKuvhnKtWsHkyaGqxwy2227zL/td\nd6085y9+oV/fTEnW0JylmTay5Ntv6fDWW6Hr6cMPw8+0eJzI1nAPDbnz54dePfPnVz4fPRr69w/l\nHnsszBpTVefOm3f0a9w49P3o2hU+/fQVDj5YU8vEIdmdQlNgFNAbmA3c5+4l2QqszrVty6zrrmPv\nTp3ggAPijkYkryxdCitWVE7gtmRJGKy1uoZZ0D78sDIpHHhgaOTt1StsPXtCjx5hpG9VQ4eGxy+/\nLPvui5IVydoUHgQ2Aa8AhwK7Ab/JRlCZsqFLF9h//7jDEMlZmzaFL/TySdzKty+/DHX6r70WynXu\nHOb7ads2NOD27r35Y2JVz+GHh03yQ7KksKu77wFgZqOBt7MTkohkw/LljXjxxdAvv3PncOzCC+Hm\nm79btlWr0L2zXMOGoeqobVv10yg0yZLCpvIn7l5SkPMdidQDJSXw3//C+++Hvv3vvx8Gc3311T4A\nPPRQ5byPffuG6p3ECdz69w/VPQ2qrOjerl12P4dkR7Kk0M/Mvo2eG9As2jfC+juta35r9CazYcDN\nQBFwr7tfU+V1i14/FFgLnObuM7b8Y4jUT2vXhvr98m3x4vDYuHHlZGwNGsDRR8P69Zu/t0WLEvr3\nb7hZ3f7pp8MZZ2Qvfsk9yXofbdXib2ZWBNxOmGF1MTDVzMa5+7yEYocAfaJtMHBn9ChSL7mHeRm/\n+Sas0btsWWjkXbYsbKeeGlbjArj6arj88urP07Il/O1voWqnQYMwx3+jRqGheOedw+PHH7/K0KH7\nb/Y+VQhIJtf1GQTMd/cFAGY2BhgBJCaFEcA/o2U/3zSztmbW1d2/yERAa9cW8dVX1b9WVBRmzC5X\nUzkIv3DNopEa69aFZRhq0rFj5S/aihXhVr6m2MqVlISyNWnbNvyCQ+j9UfUvwHJ19ZlWrmy02XtT\n/UxNm1YuIZipz1Q1tmSfqbqeMu5h69y58jMtWxYmTyt/rawsbO7h85TXv69dG6piNm0Ks6Vs3Lj5\n88RObi+8EBZRWbcuvG/dOlizBpYvD6Nt77yzMs7Ez1dVv36VSaFjx3BH0K1b5da9e+Xz0tLKlbvu\nuee751qwoOafI/WYu2dkA44hVBmV748EbqtS5llgSML+RGBgsvMOGDDA0zVixGKv/FXffOvbd/Oy\nDRtWXw7cb7utstzo0TWXA/eNGyvLDh5cc7lhwz6vKDdzZvJzvvFG5TnPOafmcnF/ptNPryyXqc9U\nVFRa559p0KCay51xRmW5GTOSn/Ott9wnTZrk7u6jRtVcbvfdK89ZVubeqZN7z57uAwe6Dx8eruPF\nF7vfeKP7nDmVZTduDOXTVR5bLlJs6UkWGzDNU/jujmEF0C1nZmcDZwN07tyZyZMnp3Wehg2706bN\nxmpfM1vL5MkzK/Zbt96b0tLq76UXLVrA5MlhJvEFCzrRpk3vGn/mlClv0LBhGAxeVtaXNm1a1hDb\n+orPtXBhC9q06VfjOWfNepf168OfvcuX96JNmy4Z/UzuTmJHg1Q/08qVy5g8eX6GP9MPKCtrUG3Z\nqp+pbdvq/53MNv9MRUW707FjK8ycBg3AzDEL5dat+4rJk8Of2EuWNKN3711p2NBp2NBp1Kgseh4e\n339/Ie3bFzN58mS6d+/AySe3pkmTUho3LqNJkzKaNi2ldesS2rffyOTJlbcxjz5a42Xiq6/CqN+6\nUFxcnPbvUqYptvTUSWypZI50NmBvYELC/qXApVXK3A2ckLD/AdA12Xm35k4hXzN83BRb+nI5PsWW\nnnyNjRTvFKr/E6tuTAX6mFlPM2sMHA+Mq1JmHHCKBT8AVnmG2hNERKR2Gas+8jC24TxgAqFL6n3u\nPtfMRkWv3wWMJ3RHnU/oknp6puIREZHaZbRNwd3HE774E4/dlfDcgXMzGYOIiKQuk9VHIiKSZ5QU\nRESkgpKCiIhUUFIQEZEKSgoiIlLBQgeg/GFmXwGfpPn2jsDXdRhOXVJs6cnl2CC341Ns6cnX2HZw\n921qO0HeJYWtYWbT3H1g3HFUR7GlJ5djg9yOT7Glp9BjU/WRiIhUUFIQEZEK9S0pVDOrfM5QbOnJ\n5dggt+NTbOkp6NjqVZuCiIgkV9/uFEREJIl6kxTMbJiZfWBm883skrjjSWRmi8zsXTObaWbTYo7l\nPjNbZmZzEo61N7P/mdlH0WO7HIrtSjNbEl27mWZ2aEyxbWdmk8xsnpnNNbPfRMdjv3ZJYov92plZ\nUzN728xmRbH9MTqeC9etpthiv24JMRaZ2Ttm9my0v9XXrV5UH5lZEfAhcBCwmLDWwwnuPi/pG7PE\nzBYRliGNve+zme0HFBPWzt49OnYdsNzdr4kSajt3vzhHYrsSKHb367MdT5XYuhIWiJphZq2A6cCR\nwGnEfO2SxHYsMV87C0v6tXD3YjNrBLwK/Ab4KfFft5piG0YO/J8DMLPfAQOB1u5+WF38rtaXO4VB\nwHx3X+DuG4ExwIiYY8pJ7v4ysLzK4RHAg9HzBwlfKFlXQ2w5wd2/cPcZ0fPVwHtAN3Lg2iWJLXbR\nomDF0W6jaHNy47rVFFtOMLPuwHDg3oTDW33d6ktS6AZ8lrC/mBz5pYg48KKZTY/Wo841nRNWxPsS\n6BxnMNX4lZnNjqqXYqnaSmRmPYDvA2+RY9euSmyQA9cuqgKZCSwD/ufuOXPdaogNcuC6ATcBFwFl\nCce2+rrVl6SQ64a4e3/gEODcqJokJ0ULI+XMX0vAnUAvoD/wBXBDnMGYWUvgCeC37v5t4mtxX7tq\nYsuJa+fupdH//+7AIDPbvcrrsV23GmKL/bqZ2WHAMnefXlOZdK9bfUkKS4DtEva7R8dygrsviR6X\nAU8RqrtyydKoXrq8fnpZzPFUcPel0S9uGfAPYrx2Ub3zE8DD7v5kdDgnrl11seXStYviWQlMItTZ\n58R1qy62HLlu+wBHRO2RY4ADzOxf1MF1qy9JYSrQx8x6mllj4HhgXMwxAWBmLaLGP8ysBXAwMCf5\nu7JuHHBq9PxU4JkYY9lM+S9A5ChiunZRo+Ro4D13vzHhpdivXU2x5cK1M7NtzKxt9LwZoTPI++TG\ndas2tly4bu5+qbt3d/cehO+zl9z9ZOriurl7vdiAQwk9kD4GLo87noS4egGzom1u3LEBjxBuiTcR\n2l5+DnQAJgIfAS8C7XMotoeAd4HZ0S9E15hiG0K4VZ8NzIy2Q3Ph2iWJLfZrB/QF3olimANcER3P\nhetWU2yxX7cqce4PPFtX161edEkVEZHU1JfqIxERSYGSgoiIVFBSEBGRCkoKIiJSQUlBREQqKClI\n3jGz4uixh5mdWMfnvqzK/ut1ef5sysT1kcKnpCD5rAewRV96ZtawliKbJQV3/+EWxpRLerCF10dE\nSUHy2TXAvtGc9udHk5f9zcymRpOV/QLAzPY3s1fMbBwwLzr2dDQB4dzySQjN7BqgWXS+h6Nj5Xcl\nFp17joW1L45LOPdkMxtrZu+b2cPRCGLM7BoLaxjMNrPvTLNsZi3N7P7ofLPN7Ojo+AnRsTlmdm1C\n+eKE58eY2QPR8wfM7BYze93MFpjZMdVdn7q88FLA4hyJp01bOhthLntIGMkZ7Z8N/D563gSYBvSM\nyq0BeiaUbR89NiOMVu2QeO5qftbRwP+AIsLMk58CXaNzryLMp9UAeIMwgrgD8AGVa5a0reZzXAvc\nlLDfDtg2Ovc2QEPgJeDIqrEBxwAPRM8fAB6Pfv6uhGniv3N9tGlLZdOdghSSg4FToqmO3yJ8MfeJ\nXnvb3RcmlP21mc0C3iRMltiH5IYAj3iYCG0pMAXYK+Hciz1MkDaTUG2zClgPjDaznwJrqznngcDt\n5TvuviI652R3/8rdS4CHgVRmzX3a3cs8LByVa1ObSx5RUpBCYsCv3L1/tPV09/9Gr62pKGS2P+EL\neW9370eY36bpVvzcDQnPS4GG0Rf6IGAscBjwwlacv1zinDRV402MwergZ0k9paQg+Ww10CphfwLw\ny2iaaMxsp2jm2araACvcfa2Z7QL8IOG1TeXvr+IV4Lio3WIbwl/vb9cUWLR2QRt3Hw+cD/Srptj/\ngHMT3tMuOuePzKyjhWVkTyDclUCYFvl7ZtaAMDtnbapeH5FaKSlIPpsNlFpYWP18wrKE84AZZjYH\nuJtQL1/VC0BDM3uP0Bj7ZsJr9wCzyxuaEzwV/bxZhHr+i9z9yySxtQKeNbPZhLV9f1dNmauAdlGD\n8ixgqIdVsy4hzN0/C5ju7uXTH18CPAu8TpgttjZVr49IrTRLqoiIVNCdgoiIVFBSEBGRCkoKIiJS\nQUlBREQqKCmIiEgFJQUREamgpCAiIhWUFEREpML/B2V4Aty/A2lYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x133c93450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12e5dc190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(xrange(model_plsa.num_phi_updates), model_plsa.score_tracker['SparsityPhiScore'].value, 'b--',\n",
    "                 xrange(model_artm.num_phi_updates), model_artm.score_tracker['SparsityPhiScore'].value, 'r--', linewidth=2)\n",
    "plt.xlabel('Iterations count')\n",
    "plt.ylabel('PLSA Phi sp. (blue), ARTM Phi sp. (red)')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(xrange(model_plsa.num_phi_updates), model_plsa.score_tracker['SparsityThetaScore'].value, 'b--',\n",
    "                 xrange(model_artm.num_phi_updates), model_artm.score_tracker['SparsityThetaScore'].value, 'r--', linewidth=2)\n",
    "plt.xlabel('Iterations count')\n",
    "plt.ylabel('PLSA Theta sp. (blue), ARTM Theta sp. (red)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кажется, что достигнутых результатов достаточно. Регуляризация позволила добиться улучшения всех характеристик, ухудшив перплексию в пределах разумного. Взглянем на топ-слова слова моделей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic_0:  [u'year', u'tax', u'jobs', u'america', u'president', u'issues']\n",
      "topic_1:  [u'people', u'war', u'service', u'military', u'rights', u'vietnam']\n",
      "topic_2:  [u'november', u'electoral', u'account', u'polls', u'governor', u'contact']\n",
      "topic_3:  [u'republican', u'gop', u'senate', u'senator', u'south', u'conservative']\n",
      "topic_4:  [u'people', u'time', u'country', u'speech', u'talking', u'read']\n",
      "topic_5:  [u'dean', u'democratic', u'edwards', u'primary', u'kerry', u'clark']\n",
      "topic_6:  [u'state', u'party', u'race', u'candidates', u'candidate', u'elections']\n",
      "topic_7:  [u'administration', u'president', u'years', u'bill', u'white', u'cheney']\n",
      "topic_8:  [u'campaign', u'national', u'media', u'local', u'late', u'union']\n",
      "topic_9:  [u'house', u'million', u'money', u'republican', u'committee', u'delay']\n",
      "topic_10:  [u'republicans', u'vote', u'senate', u'election', u'democrats', u'house']\n",
      "topic_11:  [u'iraq', u'war', u'american', u'iraqi', u'military', u'intelligence']\n",
      "topic_12:  [u'kerry', u'poll', u'percent', u'voters', u'polls', u'numbers']\n",
      "topic_13:  [u'news', u'time', u'asked', u'political', u'washington', u'long']\n",
      "topic_14:  [u'bush', u'general', u'bushs', u'kerry', u'oct', u'states']\n"
     ]
    }
   ],
   "source": [
    "for topic_name in model_plsa.topic_names:\n",
    "    print topic_name + ': ',\n",
    "    print model_plsa.score_tracker['TopTokensScore'].last_tokens[topic_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic_0:  [u'party', u'political', u'issue', u'tax', u'america', u'issues']\n",
      "topic_1:  [u'people', u'military', u'official', u'officials', u'service', u'public']\n",
      "topic_2:  [u'electoral', u'governor', u'account', u'contact', u'ticket', u'experience']\n",
      "topic_3:  [u'gop', u'convention', u'senator', u'debate', u'south', u'sen']\n",
      "topic_4:  [u'country', u'speech', u'bad', u'read', u'end', u'talking']\n",
      "topic_5:  [u'democratic', u'dean', u'john', u'edwards', u'primary', u'clark']\n",
      "topic_6:  [u'percent', u'race', u'candidates', u'candidate', u'win', u'nader']\n",
      "topic_7:  [u'administration', u'years', u'white', u'year', u'bill', u'jobs']\n",
      "topic_8:  [u'campaign', u'national', u'media', u'press', u'local', u'ads']\n",
      "topic_9:  [u'house', u'republican', u'million', u'money', u'elections', u'district']\n",
      "topic_10:  [u'november', u'poll', u'senate', u'republicans', u'vote', u'election']\n",
      "topic_11:  [u'iraq', u'war', u'american', u'iraqi', u'security', u'united']\n",
      "topic_12:  [u'bush', u'kerry', u'general', u'president', u'voters', u'bushs']\n",
      "topic_13:  [u'time', u'news', u'long', u'asked', u'washington', u'political']\n",
      "topic_14:  [u'state', u'states', u'people', u'oct', u'fact', u'ohio']\n"
     ]
    }
   ],
   "source": [
    "for topic_name in model_artm.topic_names:\n",
    "    print topic_name + ': ',\n",
    "    print model_artm.score_tracker['TopTokensScore'].last_tokens[topic_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что темы примерно одинаково интерпретируемы, но в модели ARTM они существенно разнообразнее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Извлечём матрицу $\\Phi$ в виде pandas.DataFrame и напечатаем её (в случае необходимости, можно извлекать части матрицы с помощью метода ARTM.get_phi()):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   topic_0   topic_1   topic_2   topic_3   topic_4   topic_5  \\\n",
      "predebate         0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "barbour           0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "bumblebums        0.000000  0.000000  0.000620  0.000000  0.000000  0.000000   \n",
      "spindizzy         0.000000  0.000000  0.000647  0.000000  0.000000  0.000000   \n",
      "mcentee           0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "aft               0.000000  0.000000  0.000000  0.000000  0.000000  0.000419   \n",
      "postdebate        0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "abrams            0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "bulb              0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "deanclark         0.000000  0.000000  0.000000  0.000000  0.000000  0.000348   \n",
      "amphibians        0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "flypaper          0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "inactive          0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "steinhardt        0.000000  0.000000  0.000000  0.000000  0.000365  0.000000   \n",
      "lightbulb         0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "oceana            0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "dingell           0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "sproul            0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "alzheimers        0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "yucca             0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "timken            0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "russo             0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "leach             0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "ndp               0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "berg              0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "bishops           0.000433  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "holidays          0.000000  0.000000  0.000000  0.000297  0.000000  0.000000   \n",
      "relax             0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "veepstakes        0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "theaters          0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "...                    ...       ...       ...       ...       ...       ...   \n",
      "favored           0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "review            0.002021  0.000348  0.000000  0.000000  0.000334  0.000000   \n",
      "ranch             0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "devastating       0.000000  0.000000  0.000029  0.000000  0.000183  0.000000   \n",
      "responsibilities  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "call              0.000000  0.000083  0.000000  0.000056  0.000564  0.001482   \n",
      "ceiling           0.000000  0.000000  0.000000  0.000411  0.000000  0.000000   \n",
      "chief             0.000000  0.000085  0.000000  0.000000  0.000000  0.000000   \n",
      "blowing           0.000000  0.000000  0.000000  0.000549  0.000000  0.000000   \n",
      "concern           0.000000  0.000004  0.000000  0.000000  0.001301  0.000000   \n",
      "gun               0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "notice            0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "model             0.000963  0.000000  0.000000  0.000000  0.000303  0.000000   \n",
      "options           0.000000  0.000000  0.000000  0.000030  0.000000  0.000000   \n",
      "referring         0.000000  0.000224  0.000000  0.000000  0.000000  0.000000   \n",
      "shows             0.000000  0.000000  0.000000  0.000074  0.000000  0.000000   \n",
      "content           0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "advanced          0.000408  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "posting           0.000000  0.000000  0.000000  0.000000  0.002185  0.000000   \n",
      "band              0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "elect             0.000031  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "catch             0.000000  0.000000  0.000000  0.000000  0.000446  0.000632   \n",
      "brought           0.000000  0.000934  0.000000  0.000047  0.000000  0.000000   \n",
      "limited           0.000374  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "testify           0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "deadline          0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "contempt          0.000000  0.000123  0.000000  0.000000  0.000000  0.000000   \n",
      "administration    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "assets            0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "close             0.000000  0.000000  0.000000  0.000078  0.000118  0.000000   \n",
      "\n",
      "                   topic_6   topic_7   topic_8   topic_9  topic_10  topic_11  \\\n",
      "predebate         0.000000  0.000000  0.000000  0.000000       0.0  0.000000   \n",
      "barbour           0.000000  0.000000  0.000000  0.000000       0.0  0.000000   \n",
      "bumblebums        0.000000  0.000000  0.000000  0.000000       0.0  0.000000   \n",
      "spindizzy         0.000000  0.000000  0.000000  0.000000       0.0  0.000000   \n",
      "mcentee           0.000000  0.000000  0.000778  0.000000       0.0  0.000000   \n",
      "aft               0.000000  0.000000  0.000000  0.000000       0.0  0.000000   \n",
      "postdebate        0.000000  0.000000  0.000000  0.000000       0.0  0.000000   \n",
      "abrams            0.000000  0.000533  0.000000  0.000000       0.0  0.000000   \n",
      "bulb              0.000000  0.000000  0.000000  0.000000       0.0  0.000000   \n",
      "deanclark         0.000000  0.000000  0.000000  0.000000       0.0  0.000000   \n",
      "amphibians        0.000000  0.000000  0.000000  0.000342       0.0  0.000000   \n",
      "flypaper          0.000000  0.000000  0.000000  0.000000       0.0  0.000327   \n",
      "inactive          0.000000  0.000000  0.000000  0.000000       0.0  0.000000   \n",
      "steinhardt        0.000000  0.000000  0.000000  0.000000       0.0  0.000000   \n",
      "lightbulb         0.000000  0.000000  0.000000  0.000000       0.0  0.000000   \n",
      "oceana            0.000571  0.000000  0.000000  0.000000       0.0  0.000000   \n",
      "dingell           0.000000  0.000000  0.000000  0.000517       0.0  0.000000   \n",
      "sproul            0.000000  0.000000  0.000000  0.000831       0.0  0.000000   \n",
      "alzheimers        0.000000  0.000438  0.000000  0.000000       0.0  0.000000   \n",
      "yucca             0.000000  0.000000  0.000000  0.000000       0.0  0.000000   \n",
      "timken            0.000000  0.000000  0.000000  0.000000       0.0  0.000000   \n",
      "russo             0.000000  0.000311  0.000000  0.000000       0.0  0.000000   \n",
      "leach             0.000354  0.000000  0.000000  0.000000       0.0  0.000000   \n",
      "ndp               0.000535  0.000000  0.000000  0.000000       0.0  0.000000   \n",
      "berg              0.000000  0.000000  0.000000  0.000000       0.0  0.000576   \n",
      "bishops           0.000000  0.000000  0.000000  0.000000       0.0  0.000000   \n",
      "holidays          0.000000  0.000000  0.000000  0.000000       0.0  0.000000   \n",
      "relax             0.000000  0.000000  0.000000  0.000000       0.0  0.000000   \n",
      "veepstakes        0.000139  0.000000  0.000000  0.000000       0.0  0.000000   \n",
      "theaters          0.000000  0.000000  0.000000  0.000552       0.0  0.000000   \n",
      "...                    ...       ...       ...       ...       ...       ...   \n",
      "favored           0.002018  0.000000  0.000000  0.000000       0.0  0.000000   \n",
      "review            0.000000  0.000366  0.000000  0.000000       0.0  0.000000   \n",
      "ranch             0.000000  0.000922  0.000000  0.000000       0.0  0.000000   \n",
      "devastating       0.000000  0.000000  0.000000  0.000000       0.0  0.000369   \n",
      "responsibilities  0.000000  0.000438  0.000000  0.000000       0.0  0.000000   \n",
      "call              0.000000  0.000439  0.001340  0.001730       0.0  0.000000   \n",
      "ceiling           0.000000  0.000000  0.000000  0.000000       0.0  0.000000   \n",
      "chief             0.000000  0.001233  0.000000  0.000275       0.0  0.000000   \n",
      "blowing           0.000000  0.000000  0.000000  0.000000       0.0  0.000000   \n",
      "concern           0.000000  0.000557  0.000000  0.000000       0.0  0.000000   \n",
      "gun               0.000000  0.000278  0.000000  0.000000       0.0  0.000000   \n",
      "notice            0.000000  0.000000  0.000000  0.000000       0.0  0.000000   \n",
      "model             0.000000  0.000000  0.000000  0.000000       0.0  0.000000   \n",
      "options           0.000000  0.000000  0.000313  0.000000       0.0  0.000020   \n",
      "referring         0.000000  0.000000  0.000000  0.000000       0.0  0.000340   \n",
      "shows             0.000000  0.000000  0.003136  0.000000       0.0  0.000000   \n",
      "content           0.000000  0.000000  0.000000  0.000214       0.0  0.000000   \n",
      "advanced          0.000000  0.000000  0.000000  0.000000       0.0  0.000117   \n",
      "posting           0.000000  0.000000  0.000028  0.000000       0.0  0.000000   \n",
      "band              0.000000  0.000000  0.000000  0.000000       0.0  0.000000   \n",
      "elect             0.001650  0.000000  0.000000  0.000000       0.0  0.000000   \n",
      "catch             0.000000  0.000000  0.000283  0.000000       0.0  0.000000   \n",
      "brought           0.000000  0.000117  0.001216  0.000387       0.0  0.000816   \n",
      "limited           0.000124  0.000179  0.000000  0.001287       0.0  0.000000   \n",
      "testify           0.000000  0.000000  0.000000  0.001389       0.0  0.000000   \n",
      "deadline          0.001478  0.000000  0.000000  0.000000       0.0  0.000071   \n",
      "contempt          0.000000  0.000658  0.000000  0.000000       0.0  0.000000   \n",
      "administration    0.000000  0.041239  0.000000  0.000000       0.0  0.001900   \n",
      "assets            0.000000  0.000000  0.000000  0.000000       0.0  0.000129   \n",
      "close             0.012693  0.000000  0.000371  0.000127       0.0  0.000000   \n",
      "\n",
      "                  topic_12  topic_13  topic_14  \n",
      "predebate         0.000000  0.000000  0.000204  \n",
      "barbour           0.000000  0.000000  0.000451  \n",
      "bumblebums        0.000000  0.000000  0.000000  \n",
      "spindizzy         0.000000  0.000000  0.000000  \n",
      "mcentee           0.000000  0.000000  0.000000  \n",
      "aft               0.000000  0.000000  0.000000  \n",
      "postdebate        0.000086  0.000000  0.000763  \n",
      "abrams            0.000000  0.000000  0.000000  \n",
      "bulb              0.000000  0.000360  0.000000  \n",
      "deanclark         0.000000  0.000000  0.000000  \n",
      "amphibians        0.000000  0.000000  0.000000  \n",
      "flypaper          0.000000  0.000000  0.000000  \n",
      "inactive          0.000000  0.000460  0.000000  \n",
      "steinhardt        0.000000  0.000000  0.000000  \n",
      "lightbulb         0.000000  0.000460  0.000000  \n",
      "oceana            0.000000  0.000000  0.000000  \n",
      "dingell           0.000000  0.000000  0.000000  \n",
      "sproul            0.000000  0.000000  0.000000  \n",
      "alzheimers        0.000000  0.000000  0.000000  \n",
      "yucca             0.000000  0.000360  0.000000  \n",
      "timken            0.000000  0.000000  0.000521  \n",
      "russo             0.000000  0.000000  0.000000  \n",
      "leach             0.000000  0.000000  0.000000  \n",
      "ndp               0.000000  0.000000  0.000000  \n",
      "berg              0.000000  0.000000  0.000000  \n",
      "bishops           0.000000  0.000000  0.000000  \n",
      "holidays          0.000000  0.000000  0.000000  \n",
      "relax             0.000000  0.000427  0.000000  \n",
      "veepstakes        0.000000  0.000000  0.000167  \n",
      "theaters          0.000000  0.000000  0.000000  \n",
      "...                    ...       ...       ...  \n",
      "favored           0.000000  0.000000  0.000000  \n",
      "review            0.000000  0.000000  0.000091  \n",
      "ranch             0.000016  0.000000  0.000000  \n",
      "devastating       0.000000  0.000209  0.000000  \n",
      "responsibilities  0.000000  0.000000  0.000000  \n",
      "call              0.000000  0.004296  0.001357  \n",
      "ceiling           0.000000  0.000000  0.000000  \n",
      "chief             0.000000  0.003590  0.000000  \n",
      "blowing           0.000005  0.000000  0.000000  \n",
      "concern           0.000000  0.000764  0.000000  \n",
      "gun               0.000000  0.001487  0.000062  \n",
      "notice            0.000000  0.001847  0.000586  \n",
      "model             0.000000  0.000711  0.000000  \n",
      "options           0.000000  0.001011  0.000000  \n",
      "referring         0.000000  0.000335  0.000000  \n",
      "shows             0.005833  0.000443  0.000000  \n",
      "content           0.000000  0.001243  0.000000  \n",
      "advanced          0.000000  0.000035  0.000000  \n",
      "posting           0.000000  0.000000  0.000000  \n",
      "band              0.000000  0.001093  0.000000  \n",
      "elect             0.000000  0.000000  0.000000  \n",
      "catch             0.000000  0.000572  0.000000  \n",
      "brought           0.000000  0.000136  0.000000  \n",
      "limited           0.000000  0.000241  0.000000  \n",
      "testify           0.000000  0.000000  0.000000  \n",
      "deadline          0.000000  0.000000  0.000752  \n",
      "contempt          0.000000  0.000000  0.000000  \n",
      "administration    0.000000  0.000000  0.000000  \n",
      "assets            0.000000  0.000331  0.000000  \n",
      "close             0.000448  0.000000  0.000096  \n",
      "\n",
      "[6906 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "print model_artm.phi_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дополнительно извлечём $\\Theta$ в виде pandas.DataFrame и напечатаем её:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              3001      3002      3003      3004      3005      3006  \\\n",
      "topic_0   0.076121  0.035934  0.069378  0.136763  0.083616  0.011376   \n",
      "topic_1   0.095388  0.029030  0.034951  0.043516  0.064788  0.022496   \n",
      "topic_2   0.004087  0.048284  0.012102  0.006648  0.015708  0.520680   \n",
      "topic_3   0.057739  0.029823  0.122427  0.085728  0.060413  0.016142   \n",
      "topic_4   0.122659  0.046273  0.084217  0.077540  0.064804  0.014840   \n",
      "topic_5   0.025646  0.010737  0.024132  0.051743  0.059580  0.017807   \n",
      "topic_6   0.044074  0.017331  0.072042  0.042680  0.036825  0.017084   \n",
      "topic_7   0.061900  0.059854  0.022353  0.029254  0.002857  0.005222   \n",
      "topic_8   0.049225  0.048494  0.043635  0.095823  0.025636  0.016371   \n",
      "topic_9   0.070107  0.492084  0.014166  0.131111  0.200206  0.025601   \n",
      "topic_10  0.056218  0.023523  0.158902  0.092289  0.059759  0.239757   \n",
      "topic_11  0.158816  0.031754  0.028020  0.024615  0.041939  0.006004   \n",
      "topic_12  0.054254  0.027387  0.191633  0.078728  0.125391  0.052282   \n",
      "topic_13  0.056038  0.056568  0.025291  0.041948  0.110979  0.032068   \n",
      "topic_14  0.067728  0.042923  0.096751  0.061612  0.047497  0.002270   \n",
      "\n",
      "              3007      3008      3009      3010    ...         1991  \\\n",
      "topic_0   0.153216  0.031590  0.066032  0.036219    ...     0.087483   \n",
      "topic_1   0.041968  0.009981  0.024485  0.055780    ...     0.066557   \n",
      "topic_2   0.010361  0.000000  0.012824  0.004855    ...     0.014151   \n",
      "topic_3   0.140114  0.095807  0.090739  0.080190    ...     0.042040   \n",
      "topic_4   0.028386  0.042167  0.044592  0.068054    ...     0.154455   \n",
      "topic_5   0.039975  0.080582  0.077005  0.067891    ...     0.041704   \n",
      "topic_6   0.186580  0.291586  0.159586  0.068007    ...     0.063998   \n",
      "topic_7   0.033841  0.019672  0.033055  0.071856    ...     0.042064   \n",
      "topic_8   0.021736  0.015335  0.030470  0.059429    ...     0.089434   \n",
      "topic_9   0.158546  0.344387  0.276788  0.279664    ...     0.026684   \n",
      "topic_10  0.032311  0.000000  0.048914  0.031847    ...     0.039044   \n",
      "topic_11  0.024322  0.002047  0.013785  0.018584    ...     0.031093   \n",
      "topic_12  0.044409  0.017861  0.013088  0.019472    ...     0.148379   \n",
      "topic_13  0.032618  0.034591  0.043202  0.063384    ...     0.072390   \n",
      "topic_14  0.051617  0.014394  0.065438  0.074768    ...     0.080524   \n",
      "\n",
      "              1992      1993      1994      1995      1996      1997  \\\n",
      "topic_0   0.081755  0.077711  0.028989  0.063835  0.114106  0.005819   \n",
      "topic_1   0.066412  0.049778  0.011108  0.018087  0.111398  0.034964   \n",
      "topic_2   0.028480  0.008144  0.473278  0.024771  0.018927  0.015803   \n",
      "topic_3   0.063902  0.078202  0.025081  0.073417  0.045897  0.064343   \n",
      "topic_4   0.112710  0.064262  0.047408  0.055399  0.061833  0.013510   \n",
      "topic_5   0.166137  0.200681  0.066656  0.121939  0.034560  0.330883   \n",
      "topic_6   0.062566  0.086463  0.015080  0.105102  0.047171  0.028323   \n",
      "topic_7   0.034254  0.065199  0.023008  0.017095  0.146536  0.045238   \n",
      "topic_8   0.111383  0.100479  0.028989  0.097625  0.092207  0.045791   \n",
      "topic_9   0.023452  0.026833  0.021445  0.028463  0.031318  0.012594   \n",
      "topic_10  0.041248  0.023984  0.177823  0.042699  0.006806  0.090485   \n",
      "topic_11  0.021688  0.023933  0.007305  0.011352  0.132943  0.010550   \n",
      "topic_12  0.025857  0.013149  0.016585  0.109826  0.021381  0.055667   \n",
      "topic_13  0.062305  0.120906  0.039765  0.084878  0.091554  0.025313   \n",
      "topic_14  0.097850  0.060276  0.017479  0.145512  0.043361  0.220717   \n",
      "\n",
      "              1998      1999      2000  \n",
      "topic_0   0.097601  0.074182  0.014716  \n",
      "topic_1   0.080923  0.031054  0.005184  \n",
      "topic_2   0.007222  0.000000  0.000000  \n",
      "topic_3   0.034290  0.018526  0.033572  \n",
      "topic_4   0.030466  0.028672  0.047126  \n",
      "topic_5   0.228804  0.368793  0.424609  \n",
      "topic_6   0.081716  0.079300  0.107600  \n",
      "topic_7   0.036863  0.033008  0.006729  \n",
      "topic_8   0.114196  0.041101  0.059586  \n",
      "topic_9   0.059266  0.005540  0.007309  \n",
      "topic_10  0.055971  0.055681  0.047264  \n",
      "topic_11  0.022400  0.011003  0.000000  \n",
      "topic_12  0.042442  0.197912  0.162936  \n",
      "topic_13  0.024499  0.007307  0.013284  \n",
      "topic_14  0.083341  0.047919  0.070086  \n",
      "\n",
      "[15 rows x 3430 columns]\n"
     ]
    }
   ],
   "source": [
    "theta_matrix = model_artm.get_theta()\n",
    "print theta_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-12:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/flaren/anaconda/envs/MyPython2/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/flaren/anaconda/envs/MyPython2/lib/python2.7/threading.py\", line 754, in run\n",
      "    self.__target(*self.__args, **self.__kwargs)\n",
      "  File \"/Users/flaren/anaconda/envs/MyPython2/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/flaren/anaconda/envs/MyPython2/lib/python2.7/site-packages/bigartm-0.9.0-py2.7.egg/artm/master_component.py\", line 908, in transform\n",
      "    theta_matrix_info = self._lib.ArtmRequestTransformMasterModelExternal(self.master_id, args)\n",
      "  File \"/Users/flaren/anaconda/envs/MyPython2/lib/python2.7/site-packages/bigartm-0.9.0-py2.7.egg/artm/wrapper/api.py\", line 161, in artm_api_call\n",
      "    self._check_error(result)\n",
      "  File \"/Users/flaren/anaconda/envs/MyPython2/lib/python2.7/site-packages/bigartm-0.9.0-py2.7.egg/artm/wrapper/api.py\", line 97, in _check_error\n",
      "    raise exception_class(error_message)\n",
      "InvalidOperationException: Transform: no batches to process\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_batch_vectorizer = artm.BatchVectorizer(data_format='batches', data_path='kos_test', batches=['test_docs.batch'])\n",
    "test_theta_matrix = model_artm.transform(batch_vectorizer=test_batch_vectorizer)\n",
    "print test_theta_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"> Conclusion </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Задача построения тематической модели имеет бесконечно большое множество решений. Это даёт большую свободу действий, и регуляризаторы позволяют использовать её для получения результата, удовлетворяющего сразу нескольким требованиям (разреженность, интерпретируемость, удовлетворительное значение перплексии и т.п.).\n",
    "\n",
    "Приведённый выше пример является демонстрационным, можно пробовать более гибкие стратегии регуляризации для получения ещё более хорошего результата. По аналогичной схеме можно производить эксперименты с более крупными коллекциями.\n",
    "\n",
    "\n",
    "** Check questions **\n",
    "\n",
    "1) В чем основноя отличие PLSA и LDA? На каких объемах выборок разница между моделями наиболее заметна?\n",
    "\n",
    "2) Зачем нужна регуляризация тематической модели?\n",
    "\n",
    "3) По каким параметрам можно сделать предположения о интерпретируемости модели?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1]  Hofmann T. Probabilistic latent semantic indexing. SIGIR 1999. Pp.50-57\n",
    "\n",
    "[2] Blei D., Ng A., Jordan M. Latent Dirichlet Allocation //\n",
    "    Journal of Machine Learning Research, 2003. - No.3.  Pp. 993-1022.\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
