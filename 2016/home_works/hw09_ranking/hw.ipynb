{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "МФТИ ФИВТ, Машинное обучение, Никита Волков\n",
    "\n",
    "# Ранжирование\n",
    "\n",
    "Дедлайн **24 ноября 23:59** для 399 группы и **25 ноября 23:59** для остальных групп.\n",
    "\n",
    "\n",
    "Для выполнения задания потребуются следующие библиотеки: bs4, urllib, networkx. Следующими командами можно их поставить (Ubuntu):\n",
    "\n",
    "sudo pip3 install beautifulsoup4\n",
    "\n",
    "sudo pip3 install urllib2\n",
    "\n",
    "sudo pip3 install networkx\n",
    "\n",
    "--------------\n",
    "\n",
    "Прежде чем начать читать задание, просто посмотрите на картинку ранжирования котов :)\n",
    "\n",
    "<img width=500 src=\"./resize.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тест\n",
    "\n",
    "**1.** Что является объектом в задаче обучения ранжированию? Какой смысл имеют целевые метки? Какие объекты сравнимы между собой?\n",
    "\n",
    "<Ответ>\n",
    "\n",
    "**2.** В чем преимущество метрики NDCG перед метрикой MAP?\n",
    "\n",
    "<Ответ>\n",
    "\n",
    "**3.** Почему говорят, что все основные метрики качества дискретны?\n",
    "\n",
    "<Ответ>\n",
    "\n",
    "**4.** В чем преимущество факторизации в модели RankNet?\n",
    "\n",
    "<Ответ>\n",
    "\n",
    "**5.** Как решается проблема дискретности метрик в моделях LambdaRank и LambdaMART?\n",
    "\n",
    "<Ответ>\n",
    "\n",
    "**6.** Какое преобразование данных используется в модели RankSVM?\n",
    "\n",
    "<Ответ>\n",
    "\n",
    "**7.** Как изменится верхняя оценка на скорость сходимости в модели PageRank, если считать, что при операции телепортации пользователь всегда выбирает страницу, отличную от текущей?\n",
    "\n",
    "<Ответ>\n",
    "\n",
    "**8.** Имеет ли смысл выполнять итерации в методе power iteration для разных начальных распределений $\\Pi^{(0)}$ с точки зрения теории? А с точки зрения практического применения, не обязательно при этом доводя до сходимости?\n",
    "\n",
    "<Ответ>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задачи\n",
    "\n",
    "(студенты 399 группы могут принести решение на листочках на семинар)\n",
    "\n",
    "**1.** Предположим, что известные вероятностности в модели RankNet задаются по правилу\n",
    "$$Q_{ij} = \\mathsf{Q}(X_i \\triangleright X_j) = \\frac{1}{1 + e^{-\\sigma (Y_i - Y_j)}}.$$\n",
    "Можно ли провести факторизацию в данной модели?\n",
    "\n",
    "**2.** Покажите, что вес PageRank каждой страницы не меньше $\\frac{p}{|V|}$.\n",
    "\n",
    "**3.** Пользователь браузера в дополнение к кликам по ссылкам один раз может перейти по кнопке *Назад* и вернуться на предыдущую страницу. Можно ли такую модель описать с помощью однородной марковской цепи? Если да, опишите, если нет, докажите.\n",
    "\n",
    "<Решения>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import bernoulli\n",
    "import networkx\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import urlparse, urlunparse\n",
    "from time import sleep\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('text.latex', unicode=True)\n",
    "plt.rc('text.latex', preamble='\\\\usepackage[utf8]{inputenc}')\n",
    "plt.rc('text.latex', preamble='\\\\usepackage[russian]{babel}')\n",
    "plt.rc('font', family='serif', size='16')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте вычисление весов PageRank power-методом.\n",
    "\n",
    "Реализовать может быть удобнее с помощью функции np.nan_to_num, которая в данном numpy.array заменит все вхождения nan на ноль. Это позволяет удобно производить поэлементное деление одного вектора на другой в случае, если во втором векторе есть нули.\n",
    "\n",
    "**Внимание!** Эти функции будут проверяться автоматическими тестами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_page_rank_markov_chain(links, damping_factor=0.15, N=None):\n",
    "    ''' По веб-графу со списком ребер links строит матрицу \n",
    "    переходных вероятностей соответствующей марковской цепи.\n",
    "    \n",
    "        links --- список (list) пар вершин (tuple), \n",
    "                может быть передан в виде numpy.array, shape=(|E|, 2);\n",
    "        damping_factor --- вероятность перехода не по ссылке (float);\n",
    "        N --- число веб-страниц;\n",
    "        \n",
    "        Возвращает prob_matrix --- numpy.matrix, shape=(|V|, |V|).\n",
    "    '''\n",
    "\n",
    "    links = np.array(links)\n",
    "    if N is None:\n",
    "        N = links.max() + 1\n",
    "    \n",
    "    <...>\n",
    "    \n",
    "    return prob_matrix\n",
    "\n",
    "\n",
    "def page_rank(links, start_distribution, damping_factor=0.15, \n",
    "              tolerance=10 ** (-7), return_trace=False):\n",
    "    ''' Вычисляет веса PageRank для веб-графа со списком ребер links \n",
    "    степенным методом, начиная с начального распределения start_distribution, \n",
    "    доводя до сходимости с точностью tolerance.\n",
    "    \n",
    "        links --- список (list) пар вершин (tuple), \n",
    "                может быть передан в виде numpy.array, shape=(|E|, 2);\n",
    "        start_distribution --- вектор размерности |V| в формате numpy.array;\n",
    "        damping_factor --- вероятность перехода не по ссылке (float);\n",
    "        tolerance --- точность вычисления предельного распределения;\n",
    "        return_trace --- если указана, то возвращает список распределений во \n",
    "                            все моменты времени до сходимости\n",
    "    \n",
    "        Возвращает:\n",
    "        1). если return_trace == False, то возвращает distribution --- \n",
    "        приближение предельного распределения цепи,\n",
    "        которое соответствует весам PageRank.\n",
    "        Имеет тип numpy.array размерности |V|.\n",
    "        2). если return_trace == True, то возвращает также trace ---\n",
    "        список распределений во все моменты времени до сходимости. \n",
    "        Имеет тип numpy.array размерности \n",
    "        (количество итераций) на |V|.\n",
    "    '''\n",
    "    \n",
    "    prob_matrix = create_page_rank_markov_chain(links, \n",
    "                                                damping_factor=damping_factor)\n",
    "    distribution = np.matrix(start_distribution)\n",
    "    \n",
    "    <...>\n",
    "    \n",
    "    if return_trace:\n",
    "        return np.array(distribution).ravel(), np.array(trace)\n",
    "    else:\n",
    "        return np.array(distribution).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте посмотрим, как оно работает.\n",
    "Напишите для начала функцию для генерации случайного ориентированного графа $G(n, p)$. Случайный граф генерируется следующий образом. Берется множество $\\{0, ..., n-1\\}$, которое есть множество вершин этого графа. Ребро $(i, j)$ (пара упорядочена, возможно повторение) добавляется в граф независимо от других ребер с вероятностью $p$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_graph(n, p):\n",
    "    return <Cписок ребер. Сможете в одну строчку? ;)>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь сгенерируем случайный граф и нарисуем его."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N, p = 10, 0.2\n",
    "edges = random_graph(N, p)\n",
    "\n",
    "G = networkx.DiGraph()\n",
    "G.add_edges_from(edges)\n",
    "plt.axis('off')\n",
    "networkx.draw_networkx(G, width=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем его PageRank и изобразим так, чтобы размер вершины был пропорционален ее весу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_distribution = np.ones((1, N)) / N\n",
    "pr_distribution = page_rank(edges, start_distribution)\n",
    "\n",
    "size_const = 10 ** 4\n",
    "plt.axis('off')\n",
    "networkx.draw_networkx(G, width=0.5, node_size=size_const * pr_distribution, \n",
    "                       node_color=pr_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы уже отмечали выше, эргодическая теорема дает верхнюю оценку на скорость сходимости. Давайте посмотрим, насколько она является точной. Для этого при вычислении PageRank нужно установить флаг return_trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pr_distribution, pr_trace = page_rank(edges, start_distribution, \n",
    "                                      return_trace=True)\n",
    "errors = np.abs(pr_trace - pr_trace[-1]).sum(axis=(1, 2))\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "x = np.arange(len(errors))\n",
    "plt.plot(x, errors, lw=2, label='error')\n",
    "plt.plot(x, <верхняя оценка скорости сходимости из эргодической теоремы>, \n",
    "         lw=2, label='estimation')\n",
    "plt.legend()\n",
    "plt.xlabel('iterations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Выводы>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведите небольшое исследование. В ходе исследования выясните, как скорость сходимости (количество итераций до сходимости) зависит от $n$ и $p$, а так же начального распределения. Вычислите также веса PageRank для некоторых неслучайных графов. В каждом случае стройте графики. От чего зависит вес вершины?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Исследования и выводы>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2\n",
    "\n",
    "В этой части вам предстоит построить реальный веб-граф и посчитать его PageRank. Ниже определены вспомогательные функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_links(url, sleep_time=1, attempts=5, timeout=20):\n",
    "    ''' Загружает страницу по ссылке url и выдает список ссылок, \n",
    "    на которые ссылается данная страница.\n",
    "        url --- string, адрес страницы в интернете;\n",
    "        sleep_time --- задержка перед загрузкой страницы;\n",
    "        timeout --- время ожидания загрузки страницы;\n",
    "        attempts --- число попыток загрузки страницы. \n",
    "        Попытка считается неудачной, если выбрасывается исключение.\n",
    "    \n",
    "        В случае, если за attempts попыток не удалось загрузить страницу,\n",
    "        то последнее исключение пробрасывается дальше.\n",
    "    '''\n",
    "    \n",
    "    sleep(sleep_time)\n",
    "    parsed_url = urlparse(url)\n",
    "    links = []\n",
    "\n",
    "    # Попытки загрузить страницу\n",
    "    for i in range(attempts):\n",
    "        try:\n",
    "            # Ловить исключения только из urlopen может быть недостаточно. \n",
    "            # Он может выдавать какой-то бред вместо исключения, \n",
    "            # из-за которого исключение сгенерирует BeautifulSoup\n",
    "            soup = BeautifulSoup(urlopen(url, timeout=timeout), 'lxml')\n",
    "            break\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            if i == attempts - 1:\n",
    "                raise e\n",
    "\n",
    "    for tag_a in soup('a'):  # Посмотр всех ссылочных тегов\n",
    "        if 'href' in tag_a.attrs:\n",
    "            link = list(urlparse(tag_a['href']))\n",
    "            \n",
    "            # Если ссылка является относительной,\n",
    "            # то ее нужно перевести в абсолютную\n",
    "            if link[0] == '': link[0] = parsed_url.scheme\n",
    "            if link[1] == '': link[1] = parsed_url.netloc\n",
    "            \n",
    "            links.append(urlunparse(link))\n",
    "            \n",
    "    return links\n",
    "\n",
    "\n",
    "def get_site(url):\n",
    "    ''' По ссылке url возвращает адрес сайта. '''\n",
    "    \n",
    "    return urlparse(url).netloc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Код ниже загружает $N$ веб-страниц, начиная с некоторой стартовой страницы и переходя по ссылкам. Загрузка происходит методом обхода в ширину. Все собранные урлы страниц хранятся в urls. В links хранится список ссылок с одной страницы на другую. Особенность кода такова, что в urls хранятся все встреченные урлы, которых может быть сильно больше $N$. Аналогично, в links ребра могут ссылаться на страницы с номером больше $N$. Однако, все ребра из links начинаются только в первых $N$ страницах. Таким образом, для построения веб-графа нужно удалить все, что связано с вершинами, которые не входят в первые $N$.\n",
    "\n",
    "Это очень примерный шаблон, к тому же не оптимальный. Можете вообще его не использовать и написать свое."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "urls = ['http://wikipedia.org/wiki/']\n",
    "site = get_site(urls[0])\n",
    "links = []\n",
    "\n",
    "N = 10\n",
    "for i in range(N):\n",
    "    try:\n",
    "        # Загружаем страницу по урлу и извлекаем из него все ссылки\n",
    "        # Не выставляйте sleep_time слишком маленьким, \n",
    "        # а то еще забанят где-нибудь\n",
    "        links_from_url = load_links(urls[i], sleep_time=0.5)\n",
    "        # Если мы хотим переходить по ссылкам только определенного сайта\n",
    "        links_from_url = list(filter(lambda x: get_site(x) == site, \n",
    "                                     links_from_url))\n",
    "        \n",
    "        # Добавляем соответствующие вершины и ребра в веб-граф\n",
    "        for j in range(len(links_from_url)):\n",
    "            # Такая ссылка уже есть\n",
    "            if links_from_url[j] in urls:\n",
    "                links.append((i, urls.index(links_from_url[j])))\n",
    "            \n",
    "            # Новая ссылка\n",
    "            else:\n",
    "                links.append((i, len(urls)))\n",
    "                urls.append(links_from_url[j])\n",
    "                \n",
    "    except:\n",
    "        pass  # Не загрузилась с 5 попытки, ну и ладно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь выберите какой-нибудь сайт с небольшим количеством страниц (не более 1000). Таким сайтом может быть, например, сайт <a href=http://yandexdataschool.ru>Школы анализа данных</a>, сайт магазина, больницы. Однако, советуем не выбирать сайты типа kremlin.ru, мало ли что.\n",
    "\n",
    "Постройте полный веб-граф для этого сайта и визуализируйте его. При отрисовке выставляйте width не более 0.1, иначе получится ужасно некрасиво.\n",
    "\n",
    "Посчитайте PageRank для этого веб-графа. Визуализируйте данный веб-граф, сделав размер вершин пропорционально весу PageRank (см. пример в части 1). Постройте гистограмму весов. Что можно сказать про скорость сходимости?\n",
    "\n",
    "Выделите небольшое количество (15-20) страниц с наибольшим весом и изобразите граф, индуцированный на этом множестве вершин. Что это за страницы? Почему именно они имеют большой вес?\n",
    "\n",
    "Как меняется вес PageRank для страниц в зависимости от начального приближения в случае, если не доводить итерационный процесс вычисления до сходимости? Какие выводы о поведении пользователя отсюда можно сделать?\n",
    "\n",
    "Для получения дополнительных баллов проведите аналогичные исследования для больших сайтов. Так же вы можете провести исследования, не ограничиваясь загрузкой только одного сайта."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 3\n",
    "\n",
    "Для выполнения этой части вам потребуется библиотека RankLib https://sourceforge.net/p/lemur/wiki/RankLib/\n",
    "\n",
    "Скачайте датасет с конкурса «Интернет-математика 2009»\n",
    "https://academy.yandex.ru/events/data_analysis/grant2009/\n",
    "\n",
    "Разбейте его на три части train, test, valid размера 10% каждая.\n",
    "Функции, реализующие это, возьмите с семинара.\n",
    "\n",
    "Обучите на train методы MART и LambdaMART на 300 итераций, указав им метрику NDCG и передав так же valid.\n",
    "Записывайте сюда команды аналогично тому, как это было сделано на семинаре.\n",
    "Значения метрики в зависимости от номера итерации сохранились в log-файле.\n",
    "Для считывания поможет приведенная ниже функция."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_metric_dependence_from_file(file_name, num_lines, num_blocks=1):\n",
    "    ''' Извлекает значения метрики в процессе обучения из log-файлов, \n",
    "    создаваемых библиотекой RankLib при обучении.\n",
    "        file_name --- имя log-файла\n",
    "        num_lines --- число строк, в которых записаны значения. \n",
    "                      Смысл --- количество выполненых итераций при обучении.\n",
    "        num_blocks --- количество блоков значений. \n",
    "                       Смысл --- число k в случае k-fold CV\n",
    "                       \n",
    "        Возвращает лист из np.array в количестве num_blocks.\n",
    "    Первый столбец каждого np.array --- номер итерации. Все следующие --- значения.\n",
    "    '''\n",
    "    \n",
    "    with open(file_name) as f:\n",
    "        text = f.readlines()\n",
    "    \n",
    "    values = []\n",
    "    for block_id in range(num_blocks):\n",
    "        index = text.index('Training starts...\\n') + 4\n",
    "        block_values = np.array(list(map(lambda x: list(map(float, x.split('|')[:-1])), \n",
    "                                         text[index:index + num_lines])))\n",
    "        values.append(block_values)\n",
    "        text = text[index:]\n",
    "        \n",
    "    return values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постройте график значения метрики NDCG в зависимости от номера итерации на train и valid для ранее обученных моделей MART и LambdaMART."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "values = (read_metric_dependence_from_file('... log_LambdaMART', 300)[0],\n",
    "          read_metric_dependence_from_file('... log_MART', 300)[0])\n",
    "\n",
    "plt.figure(figsize=(20, 8))\n",
    "plt.plot(<x>, <y>, lw=2, label=<...>)\n",
    "<...>\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('NDCG')\n",
    "plt.title(<...>)\n",
    "plt.legend(loc=2)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно ли сказать, что какая-то модель работает лучше? Достигается ли точка переобучения?\n",
    "\n",
    "<Ответ>\n",
    "\n",
    "Постройте аналогичные графики для Random Forests и RankNet (по отдельности).\n",
    "Какие выводы можно сделать?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "<...>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Сглаживание дискретных метрик\n",
    "\n",
    "Одна из основных проблем в обучении ранжированию --- дискретность метрик.\n",
    "Мы знаем, как решается эта проблема в LambdaRank и LambdaMART (см. вопрос выше).\n",
    "Однако, в некоторых задачах нужно использовать саму метрику.\n",
    "В связи с этим возникают задачи разработки сглаженных версий дискретных метрик.\n",
    "Рассмотрим самый простой из них.\n",
    "\n",
    "Пусть $X_{train}$ --- обучающая выборка. Разобьем ее на две части независимо $M$ раз: $X_{train} = X_1^m \\sqcup X_2^m$, причем разбиение будем производить *по запросам*, то есть пары $(q, d_1)$ и $(q, d_2)$ попадают в одну из этих двух частей. Далее обучаем наш метод на $X_1^m$ и применяем к $X_{test}$ --- тестовая выборка. Так мы получим $M$ чисел $Z_1, ..., Z_M$, каждое из которых есть значение метрики. Их усреднение дает сглаженное значение метрики."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почему такой способ является нечестным? Как нужно было бы действовать честно?\n",
    "\n",
    "<Ответ>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь вам предстоит построить график сглаженной метрики $NDCG_{10}$ для LambdaMART c 300 деревьями и $M=10$.\n",
    "Алгоритм примерно следующий:\n",
    "\n",
    "на каждой итерации\n",
    "* перемешать $X_{train}$ по запросам. Для этого есть специальная команда, см. описание библиотеки.\n",
    "* разбить $X_{train}$ на две части. Для этого есть функция с семинара.\n",
    "* обучить LambdaMART на первой части на 300 деревьях. Валидационную выборку передавать не нужно.\n",
    "* посчитать значение NDCG на $X_{test}$ по полученной модели в зависимости от количества деревьев.\n",
    "\n",
    "В последнем пункте имеется ввиду следующее. \n",
    "Пусть модель представляется в виде $F(x) = \\sum\\limits_{t=1}^T \\alpha_t f_t(x)$.\n",
    "Нужно посчитать значение метрики по всем моделям $F(x) = \\sum\\limits_{t=1}^K \\alpha_t f_t(x), K=1, ..., T$.\n",
    "\n",
    "Для реализации вам потребуется самостоятельно создать файл с такой моделью на основе файла с обученной моделью, который представляет из себя список деревьев с некоторой дополнительной информацией.\n",
    "Вам нужно в свой файл последовательно добавлять деревья по одному, а затем использовать команду для подсчета значения метрики на тестовой выборке по этой модели, см. описание библиотеки.\n",
    "\n",
    "Выполнив эти операции, постройте график сглаженной метрики. Сравните с графиком исходной метрики."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполнять консольные команды можно в цикле:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    ! echo {np.log(i + 1) ** 2} > file.txt\n",
    "    with open('file.txt') as f:\n",
    "        print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если код выше не работает, воспользуйтесь следующей функцией."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def _run_cmd(cmd, print=False):\n",
    "    \"\"\" Запуск консольной команды cmd \"\"\"\n",
    "    \n",
    "    PIPE = subprocess.PIPE\n",
    "    p = subprocess.Popen(cmd, shell=True, stdin=PIPE, stdout=PIPE,\n",
    "                         stderr=subprocess.STDOUT, close_fds=True)\n",
    "    output = ''\n",
    "    \n",
    "    while True:\n",
    "        s = p.stdout.readline().decode('utf-8')\n",
    "        if not s: break\n",
    "        output += str(s)\n",
    "        if print:\n",
    "            print(s)\n",
    "    \n",
    "    return output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
