{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 14pt\">MIPT, TS forecasting in Retail, Autumn 2017</span>\n",
    "\n",
    "<span style=\"font-size: 16pt\"> Training ES models </span>\n",
    "\n",
    "<span style=\"color:blue; font-size: 12pt\">Alexey Romanenko </span>,\n",
    "<span style=\"color:blue; font-size: 12pt; font-family: 'Verdana'\">alexromsput@gmail.com</span>d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select best ES model for each TS \n",
    "\n",
    "* I.   Download datasets <span style=\"color:blue; font-family:'New Times Roman'; font-size:14pt\">TS_dep36.csv</span> \n",
    "     \n",
    "* II. Define the train period: the beginning is 12.05.2005 and the end is 13.06.2006\n",
    "    \n",
    "* III. For TS_dep36.csv Find the best ES algorithm (it means ES model + its optimal parameters) for each TS by next sheme:\n",
    "     \n",
    "    - 0) Use only following ES models: IES (see seminar 2), AES (see seminar 2), Winters with additive seasonality (see Practice Day 1 task 3), Theil-Wage.\n",
    "    - 1) forecasting delay $h = 1$, loss function is MACAPE;\n",
    "    - 2) For all models find optimal params of each ES models using first 75% of dates (for TS_dep36.csv from 12.05.2005 to 12.03.2006);\n",
    "   \n",
    "    - 3) forecast each TS by each ES Model with optimal params using first 90% of dates (for TS_dep36.csv from 12.05.2005 to 30.04.2006);\n",
    "    \n",
    "    - 4) find the optimal ES algorithm: just compare losses of ES models with optimal params calclated for dates that were not used for tuning parameters (for TS_dev36.csv: from 13.03.2006 to 30.04.2006).\n",
    "    \n",
    "    You need to remember optimal ES algorithm for each TS!\n",
    "    \n",
    "    - 5) Build barchar (histogram) of losses of optimal ES algorithm (were calulated at step before) for all TS (axis x - value of loss, axis y - percentage of TS that have such loss). Here you must exclude those TS which has only NaNs in period under consideration.\n",
    "            \n",
    "* IV. Calculate Forecast for each TS by optimal TS algorithm that you find in step 3 for all dates (for TS_dep36.csv from 12.05.2005 to 13.06.2006). \n",
    "       \n",
    "    - 1) Measure accuracy (loss) of forecast for each TS using dates that were not used in step 2)-3) (for TS_dep36.csv from 12.05.2005 to 12.03.2006), here you must exclude those TS which has only NaNs in the end.\n",
    "    \n",
    "    - 2) Build barchar (histogram) of losses of optimal ES algorithm for all TS (axis x - value of loss, axis y - percentage of TS that has such loss), here you must exclude those TS which has only NaNs in period under consideration.\n",
    "\n",
    "    - 3) Are barcharts calculated in step III.4) and in step IV.2) the same? If they differ than say in what manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rusrom.EUROPE\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import statsmodels.api as sm\n",
    "from utils import qualityMACAPE, build_forecast, plot_tsforecast\n",
    "from utils import InitExponentialSmoothing, AdaptiveExponentialSmoothing, WintersExponentialSmoothing, TWExponentialSmoothing\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Download datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read data\n",
    "ts = pd.read_csv('./data/TS_dep36.csv', sep=';', index_col='Timestamp', parse_dates=True, dayfirst=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Define the train period: the beginning is 12.05.2005 and the end is 13.06.2006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* I use the data from '2005-05-12'-'2006-03-12'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For each model we find best params for EACH of TS and save values in corresponding .csv \n",
    "\n",
    "* For finding best params i use 11 values in [0,1].\n",
    "\n",
    "* In IES and AES I use \"Adaptation period\"=10. But the results for values from 5 to 10 are almost same.\n",
    "\n",
    "* In the models with more than one params (AES, WES, TWES), I use the method of sequentual approximations. I.e. e.g. for WES\n",
    "\n",
    "    1. initialize any $\\alpha$-s and $\\gamma$-s\n",
    "    \n",
    "    2. for initialised $\\alpha$-s find best $\\gamma$-s and vice versa\n",
    "    \n",
    "    3. for new $\\alpha$-s find best $\\gamma$-s and vice versa\n",
    "    \n",
    "    4. do it untill mean_LF(new $\\alpha$-s and previous $\\gamma$-s)=mean_LF(previous $\\alpha$-s and new $\\gamma$-s), and both stop changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Find the best ES algorithm for each ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-1f1c64f420e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mALPHA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mes_params_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'alpha'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'AdaptationPeriod'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m}\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mALPHA\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mFRC_TS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_forecast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malgname\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[1;34m'InitExponentialSmoothing'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malgtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'IES'\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mparams_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mes_params_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# line=np.linspace(0,1,11)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\rusrom.EUROPE\\Documents\\Teaching\\MachineLearning\\ml-mipt-part2\\2017\\seminars\\4_ts_retailTS\\utils.py\u001b[0m in \u001b[0;36mbuild_forecast\u001b[1;34m(h, ts, algname, algtitle, params_array, step)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparams_array\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 218\u001b[1;33m         \u001b[0mfrc_horizon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate_range\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mperiods\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    219\u001b[0m         \u001b[0mfrc_ts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfrc_horizon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# plotTSForecast(ts.loc['2009-01-01':'2009-03-31'], frc_ts.loc['2009-01-01':'2009-03-31'], ts_num=0, alg_title='ES alpha=0.1')\n",
    "\n",
    "#Fit parameters\n",
    "ALPHA = np.linspace(0,1,11)\n",
    "es_params_array = [{'alpha':alpha, 'AdaptationPeriod':10} for alpha in ALPHA]\n",
    "FRC_TS = build_forecast(h=1, ts=ts, algname =  'InitExponentialSmoothing', algtitle='IES' ,params_array = es_params_array)\n",
    "\n",
    "# line=np.linspace(0,1,11)\n",
    "# h = 1\n",
    "# start = train_ts.index[-1]+timedelta(1)\n",
    "# end = train_ts.index[-1]+timedelta(h)\n",
    "# rng = pd.date_range(start, end)\n",
    "\n",
    "# best=np.zeros([len(ts.columns),4,3])\n",
    "# ies = pd.DataFrame(index = train_ts.index.append(rng), columns = ts.columns)\n",
    "# aes = pd.DataFrame(index = train_ts.index.append(rng), columns = ts.columns)\n",
    "# w = pd.DataFrame(index = train_ts.index.append(rng), columns = ts.columns)\n",
    "# tw = pd.DataFrame(index = train_ts.index.append(rng), columns = ts.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "104\n"
     ]
    }
   ],
   "source": [
    "j=0\n",
    "accs=[]\n",
    "for alpha in line:\n",
    "    accs.append([])\n",
    "    i=0\n",
    "    for col in ts.columns:\n",
    "        print(j)\n",
    "        print(i)\n",
    "        display.clear_output(wait=True)\n",
    "        ies[col] = InitExponentialSmoothing(train_ts[col], h, {'alpha':alpha, 'AdaptationPeriod': 10})\n",
    "        accs[j].append(1-qualityMACAPE(ies[col],train_ts[col])[0])\n",
    "        i+=1\n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IES alphas:\n",
      "[ 0.   0.1  0.1  0.1  0.   0.1  0.1  0.   0.   0.   0.1  0.   0.1  0.1  0.\n",
      "  0.1  0.1  0.   0.1  0.1  0.1  0.   0.   0.1  0.   0.1  0.1  0.1  0.   0.1\n",
      "  0.1  0.   0.1  1.   0.   0.1  0.1  0.1  0.1  0.1  0.2  0.   0.   0.   0.\n",
      "  0.1  0.   0.1  0.   0.1  0.1  0.1  0.   0.1  0.   0.1  0.1  0.1  0.1  0.1\n",
      "  0.   0.   0.1  0.1  0.1  1.   1.   0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1\n",
      "  0.1  0.1  1.   0.   1.   0.1  0.1  0.1  0.1  1.   0.1  0.1  0.1  0.1  0.1\n",
      "  0.1  0.1  0.   0.1  0.1  0.1  0.1  1.   1.   0.1  0.2  0.1  0.1  0.1  0.1]\n",
      "0.256956480128\n"
     ]
    }
   ],
   "source": [
    "ies_accs=np.array(accs)\n",
    "arg_max_accs=np.argmax(accs, axis=0)\n",
    "ies_alphas=line[arg_max_accs]\n",
    "print(\"IES alphas:\\n\"+str(ies_alphas))\n",
    "print(ies_accs.max(axis=0).mean())\n",
    "\n",
    "ies_alphas = pd.Series(ies_alphas)\n",
    "ies_alphas.to_csv('params/ies_alphas.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aes_alphas=np.ones(len(ts.columns))/10.0\n",
    "aes_gammas=np.ones(len(ts.columns))/10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma\n",
      "10\n",
      "104\n"
     ]
    }
   ],
   "source": [
    "# j=0\n",
    "# accs1=[]\n",
    "# for alpha in line:\n",
    "#     accs1.append([])\n",
    "#     i=0\n",
    "#     for col in ts.columns:\n",
    "#         print(j)\n",
    "#         print(i)\n",
    "#         display.clear_output(wait=True)\n",
    "#         aes[col] = AdaptiveExponentialSmoothing(train_ts[col], h, {'alpha':alpha, 'gamma': aes_gammas[i], 'AdaptationPeriod':10})\n",
    "#         accs1[j].append(1-qualityMACAPE(aes[col],train_ts[col])[0])\n",
    "#         i+=1\n",
    "#     j+=1\n",
    "\n",
    "# j=0\n",
    "accs2=[]\n",
    "for gamma in line:\n",
    "    accs2.append([])\n",
    "    i=0\n",
    "    for col in ts.columns:\n",
    "        print('gamma')\n",
    "        print(j)\n",
    "        print(i)\n",
    "        display.clear_output(wait=True)\n",
    "        aes[col] = AdaptiveExponentialSmoothing(train_ts[col], h, {'alpha':aes_alphas[i], 'gamma': gamma, 'AdaptationPeriod':10})\n",
    "        accs2[j].append(1-qualityMACAPE(aes[col],train_ts[col])[0])\n",
    "        i+=1\n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aes_accs1=np.array(accs1)\n",
    "arg_max_accs1=np.argmax(aes_accs1, axis=0)\n",
    "aes_alphas=line[arg_max_accs1]\n",
    "\n",
    "aes_accs2=np.array(accs2)\n",
    "arg_max_accs2=np.argmax(aes_accs2, axis=0)\n",
    "aes_gammas=line[arg_max_accs2]\n",
    "\n",
    "aes_alphas = pd.Series(aes_alphas)\n",
    "aes_alphas.to_csv('params/aes_alphas.csv'.format(i))\n",
    "\n",
    "aes_gammas = pd.Series(aes_gammas)\n",
    "aes_gammas.to_csv('params/aes_gammas.csv'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AES alphas:\n",
      "[ 0.   0.1  0.1  0.1  0.   0.1  0.1  0.   0.   0.   0.1  0.   0.1  0.1  0.\n",
      "  0.1  0.1  0.   0.1  0.1  0.1  0.   0.   0.1  0.   0.1  0.1  0.1  0.   0.1\n",
      "  0.1  0.   0.1  1.   0.   0.1  0.1  0.1  0.1  0.1  0.2  0.   0.   0.   0.\n",
      "  0.1  0.   0.1  0.   0.1  0.1  0.1  0.   0.1  0.   0.1  0.1  0.1  0.1  0.1\n",
      "  0.   0.   0.1  0.1  0.1  0.   0.   0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1\n",
      "  0.1  0.   1.   0.   0.2  0.1  0.1  0.1  0.1  1.   0.1  0.1  0.1  0.1  0.1\n",
      "  0.1  0.1  0.   0.1  0.1  0.1  0.1  0.   0.   0.1  0.2  0.1  0.1  0.1  0.1]\n",
      "AES gammas:\n",
      "[ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   1.   1.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.1  0.   0.   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.2  1.   0.   0.   0.   0.   0.   0. ]\n",
      "\n",
      "\n",
      "0.257532812509\n",
      "0.257993587808\n"
     ]
    }
   ],
   "source": [
    "print(\"AES alphas:\\n\"+str(np.array(aes_alphas)))\n",
    "print(\"AES gammas:\\n\"+str(np.array(aes_gammas)))\n",
    "\n",
    "print('\\n')\n",
    "print(aes_accs1.max(axis=0).mean())\n",
    "# plt.plot(range(len(ts.columns)),accs1.max(axis=0))\n",
    "# plt.show()\n",
    "print(aes_accs2.max(axis=0).mean())\n",
    "# plt.plot(range(len(ts.columns)),accs2.max(axis=0))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w_alphas=np.ones(len(ts.columns))/10.0\n",
    "w_gammas=np.ones(len(ts.columns))/10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "104\n"
     ]
    }
   ],
   "source": [
    "j=0\n",
    "accs1=[]\n",
    "for alpha in line:\n",
    "    accs1.append([])\n",
    "    i=0\n",
    "    for col in ts.columns:\n",
    "        print(j)\n",
    "        print(i)\n",
    "        display.clear_output(wait=True)\n",
    "        w[col] = WintersExponentialSmoothing(train_ts[col], h, {'alpha':alpha, 'gamma': w_gammas[i], 'seasonality_period':7})\n",
    "        accs1[j].append(1-qualityMACAPE(w[col],train_ts[col])[0])\n",
    "        i+=1\n",
    "    j+=1\n",
    "\n",
    "# j=0\n",
    "# accs2=[]\n",
    "# for gamma in line:\n",
    "#     accs2.append([])\n",
    "#     i=0\n",
    "#     for col in ts.columns:\n",
    "#         print('gamma')\n",
    "#         print(j)\n",
    "#         print(i)\n",
    "#         display.clear_output(wait=True)\n",
    "#         w[col] = WintersExponentialSmoothing(train_ts[col], h, {'alpha':w_alphas[i], 'gamma': gamma, 'seasonality_period':7})\n",
    "#         accs2[j].append(1-qualityMACAPE(w[col],train_ts[col])[0])\n",
    "#         i+=1\n",
    "#     j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WES alphas:\n",
      "[ 0.   0.   0.1  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.1\n",
      "  0.   0.1  0.   0.1  0.   0.   0.   0.1  0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.1  0.   0.1  0.   0.   0.1  0.   0.   0.1  0.   0.   0.\n",
      "  0.1  0.1  0.1  0.1  0.   0.1  0.   0.   0.   0.   0.   0.1  0.   0.   0.\n",
      "  0.   0.   0.   0.1  0.   0.   0.2  0.   0.1  0.1  0.1  0.1  0.   0.1  0.1\n",
      "  0.1  0.   0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.2  0.1  0.   0.1  0.1  0.1\n",
      "  0.1  0.1  0.1  0.1  0.   0.1  0.1  1.   0.3  0.2  0.2  0.1  0.1  0.1  0.1]\n",
      "WES gammas:\n",
      "[ 0.2  0.2  0.2  0.3  0.1  0.3  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1\n",
      "  0.1  0.1  0.1  0.   0.2  0.2  0.1  0.1  0.2  0.1  0.1  0.1  0.1  0.2  0.1\n",
      "  0.1  0.2  0.1  0.1  0.2  0.1  0.1  0.2  0.1  0.2  0.   0.1  0.2  0.1  0.1\n",
      "  0.2  0.1  0.2  0.1  0.3  0.2  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.3\n",
      "  0.1  0.1  0.2  0.1  0.3  0.1  0.1  0.2  0.2  0.2  0.1  0.1  0.2  0.1  0.1\n",
      "  0.   0.1  0.2  0.1  0.2  0.1  0.   0.1  0.1  0.1  0.1  0.1  0.1  0.2  0.1\n",
      "  0.2  0.1  0.2  0.2  0.1  0.1  0.1  0.   0.2  0.1  0.1  0.3  0.2  0.3  0.2]\n",
      "\n",
      "\n",
      "0.214512600947\n",
      "0.214512600947\n"
     ]
    }
   ],
   "source": [
    "w_accs1=np.array(accs1)\n",
    "arg_max_accs1=np.argmax(w_accs1, axis=0)\n",
    "w_alphas=line[arg_max_accs1]\n",
    "print(\"WES alphas:\\n\"+str(w_alphas))\n",
    "\n",
    "w_accs2=np.array(accs2)\n",
    "arg_max_accs2=np.argmax(w_accs2, axis=0)\n",
    "w_gammas=line[arg_max_accs2]\n",
    "print(\"WES gammas:\\n\"+str(w_gammas))\n",
    "\n",
    "w_alphas = pd.Series(w_alphas)\n",
    "w_alphas.to_csv('params/w_alphas.csv')\n",
    "\n",
    "w_gammas = pd.Series(w_gammas)\n",
    "w_gammas.to_csv('params/w_gammas.csv')\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print(w_accs1.max(axis=0).mean())\n",
    "# plt.plot(range(len(ts.columns)),w_accs1.max(axis=0))\n",
    "# plt.show()\n",
    "print(w_accs2.max(axis=0).mean())\n",
    "# plt.plot(range(len(ts.columns)),w_accs2.max(axis=0))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TWES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tw_alphas=np.ones(len(ts.columns))/10.0\n",
    "tw_betas=np.ones(len(ts.columns))/10.0\n",
    "tw_gammas=np.ones(len(ts.columns))/10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta\n",
      "10\n",
      "104\n"
     ]
    }
   ],
   "source": [
    "# accuracies for alpha\n",
    "# j=0\n",
    "# accs1=[]\n",
    "# for alpha in line:\n",
    "#     accs1.append([])\n",
    "#     i=0\n",
    "#     for col in ts.columns:\n",
    "#         print(j)\n",
    "#         print(i)\n",
    "#         display.clear_output(wait=True)\n",
    "#         tw[col] = TWExponentialSmoothing(train_ts[col], h, {'alpha':alpha, 'beta':tw_betas[i], 'gamma': tw_gammas[i], 'seasonality_period':7})\n",
    "#         accs1[j].append(1-qualityMACAPE(tw[col],train_ts[col])[0])\n",
    "#         i+=1\n",
    "#     j+=1\n",
    "\n",
    "# # accuracies for gamma\n",
    "# j=0\n",
    "# accs2=[]\n",
    "# for gamma in line:\n",
    "#     accs2.append([])\n",
    "#     i=0\n",
    "#     for col in ts.columns:\n",
    "#         print('gamma')\n",
    "#         print(j)\n",
    "#         print(i)\n",
    "#         display.clear_output(wait=True)\n",
    "#         tw[col] = TWExponentialSmoothing(train_ts[col], h, {'alpha':tw_alphas[i], 'beta':tw_betas[i], 'gamma': gamma, 'seasonality_period':7})\n",
    "#         accs2[j].append(1-qualityMACAPE(tw[col],train_ts[col])[0])\n",
    "#         i+=1\n",
    "#     j+=1\n",
    "\n",
    "# accuracies for beta\n",
    "j=0\n",
    "accs3=[]\n",
    "for beta in line:\n",
    "    accs3.append([])\n",
    "    i=0\n",
    "    for col in ts.columns:\n",
    "        print('beta')\n",
    "        print(j)\n",
    "        print(i)\n",
    "        display.clear_output(wait=True)\n",
    "        tw[col] = TWExponentialSmoothing(train_ts[col], h, {'alpha':tw_alphas[i], 'beta':beta, 'gamma': tw_gammas[i], 'seasonality_period':7})\n",
    "        accs3[j].append(1-qualityMACAPE(tw[col],train_ts[col])[0])\n",
    "        i+=1\n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tw_accs1=np.array(accs1)\n",
    "arg_max_accs1=np.argmax(tw_accs1, axis=0)\n",
    "tw_alphas=line[arg_max_accs1]\n",
    "\n",
    "tw_accs2=np.array(accs2)\n",
    "arg_max_accs2=np.argmax(tw_accs2, axis=0)\n",
    "tw_gammas=line[arg_max_accs2]\n",
    "\n",
    "tw_accs3=np.array(accs3)\n",
    "arg_max_accs3=np.argmax(tw_accs3, axis=0)\n",
    "tw_betas=line[arg_max_accs3]\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "tw_alphas = pd.Series(tw_alphas)\n",
    "tw_alphas.to_csv('params/tw_alphas.csv')\n",
    "\n",
    "tw_gammas = pd.Series(tw_gammas)\n",
    "tw_gammas.to_csv('params/tw_gammas.csv')\n",
    "\n",
    "tw_betas = pd.Series(tw_betas)\n",
    "tw_betas.to_csv('params/tw_betas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TWES alphas:\n",
      "[ 0.   0.   0.1  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.1  0.   0.1  0.   0.   0.   0.1  0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.1  0.   0.   0.   0.   0.   0.1  0.   0.   0.\n",
      "  0.1  0.   0.1  0.   0.   0.1  0.   0.   0.   0.   0.   0.1  0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.1  0.   0.1  0.1  0.   0.   0.   0.   0.1\n",
      "  0.1  0.   0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.2  0.1  0.   0.1  0.1  0.1\n",
      "  0.1  0.1  0.1  0.1  0.   0.1  0.1  1.   0.3  0.2  0.2  0.1  0.1  0.1  0.1]\n",
      "TWES gammas:\n",
      "[ 0.2  0.2  0.2  0.3  0.1  0.3  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.2\n",
      "  0.1  0.1  0.1  0.   0.2  0.2  0.1  0.1  0.2  0.1  0.1  0.1  0.1  0.2  0.1\n",
      "  0.1  0.2  0.1  1.   0.2  0.1  0.1  0.2  0.2  0.2  0.   0.1  0.2  0.1  0.1\n",
      "  0.2  0.2  0.2  0.2  0.3  0.2  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.3\n",
      "  0.1  0.1  0.2  0.2  0.3  0.1  0.1  0.2  0.2  0.2  0.3  0.2  0.2  0.2  0.1\n",
      "  0.   0.1  0.2  0.1  0.2  0.1  0.   0.1  0.1  0.1  0.1  0.1  0.1  0.2  0.1\n",
      "  0.2  0.1  0.2  0.2  0.1  0.1  0.1  0.   0.2  0.1  0.1  0.3  0.2  0.3  0.2]\n",
      "TWES betas:\n",
      "[ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.1  0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]\n",
      "0.214107193746\n",
      "0.214107193746\n",
      "0.214107193746\n"
     ]
    }
   ],
   "source": [
    "print(\"TWES alphas:\\n\"+str(np.array(tw_alphas)))\n",
    "print(\"TWES gammas:\\n\"+str(np.array(tw_gammas)))\n",
    "print(\"TWES betas:\\n\"+str(np.array(tw_betas)))\n",
    "\n",
    "print(tw_accs1.max(axis=0).mean())\n",
    "# plt.plot(range(len(ts.columns)),tw_accs1.max(axis=0))\n",
    "# plt.show()\n",
    "print(tw_accs2.max(axis=0).mean())\n",
    "# plt.plot(range(len(ts.columns)),tw_accs2.max(axis=0))\n",
    "# plt.show()\n",
    "print(tw_accs3.max(axis=0).mean())\n",
    "# plt.plot(range(len(ts.columns)),tw_accs3.max(axis=0))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3\n",
    "\n",
    "Get found best params from saved .csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ies_alphas=np.array(pd.read_csv('params/ies_alphas.csv',header=None))[:,1]\n",
    "aes_alphas=np.array(pd.read_csv('params/aes_alphas.csv',header=None))[:,1]\n",
    "aes_gammas=np.array(pd.read_csv('params/aes_gammas.csv',header=None))[:,1]\n",
    "w_alphas=np.array(pd.read_csv('params/w_alphas.csv',header=None))[:,1]\n",
    "w_gammas=np.array(pd.read_csv('params/w_gammas.csv',header=None))[:,1]\n",
    "tw_alphas=np.array(pd.read_csv('params/tw_alphas.csv',header=None))[:,1]\n",
    "tw_betas=np.array(pd.read_csv('params/tw_betas.csv',header=None))[:,1]\n",
    "tw_gammas=np.array(pd.read_csv('params/tw_gammas.csv',header=None))[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use the data from '2005-05-12' - '2006-04-30' to make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104\n"
     ]
    }
   ],
   "source": [
    "ts_for=ts['2005-05-12':'2006-04-30']\n",
    "\n",
    "h = 1\n",
    "start = ts_for.index[-1]+timedelta(1)\n",
    "end = ts_for.index[-1]+timedelta(h)\n",
    "rng = pd.date_range(start, end)\n",
    "\n",
    "ies = pd.DataFrame(index = ts_for.index.append(rng), columns = ts.columns)\n",
    "aes = pd.DataFrame(index = ts_for.index.append(rng), columns = ts.columns)\n",
    "w = pd.DataFrame(index = ts_for.index.append(rng), columns = ts.columns)\n",
    "tw = pd.DataFrame(index = ts_for.index.append(rng), columns = ts.columns)\n",
    "\n",
    "i=0\n",
    "for col in ts.columns:\n",
    "    print(i)\n",
    "    display.clear_output(wait=True)\n",
    "    ies[col] = InitExponentialSmoothing(ts_for[col], h, {'alpha':ies_alphas[i], 'AdaptationPeriod': 10})\n",
    "    aes[col] = AdaptiveExponentialSmoothing(ts_for[col], h, {'alpha':aes_alphas[i], 'gamma': aes_gammas[i], 'AdaptationPeriod':10})\n",
    "    w[col] = WintersExponentialSmoothing(ts_for[col], h, {'alpha':w_alphas[i], 'gamma': w_gammas[i], 'seasonality_period':7})\n",
    "    tw[col] = TWExponentialSmoothing(ts_for[col], h, {'alpha':tw_alphas[i], 'beta':tw_betas[i], 'gamma': tw_gammas[i], 'seasonality_period':7})\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4\n",
    "\n",
    "Calculating accuracies and finding best models for EACH of TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ies_accs=[]\n",
    "aes_accs=[]\n",
    "w_accs=[]\n",
    "tw_accs=[]\n",
    "\n",
    "for col in ts.columns:\n",
    "    ies_accs.append(1-qualityMACAPE(ies[col]['2006-03-13':],ts_for[col]['2006-03-13':])[0])\n",
    "    aes_accs.append(1-qualityMACAPE(aes[col]['2006-03-13':],ts_for[col]['2006-03-13':])[0])\n",
    "    w_accs.append(1-qualityMACAPE(w[col]['2006-03-13':],ts_for[col]['2006-03-13':])[0])\n",
    "    tw_accs.append(1-qualityMACAPE(tw[col]['2006-03-13':],ts_for[col]['2006-03-13':])[0])\n",
    "\n",
    "all_accs=np.array([ies_accs,aes_accs,w_accs,tw_accs])\n",
    "\n",
    "best_models=np.argmax(all_accs, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each element of array bellow means number of best model corresponds to each TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best models for the series\n",
      "\n",
      "0: IES, 1: AES, 2: WES, 3: TWES\n",
      "\n",
      "[0 0 0 0 2 0 0 0 0 0 2 2 0 0 0 0 0 0 0 0 0 2 0 0 0 2 2 2 0 0 2 0 2 2 0 0 0\n",
      " 2 0 0 0 0 2 0 0 0 2 0 2 0 0 0 0 0 0 0 0 2 0 0 0 2 0 0 0 2 2 0 0 0 0 3 2 0\n",
      " 0 0 2 2 2 0 2 0 0 0 0 0 0 2 0 2 0 0 0 0 0 0 2 0 2 0 0 0 2 0 0]\n"
     ]
    }
   ],
   "source": [
    "print('Best models for the series\\n')\n",
    "print('0: IES, 1: AES, 2: WES, 3: TWES\\n')\n",
    "\n",
    "print(best_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5\n",
    "Build the histogram of best Accuracy distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD8CAYAAACfF6SlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f77afb86f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_all_accs=pd.Series(all_accs.max(axis=0)).dropna()\n",
    "\n",
    "plt.hist(best_all_accs, bins=50,  normed=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br /><br /><br />\n",
    "<h1 align=\"center\">IV</h1>\n",
    "Use whole data to make prediction. Note that each TS predicted individually by one's best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n"
     ]
    }
   ],
   "source": [
    "ts_all=ts\n",
    "\n",
    "# Remove TS-s that have NaNs at 10 last cells\n",
    "for col in ts.columns:\n",
    "    if len(ts[col]['2006-06-03':].dropna())==0:\n",
    "        ts_all=ts_all.drop(col, 1)\n",
    "        \n",
    "h = 1\n",
    "start = ts_all.index[-1]+timedelta(1)\n",
    "end = ts_all.index[-1]+timedelta(h)\n",
    "rng = pd.date_range(start, end)\n",
    "\n",
    "es = pd.DataFrame(index = ts_all.index.append(rng), columns = ts_all.columns)\n",
    "\n",
    "i=0\n",
    "for col in ts_all.columns:\n",
    "    print(i)\n",
    "    display.clear_output(wait=True)\n",
    "    if best_models[i]==0:\n",
    "        es[col] = InitExponentialSmoothing(ts_all[col], h, {'alpha':ies_alphas[i], 'AdaptationPeriod': 10})\n",
    "    elif best_models[i]==1:\n",
    "        es[col] = AdaptiveExponentialSmoothing(ts_all[col], h, {'alpha':aes_alphas[i], 'gamma': aes_gammas[i], 'AdaptationPeriod':10})\n",
    "    elif best_models[i]==2:\n",
    "        es[col] = WintersExponentialSmoothing(ts_all[col], h, {'alpha':w_alphas[i], 'gamma': w_gammas[i], 'seasonality_period':7})\n",
    "    else:\n",
    "        es[col] = TWExponentialSmoothing(ts_all[col], h, {'alpha':tw_alphas[i], 'beta':tw_betas[i], 'gamma': tw_gammas[i], 'seasonality_period':7})\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4.1\n",
    "\n",
    "Calculate accuracies for unused data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accs_body=[]\n",
    "accs_tail=[]\n",
    "\n",
    "for col in ts_all.columns:\n",
    "    accs_body.append(1-qualityMACAPE(es[col][:'2006-04-30'],ts_all[col][:'2006-04-30'])[0])\n",
    "    accs_tail.append(1-qualityMACAPE(es[col]['2006-04-30':],ts_all[col]['2006-04-30':])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4.2\n",
    "Build the histogram of Accuracy distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nviQVxNCXpIL8P19DFfVnKOzpAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc34fad44d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nklQQQ1+SCmLoS1JB/j+VDxR6pEVfsQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc34d129990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA/sSDgKGV06yAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc34d6113d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Body acc 12.05.05-30.04.06: 0.21669238447\n",
      "Tail acc 30.04.06-13.06.06: 0.179029631742\n"
     ]
    }
   ],
   "source": [
    "accs_body=pd.Series(accs_body).dropna()\n",
    "accs_tail=pd.Series(accs_tail).dropna()\n",
    "\n",
    "bins=60\n",
    "\n",
    "def acc_dens(accs,bins):\n",
    "    dens=np.zeros(bins)\n",
    "    interval=[-1.0,0.73]\n",
    "    ac=[]\n",
    "    for i in range(bins):\n",
    "        a=interval[0]+(interval[1]-interval[0])*i/bins\n",
    "        b=interval[0]+(interval[1]-interval[0])*(i+1)/bins\n",
    "        for acc in accs:\n",
    "            if acc>a and acc<=b:\n",
    "                dens[i]+=1\n",
    "        ac.append(a)\n",
    "    dens=dens/dens.sum()\n",
    "    return dens, ac\n",
    "\n",
    "plt.bar(acc_dens(accs_body,bins)[1], acc_dens(accs_body,bins)[0],width=0.03,label='Body')\n",
    "plt.bar(acc_dens(accs_tail,bins)[1], acc_dens(accs_tail,bins)[0],width=0.03,label='Tail',color='r')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.bar(acc_dens(accs_tail,bins)[1], acc_dens(accs_tail,bins)[0],width=0.03,label='Tail',color='r')\n",
    "plt.bar(acc_dens(accs_body,bins)[1], acc_dens(accs_body,bins)[0],width=0.03,label='Body')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.bar(acc_dens(accs_body,bins)[1], acc_dens(accs_body,bins)[0]-acc_dens(accs_tail,bins)[0],width=0.03,label='Body-Tail')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print('Body acc 12.05.05-30.04.06: '+str(accs_body.mean()))\n",
    "print('Tail acc 30.04.06-13.06.06: '+str(accs_tail.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4.3\n",
    "The barchart for used data (Body) has higher probability of high accuracies more than unused data (Tail). Peak of Tail is located to the right of Body peak, but Body chart is heavy at the right side unlike Tail chart"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
