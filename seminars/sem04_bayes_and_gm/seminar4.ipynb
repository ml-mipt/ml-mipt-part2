{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "МФТИ ФИВТ: Курс Машинное Обучение (осень, 2016), Арсений Ашуха, ars.ashuha@gmail.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline \n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Bayesian inference</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Получение распределения, вместо точечных оценок\n",
    "- Устойчивость к переобучению\n",
    "- Автоматический выбор моделей\n",
    "- Автоматическое определение релевантности признаков \n",
    "- Неуверенность предсказания и весов модели \n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Задачка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![image1](img/task.png)\n",
    "\n",
    "Переменные: t (срабатывание тревоги), v (наличие вора), e (было ли землетрясение), r (радиосообщение) - бинарные\n",
    "\n",
    "Переменная: s (уточненная статистика по криминогенной активности) непрерывная из отрезка [0, 1]\n",
    "\n",
    "\n",
    "| p(t = 1; v, e) | v | e |\n",
    "|----------------|---|---|\n",
    "| 0              | 0 | 0 |\n",
    "| 0.1            | 0 | 1 |\n",
    "| 1              | 1 | 0 |\n",
    "| 1              | 1 | 1 |\n",
    "\n",
    "| p(r = 1; e) | e |\n",
    "|-------------|---|\n",
    "| 0           | 0 |\n",
    "| 0.5         | 1 |\n",
    "\n",
    "\n",
    "\n",
    "p(e=1) = 10^{−2}, p(v=1) = 2×10^{−3}, p(v = 1|s) = s\n",
    "\n",
    "- Расчет p(v = 1|t = 1) (Вероятность вора при условии тревоги)\n",
    "- Расчет p(v = 1|t = 1,s0), где s0 = 2×10^{−3} (Вероятность вора с учетом статистики краж)\n",
    "- Расчет p(v = 1|t = 1, s0, r=1) (Вероятность вора с учетом статистики краж и сообщение про землетрясение)\n",
    "\n",
    "Решение: http://www.machinelearning.ru/wiki/images/8/8c/Lecture7_2012.pdf\n",
    "\n",
    "---\n",
    "\n",
    "[1] Байесовский подход в теории вероятностей. Пример байесовских рассуждений Д. П. Ветров."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h2 align=\"center\">Bayesian Models</h2> \n",
    "### Relevance Vector Machine\n",
    "    Идея: \n",
    "        - Введем персональный коэффициент регуляризации для каждого признака\n",
    "        - Настроим коэффициенты регуляризации, с помощью максимума обоснованности\n",
    "    Итог: \n",
    "        - Веса не релевантных признаков = 0 а значения регуляризатора +inf\n",
    "        - В итоговом решение участвуют очень мало \"релевантных\" объектов\n",
    "            \n",
    "Ссылки: \n",
    "[Пример](https://github.com/AmazaspShumik/sklearn-bayes/blob/master/ipython_notebooks_tutorials/rvm_ard/rvm_demo.ipynb)\n",
    "https://en.wikipedia.org/wiki/Relevance_vector_machine\n",
    "        \n",
    "### Tree-structured Parzen Estimator\n",
    "    Идея: \n",
    "        - Оптимизируем ожидаемое улучшение в пространстве параметров модели (Expected Improvement)\n",
    "        - Мат. ожидание берем по текущему распределению в пространстве параметров модели \n",
    "        \n",
    "Ссылки: \n",
    "[Статья](https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf)\n",
    "[Дока](https://github.com/hyperopt/hyperopt/wiki/FMin)\n",
    "[Пример](https://github.com/bjkomer/hyperopt-tutorial/blob/master/MNIST-Example.ipynb)\n",
    "\n",
    "#### Latent Dirichlet Allocation (Пример модели со скрытыми переменными)\n",
    "    Идея: \n",
    "        - Каждый документ порожден как смесь распределений на словах\n",
    "        - Будем икать распределения на слова (темы), и описывать каждый документ принадлежностью к распределением на слова\n",
    "        - Скрытые переменные p(w|t) и p(t|d) наблюдаемые p(w|d)\n",
    "\n",
    "Ссылки:\n",
    "[Модель сложная](https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation)\n",
    "[Пример](http://nbviewer.jupyter.org/github/arongdari/python-topic-model/blob/master/notebook/AuthorTopicModel_example.ipynb)\n",
    "[Либа](https://radimrehurek.com/gensim/)\n",
    "\n",
    "#### Adaptive Skip-gram (Пример модели с автоматическим определением числа скрытых переменных)\n",
    "    Идея:\n",
    "        - Для построения эмбедингов слов нужно учитывать несколько смыслов одного слова в зависимости от контекста\n",
    "        - Скрытые переменные число смыслов для слова, вектора для пары (слово, смысл)\n",
    "        - Априорное распределение из процесса Дирихле на смыслы для слов\n",
    "        \n",
    "Ссылки: \n",
    "[Статья](https://arxiv.org/abs/1502.07257)\n",
    "[Картинка](https://cs.hse.ru/en/bayesgroup/projects/latent_semantic_space_we)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Structured Prediction</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Цель: предсказывать не одну переменную, а несколько взаимосвязанных: последовательность, набор классов, матрицу дерево. \n",
    "Как решать?: \n",
    "    - Сложно -- очень большое число возможных ответов\n",
    "    - Предполагаем, что зависимости низких порядков\n",
    "![image1](img/e.png)\n",
    "    - Выбор потенциалов -> решение задачи дискретной оптимизации\n",
    "    \n",
    "\n",
    "### Tag prediction (Image2Seq)\n",
    "\n",
    "![image1](img/tag.png)\n",
    "\n",
    "- Какие потенциалы выбирать для задачи? \n",
    "\n",
    "### Image segmentation (Image2Matrix)\n",
    "\n",
    "![image1](img/segm.png)\n",
    "\n",
    "- Какие потенциалы выбирать для задачи?\n",
    "\n",
    "![image1](img/crf.png)\n",
    "\n",
    "### Traffic prediction (Image2Graph)\n",
    "\n",
    "![image1](img/trafic.png)\n",
    "\n",
    "- Какие потенциалы выбирать для задачи?\n",
    "\n",
    "---\n",
    "Автоматическая настройка весов потенциалов -- Structured SVM: \n",
    "\n",
    "Выбор потенциалов -> Настройка коэффициентов  -> Решение задачи дискретной оптимизации\n",
    "\n",
    "![image1](img/ew.png)\n",
    "![image1](img/ssvm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h1 align=\"center\">Recap</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- Байсовские методы и Структурное предсказание -- очень важная тема, по которой нужно читать отдельные курсы \n",
    "\n",
    "Байсовские методы:\n",
    "    - Получение апостреотного распределения на параметры или скрытые компоненты\n",
    "    - Устойчево к переобучению, позволяет выбирать модели и признаки\n",
    "\n",
    "Структурное предсказание:\n",
    "    - Основная идея -- учет взаимосвязи переменных, которые нужно предсказать\n",
    "    - Основная проблема --- экспоненциальное сило ответов\n",
    "    \n",
    "Домашка: сегментация картинок с использованием ssvm, будет выданна 01.10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
