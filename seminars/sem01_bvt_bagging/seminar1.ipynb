{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "МФТИ ФИВТ: Курс Машинное Обучение (осень, 2016), Арсений Ашуха, ars.ashuha@gmail.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline \n",
    "\n",
    "# Проверьте установлин ли у вас grapviz \"dot -h\" в терминале\n",
    "# Обновите pydot \"sudo pip2 install pydot --upgrade\" в терминале\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Course Rulles</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Курс будет состоять из 12 Лекций и 4 Гостевых лекций (от лучших в стране специалистов ;)). \n",
    "\n",
    "**Домашнее задание**\n",
    "- Будет выдаваться после каждого семинара, иногда это будут контексты\n",
    "- Задание необходимо сдать в течении 6 дней после семинара\n",
    "- Задание оценивается  1, если вы его сделали достаточно хорошо\n",
    "- Задание оценивается  0, если вы не выполнили задание или сделали много ГРУБЫХ ошибок \n",
    "- Задание оценивается -1, если вы его списали (и тому кто и тому у кого)\n",
    "- Задания, сданные после дедлайна, не проверяются\n",
    "- **PS**: Каждый 0 или -1 это доп. вопрос на экзамене, который идет в итоговую оценку за экзамен. \n",
    "\n",
    "**Контексты**\n",
    "\n",
    "- Будет проведено 4 контеста \n",
    "- Задание необходимо сдать в течение 6 дней после семинара\n",
    "- Вы получаете 1 балл, если побили бейзлайн и коротко текстом описали решение, 0 - если нет\n",
    "- Бонусы получают первые три человека в каждой в группе\n",
    "\n",
    "**Экзамен**\n",
    "\n",
    "- Будет экзамен, автоматов не будет\n",
    "- Будет список вопросов \n",
    "- Будет теор. минимум\n",
    "\n",
    "**Оценка**\n",
    "\n",
    "Финальная оценка будет вычисляться, как\n",
    "    $$mark = [exam\\_creidts > c_0] \\cdot (c_1 \\cdot hw\\_credits + c_2 \\cdot contest\\_credits + c_3 \\cdot exam\\_creidts)$$\n",
    "коэффициенты будут объявлены позже"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">In the previous series</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Model Theoretical Background\n",
    "\n",
    "Мы хотим научиться предсказывать какую-то величину $y_i$ по каким-то признакам $x_i$.\n",
    "\n",
    "Линейные модели - это набор методов, которые предполагают, что целевое значение ($y_i$) может быть восстановлено как линейная комбинация признаков ($x_i$). \n",
    "\n",
    "$$\\hat{y}_i(x_i, w) = x_i \\cdot w^T$$\n",
    "\n",
    "<img src=\"img/linear_model.png\">\n",
    "\n",
    "Для обучения модели, вводится функция потерь $L_i(\\hat{y}_i(x_i), y_i)$, к примеру:\n",
    "- Для регрессии:\n",
    "$$L_i(\\hat{y}_i(x_i, w), y_i) = (\\hat{y}_i(x_i, w) - y_i)^2$$ \n",
    "- Для классификации: \n",
    "$$L_i(\\hat{y}_i(x_i, w), y_i) = \\sum_{y_i} y_i \\log \\hat{y}_i(x_i, w)$$\n",
    "Целевой функцией является сумма ошибок по всем объектам тренировочной выборки\n",
    "\n",
    "$$L(X, Y, w) = \\sum_{x_i} L_i(y_i(x_i, w), y_i) \\rightarrow \\min_w$$\n",
    "\n",
    "Оптимизируем функцию:\n",
    "- Если данных много -- стохастические, градиентные методы \n",
    "\n",
    "$$w_k = w_{k-1} - step\\_length \\cdot \\frac{dL}{dw}$$\n",
    "\n",
    "- Если данных мало -- методы второго порядка, использующие гессиан (HFN, LBFGS, ...)\n",
    "\n",
    "### Trees Theoretical Background\n",
    "\n",
    "Мы решаем всю ту-же задачу, только теперь хотим предсказать неизвестное значение не как линейную комбинацию признаков, а как дерево, в каждом узле которого есть какие-то правила. \n",
    "\n",
    "<img src=\"img/tree_model.png\">\n",
    "\n",
    "<center> Предсказание смерти пассажиров Титаника. </center>\n",
    "\n",
    "Для обучения модели обычно используется жадная стратегия, которая стремится как можно сильнее разделить классы (снизить ошибку предсказания) при построении каждого листа дерева. К примеру, можно строить пороговые функции (x_i > w_i) минимизируя следующие функции:\n",
    "- Для задачи классификации -- ответ, номер класса с большей вероятностью\n",
    "$$ H(Y_{leaf}) = |leaf\\_left|\\sum_{y \\in Y_{leaf\\_left}} p(y) log~p(y) + |leaf\\_right|\\sum_{y \\in Y_{leaf\\_right}} p(y) log~p(y)$$\n",
    "- Для задачи регрессии, ответ среднее значение в листе\n",
    "$$ MSE(Y_{leaf}) = |leaf\\_left| \\sum_{y \\in Y_{leaf_left}} (E(y) - y)^2 + |leaf\\_right| \\sum_{y \\in Y_{leaf_right}} (E(y) - y)^2$$\n",
    "\n",
    "### Some Facts about a Trees and a Linear models\n",
    "\n",
    "- Linear Model\n",
    "    - Слишком простые\n",
    "    - Не сильно меняются при небольшом изменении выборки\n",
    "- Tree Model\n",
    "    - Слишком сложные -- легко закодировать всю выборку деревом\n",
    "    - Сильно меняются при небольшом изменении выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузим датасет титаник"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titanic = pd.read_csv('./data/train.csv')[['Survived', 'Pclass', 'Sex', 'Age', 'Fare']]\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sex_encoder = LabelEncoder()\n",
    "titanic.Sex = sex_encoder.fit_transform(titanic.Sex)\n",
    "features = ['Pclass', 'Sex', 'Age', 'Fare']\n",
    "X, y = titanic[features].values, titanic.Survived.values\n",
    "\n",
    "X = np.nan_to_num(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучим диненую модель на разных подвыборках, похожи-ли коэфиценты?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "for n_items in [200, 500]:\n",
    "    reg = LogisticRegression().fit(X[:n_items], y[:n_items])\n",
    "    print 'n_items', n_items, 'w = ',', '.join(map(lambda x: '%.4f' % x, reg.coef_[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучем деревья на тех-же подвыборках, похожи-ли деревья?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "\n",
    "tree1 = DecisionTreeClassifier().fit(X[:200], y[:200])\n",
    "tree2 = DecisionTreeClassifier().fit(X[:500], y[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если не работает pydot, то можно установить pydotplus и заменить все включения. Дополнительно необходимо установить graphviz для отображения дерева.\n",
    "Подробности установки можно найти на http://graphviz.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pydot \n",
    "from StringIO import StringIO\n",
    "from IPython.display import Image  \n",
    "\n",
    "dot_data = StringIO()  \n",
    "export_graphviz(tree1, out_file=dot_data)  \n",
    "graph = pydot.graph_from_dot_data(dot_data.getvalue())[0]\n",
    "Image(graph.create_png())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dot_data = StringIO()  \n",
    "export_graphviz(tree2, out_file=dot_data)  \n",
    "graph = pydot.graph_from_dot_data(dot_data.getvalue())[0]\n",
    "Image(graph.create_png()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте разберемся, что происходит"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Bias-variance tradeoff</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teoretical Background\n",
    "\n",
    "#### Какя природа бывает у ошибок\n",
    "\n",
    "<img src=\"img/bv_darts.png\", width=400>\n",
    "\n",
    "#### Как это отражается на модели\n",
    "\n",
    "<img src=\"img/bv_model_complex.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teoretical Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$$\\mathrm{E}\\Big[\\big(y - \\hat{f}(x)\\big)^2\\Big] = \\mathrm{Bias}\\big[\\hat{f}(x)\\big]^2 + \\mathrm{Var}\\big[\\hat{f}(x)\\big] + \\sigma^2 \\\\$$\n",
    "\n",
    "---------\n",
    "$$ \\mathrm{Bias}\\big[\\hat{f}(x)\\big] = \\mathrm{E}\\big[\\hat{f}(x) - f(x)\\big] $$\n",
    "\n",
    "\n",
    "and\n",
    "\n",
    "$$\\mathrm{Var}\\big[\\hat{f}(x)\\big] = \\mathrm{E}[\\hat{f}(x)^2] - \\mathrm{E}[\\hat{f}(x)]^2$$\n",
    "\n",
    "----------\n",
    "\n",
    "\n",
    "<img src=\"img/bvts.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Bagging</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theoretical Background\n",
    "\n",
    "- Усреднение моделей\n",
    "- Работает, потому что не ухудшает смещение, а разброс уменьшается линейно (если алгоритмы не коррелированы)\n",
    "- Нужны модели с маленьким смещением (Какие???)\n",
    "- Нужны некоррелированные модели\n",
    "\n",
    "Help: Раздел 3.2 https://github.com/esokolov/ml-course-msu/blob/master/ML15-spring/lecture-notes/Sem04_ensembles.pdf  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Смещение для беггинга\n",
    "\n",
    "<img src=\"img/bag_mu1.png\">\n",
    "\n",
    "<img src=\"img/bag_mu2.png\">\n",
    "\n",
    "### Разброс для беггинга\n",
    "\n",
    "<img src=\"img/bag_var1.png\">\n",
    "\n",
    "<img src=\"img/bag_var2.png\">\n",
    "\n",
    "<img src=\"img/bag_var3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practical Task Model Сorrelation (Linear and Trees Bagging)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!sh ./get_data.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adult = pd.read_csv(\n",
    "    './data/adult.data', \n",
    "    names=[\n",
    "        \"Age\", \"Workclass\", \"fnlwgt\", \"Education\", \"Education-Num\", \"Martial Status\",\n",
    "        \"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Capital Gain\", \"Capital Loss\",\n",
    "        \"Hours per week\", \"Country\", \"Target\"], \n",
    "    header=None, na_values=\"?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adult.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adult = pd.get_dummies(adult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adult.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adult[\"Target\"] = adult[\"Target_ >50K\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adult.columns[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = adult[adult.columns[:-3]].values, adult[adult.columns[-1]].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Бегинг на лог-регрессиях "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf1 = BaggingClassifier(base_estimator=LogisticRegression(), n_estimators=100)\n",
    "scores1 = cross_val_score(clf1, X, y, cv=4, n_jobs=4)\n",
    "\n",
    "print scores1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Бегинг на девевьях"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf2 = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=100)\n",
    "scores2 = cross_val_score(clf2, X, y, cv=4, n_jobs=4)\n",
    "\n",
    "print scores2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Натренируем модели и вытащим базовые алгоритмы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = X[:20000], y[:20000], X[20000:], y[20000:]\n",
    "\n",
    "clf1 = clf1.fit(X_train, y_train)\n",
    "clf2 = clf2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf1.estimators_[0].predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Посмотрим на корреляцию предсказаний"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred1 = [clf.predict(X_test) for clf in clf1.estimators_]\n",
    "pred2 = [clf.predict(X_test) for clf in clf2.estimators_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pearsonr(pred1[0], pred1[1])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pearsonr(pred2[0], pred2[1])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = np.zeros((len(clf1.estimators_), len(clf1.estimators_)))\n",
    "\n",
    "for i in range(len(clf1.estimators_)):\n",
    "    for j in range(len(clf1.estimators_)):\n",
    "        A[i, j] = pearsonr(pred1[i], pred1[j])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pylab.imshow(A, interpolation='none', cmap='hot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = np.zeros((len(clf1.estimators_), len(clf1.estimators_)))\n",
    "\n",
    "for i in range(len(clf1.estimators_)):\n",
    "    for j in range(len(clf1.estimators_)):\n",
    "        A[i, j] = pearsonr(pred2[i], pred2[j])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pylab.imshow(A, interpolation='none', cmap='hot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Есть-ли Overfitting с увиличением числа деревьев и сложности?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for n_estimators in [10, 40, 100, 200, 600, 1000]:\n",
    "    clf = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=n_estimators, n_jobs=4)\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    train_acc, test_acc = accuracy_score(clf.predict(X_train), y_train), accuracy_score(clf.predict(X_test), y_test)\n",
    "    print 'n_estimators = %4s train_acc = %4s test_acc = %4s' %(n_estimators, train_acc, test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for n_estimators in [10, 40, 100, 200, 600, 1000]:\n",
    "    clf = BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=7), n_estimators=n_estimators, n_jobs=4)\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    train_acc, test_acc = accuracy_score(clf.predict(X_train), y_train), accuracy_score(clf.predict(X_test), y_test)\n",
    "    print 'n_estimators = %4s train_acc = %4s test_acc = %4s' %(n_estimators, train_acc, test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for n_estimators in [10, 40, 100, 200, 600, 1000]:\n",
    "    clf = BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=14), n_estimators=n_estimators, n_jobs=4)\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    train_acc, test_acc = accuracy_score(clf.predict(X_train), y_train), accuracy_score(clf.predict(X_test), y_test)\n",
    "    print 'n_estimators = %4s train_acc = %4s test_acc = %4s' %(n_estimators, train_acc, test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Resume</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Смещение и разброс**:\n",
    "    - Ошибки бывают разные\n",
    "    - Ошибку можно разложить на составляющие части, чтобы лучше понимать, что происходит\n",
    "    - Это может помочь нам придумать хорошие алгоритмы и понимать, как такие алгоритмы будут работать\n",
    "\n",
    "**Bagging**:\n",
    "    - Одна из лучших техник для построения алгоритмов ML\n",
    "    - Линейно уменьшает Разброс и не уменьшает Смещение \n",
    "    - Слабое переобучение\n",
    "    - НО переобучение ЕСТЬ -- от сложности одного алгоритма, лучше все же немного обрезать деревья\n",
    "\n",
    "**Что почитать**:\n",
    "- Hastie, The Elements of Statistical Learning, https://goo.gl/k3wfEU\n",
    "    - 2.9 Model Selection and the Bias–Variance Tradeoff \n",
    "    - 15 Random Forests\n",
    "- Соколов, Семинары по композиционным методам, https://goo.gl/sn8RyJ\n",
    "- Andrew Ng, Bias vs. Variance, https://goo.gl/1ISZ6Y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
